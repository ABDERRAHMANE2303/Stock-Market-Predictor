{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Model Training for Stock Prediction\n",
    "\n",
    "This notebook trains LSTM models for predicting stock price movements for:\n",
    "- 20 different stocks\n",
    "- 3 prediction periods (day, week, month)\n",
    "\n",
    "The trained models will be saved to `../model/lstm/period/lstm_stock_period.h5`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "import random\n",
    "import tensorflow as tf\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Define the list of stocks to process\n",
    "stocks = [\n",
    "    'AAPL', 'MSFT', 'GOOG', 'AMZN', 'TSLA', 'META', 'NVDA', 'SPY', 'V', 'DIS',\n",
    "    'NFLX', 'PYPL', 'BABA', 'IBM', 'AMD', 'BA', 'INTC', 'T', 'GS', 'NKE'\n",
    "]\n",
    "\n",
    "# Define periods\n",
    "periods = ['day', 'week', 'month']\n",
    "\n",
    "# Create output directories\n",
    "for period in periods:\n",
    "    os.makedirs(f'../model/lstm/{period}', exist_ok=True)\n",
    "print(\"Output directories created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Preparation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(stock, period):\n",
    "    \"\"\"Load prepared data from CSV\"\"\"\n",
    "    file_path = f'../data/lstm/{period}/{stock}_lstm_{period}.csv'\n",
    "    \n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"Warning: File {file_path} does not exist. Skipping.\")\n",
    "        return None\n",
    "    \n",
    "    df = pd.read_csv(file_path)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_lstm_data(df, target_col, time_steps=10, test_size=0.2, validation_size=0.2):\n",
    "    \"\"\"Prepare data for LSTM model training with sequences\"\"\"\n",
    "    # Convert date column to datetime and sort\n",
    "    if 'date' in df.columns:\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "        df.sort_values('date', inplace=True)\n",
    "        df = df.drop(columns=['date'])  # Remove date after sorting\n",
    "    \n",
    "    # Extract features and target\n",
    "    y = df[target_col].values\n",
    "    X = df.drop(columns=[target_col]).values\n",
    "    \n",
    "    # Create sequences for LSTM\n",
    "    X_seq, y_seq = [], []\n",
    "    for i in range(len(X) - time_steps):\n",
    "        X_seq.append(X[i:i + time_steps])\n",
    "        y_seq.append(y[i + time_steps])\n",
    "    \n",
    "    X_seq = np.array(X_seq)\n",
    "    y_seq = np.array(y_seq)\n",
    "    \n",
    "    # Split into training and temporary test sets\n",
    "    X_train_temp, X_test, y_train_temp, y_test = train_test_split(\n",
    "        X_seq, y_seq, test_size=test_size, shuffle=False\n",
    "    )\n",
    "    \n",
    "    # Split training set into actual training and validation sets\n",
    "    val_size_adjusted = validation_size / (1 - test_size)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train_temp, y_train_temp, test_size=val_size_adjusted, shuffle=False\n",
    "    )\n",
    "    \n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Building Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm_model(input_shape, lstm_units=64, dropout_rate=0.2, learning_rate=0.001):\n",
    "    \"\"\"Build LSTM model for binary classification\"\"\"\n",
    "    model = Sequential([\n",
    "        LSTM(lstm_units, return_sequences=True, input_shape=input_shape),\n",
    "        Dropout(dropout_rate),\n",
    "        LSTM(lstm_units // 2),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Quick Parameter Selection Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_parameters(X_train, X_val, y_train, y_val, verbose=0):\n",
    "    \"\"\"Simple parameter selection for LSTM model\"\"\"\n",
    "    # Define parameter options to try\n",
    "    lstm_units_options = [32, 64]\n",
    "    dropout_options = [0.2, 0.3]\n",
    "    learning_rate_options = [0.001, 0.0005]\n",
    "    \n",
    "    best_accuracy = 0\n",
    "    best_params = {}\n",
    "    \n",
    "    # Simple grid search\n",
    "    for lstm_units in lstm_units_options:\n",
    "        for dropout_rate in dropout_options:\n",
    "            for learning_rate in learning_rate_options:\n",
    "                # Build model with current parameters\n",
    "                model = build_lstm_model(\n",
    "                    input_shape=(X_train.shape[1], X_train.shape[2]),\n",
    "                    lstm_units=lstm_units,\n",
    "                    dropout_rate=dropout_rate,\n",
    "                    learning_rate=learning_rate\n",
    "                )\n",
    "                \n",
    "                # Train for a few epochs to get a quick estimate\n",
    "                history = model.fit(\n",
    "                    X_train, y_train,\n",
    "                    epochs=5,\n",
    "                    batch_size=32,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    verbose=verbose\n",
    "                )\n",
    "                \n",
    "                # Get validation accuracy\n",
    "                val_accuracy = history.history['val_accuracy'][-1]\n",
    "                \n",
    "                # Print current parameters and accuracy\n",
    "                if verbose > 0:\n",
    "                    print(f\"LSTM units: {lstm_units}, Dropout: {dropout_rate}, LR: {learning_rate}, Val Acc: {val_accuracy:.4f}\")\n",
    "                \n",
    "                # Update best parameters if current is better\n",
    "                if val_accuracy > best_accuracy:\n",
    "                    best_accuracy = val_accuracy\n",
    "                    best_params = {\n",
    "                        'lstm_units': lstm_units,\n",
    "                        'dropout_rate': dropout_rate,\n",
    "                        'learning_rate': learning_rate\n",
    "                    }\n",
    "    \n",
    "    print(f\"Best parameters: {best_params}, Best validation accuracy: {best_accuracy:.4f}\")\n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lstm_model(X_train, X_val, y_train, y_val, params, epochs=50, batch_size=32):\n",
    "    \"\"\"Train LSTM model with early stopping\"\"\"\n",
    "    # Build model with selected parameters\n",
    "    model = build_lstm_model(\n",
    "        input_shape=(X_train.shape[1], X_train.shape[2]),\n",
    "        lstm_units=params['lstm_units'],\n",
    "        dropout_rate=params['dropout_rate'],\n",
    "        learning_rate=params['learning_rate']\n",
    "    )\n",
    "    \n",
    "    # Set up callbacks\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    \n",
    "    # Train model\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(X_val, y_val),\n",
    "        callbacks=[early_stopping],\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluate and Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_lstm_model(model, X_test, y_test, history, stock, period):\n",
    "    \"\"\"Evaluate LSTM model and plot results\"\"\"\n",
    "    # Evaluate on test set\n",
    "    test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(f\"Test accuracy: {test_accuracy:.4f}\")\n",
    "    \n",
    "    # Plot training history\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # Plot accuracy\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title(f'{stock} {period} - Model Accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='lower right')\n",
    "    \n",
    "    # Plot loss\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title(f'{stock} {period} - Model Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Generate predictions for test set\n",
    "    y_pred_prob = model.predict(X_test, verbose=0)\n",
    "    y_pred = (y_pred_prob > 0.5).astype(int).flatten()\n",
    "    \n",
    "    # Calculate confusion matrix\n",
    "    from sklearn.metrics import confusion_matrix, classification_report\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # Print classification report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title(f'{stock} {period} - Confusion Matrix')\n",
    "    plt.colorbar()\n",
    "    classes = ['Down', 'Up']\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    \n",
    "    # Add text annotations\n",
    "    thresh = cm.max() / 2\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            plt.text(j, i, format(cm[i, j], 'd'),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()\n",
    "    \n",
    "    return test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Main Processing Function for Single Stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_stock_lstm(stock, period, time_steps=10, param_selection=True, plot=True):\n",
    "    \"\"\"Process a single stock for a specific prediction period\"\"\"\n",
    "    print(f\"\\nProcessing {stock} for {period} prediction...\")\n",
    "    \n",
    "    # Load data\n",
    "    df = load_data(stock, period)\n",
    "    if df is None:\n",
    "        return None\n",
    "    \n",
    "    # Get target column name\n",
    "    target_col = f'Target_Next_{period.capitalize()}'\n",
    "    if target_col not in df.columns:\n",
    "        print(f\"Error: Target column {target_col} not found in data.\")\n",
    "        return None\n",
    "    \n",
    "    # Prepare data\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test = prepare_lstm_data(\n",
    "        df, target_col, time_steps=time_steps\n",
    "    )\n",
    "    \n",
    "    print(f\"Data shapes: X_train: {X_train.shape}, X_val: {X_val.shape}, X_test: {X_test.shape}\")\n",
    "    \n",
    "    # Quick parameter selection if enabled\n",
    "    if param_selection:\n",
    "        params = select_parameters(X_train, X_val, y_train, y_val)\n",
    "    else:\n",
    "        # Default parameters\n",
    "        params = {\n",
    "            'lstm_units': 64,\n",
    "            'dropout_rate': 0.2,\n",
    "            'learning_rate': 0.001\n",
    "        }\n",
    "    \n",
    "    # Train model\n",
    "    model, history = train_lstm_model(X_train, X_val, y_train, y_val, params)\n",
    "    \n",
    "    # Evaluate model\n",
    "    if plot:\n",
    "        test_accuracy = evaluate_lstm_model(model, X_test, y_test, history, stock, period)\n",
    "    else:\n",
    "        test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "        print(f\"Test accuracy: {test_accuracy:.4f}\")\n",
    "    \n",
    "    # Save model\n",
    "    model_path = f'../model/lstm/{period}/lstm_{stock}_{period}.h5'\n",
    "    model.save(model_path)\n",
    "    print(f\"Model saved to {model_path}\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Test with Sample Stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with a sample stock\n",
    "sample_stock = 'AAPL'\n",
    "sample_period = 'day'\n",
    "\n",
    "test_model = process_stock_lstm(sample_stock, sample_period, time_steps=10, param_selection=True, plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Process All Stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_all_stocks(time_steps=10, param_selection=False, plot=False):\n",
    "    \"\"\"Process all stocks and periods\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    # Process each stock\n",
    "    for stock in stocks:\n",
    "        results[stock] = {}\n",
    "        \n",
    "        # Process each period\n",
    "        for period in periods:\n",
    "            print(f\"\\n{'='*50}\")\n",
    "            print(f\"Training {stock} {period} model\")\n",
    "            print(f\"{'='*50}\")\n",
    "            \n",
    "            # Process the current stock-period combination\n",
    "            model = process_stock_lstm(\n",
    "                stock=stock,\n",
    "                period=period,\n",
    "                time_steps=time_steps,\n",
    "                param_selection=param_selection,\n",
    "                plot=plot\n",
    "            )\n",
    "            \n",
    "            if model is not None:\n",
    "                results[stock][period] = 'Success'\n",
    "            else:\n",
    "                results[stock][period] = 'Failed'\n",
    "    \n",
    "    # Display summary\n",
    "    print(\"\\nProcessing Summary:\")\n",
    "    for stock in stocks:\n",
    "        print(f\"\\n{stock}:\")\n",
    "        for period in periods:\n",
    "            status = results.get(stock, {}).get(period, 'Not processed')\n",
    "            print(f\"  {period}: {status}\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Run Full Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set to True when ready to process all stocks\n",
    "process_all = True\n",
    "\n",
    "if process_all:\n",
    "    # Process all stocks\n",
    "    # Set param_selection=False to use default parameters for all models\n",
    "    # Set plot=False to disable plotting for each model\n",
    "    processing_results = process_all_stocks(time_steps=10, param_selection=False, plot=False)\n",
    "else:\n",
    "    print(\"Full processing is disabled. Set 'process_all = True' to train all models.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Verify Saved Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_saved_models():\n",
    "    \"\"\"Verify that all expected models have been saved\"\"\"\n",
    "    print(\"Verifying saved models...\")\n",
    "    \n",
    "    expected_count = len(stocks) * len(periods)\n",
    "    found_count = 0\n",
    "    missing_models = []\n",
    "    \n",
    "    for period in periods:\n",
    "        for stock in stocks:\n",
    "            model_path = f'../model/lstm/{period}/lstm_{stock}_{period}.h5'\n",
    "            if os.path.exists(model_path):\n",
    "                found_count += 1\n",
    "            else:\n",
    "                missing_models.append(f\"{stock}_{period}\")\n",
    "    \n",
    "    print(f\"Found {found_count} out of {expected_count} expected models.\")\n",
    "    \n",
    "    if missing_models:\n",
    "        print(f\"Missing {len(missing_models)} models:\")\n",
    "        for model in missing_models[:10]:  # Show first 10 if many are missing\n",
    "            print(f\"  - {model}\")\n",
    "        if len(missing_models) > 10:\n",
    "            print(f\"  ...and {len(missing_models) - 10} more\")\n",
    "    else:\n",
    "        print(\"All expected models have been saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this after processing all stocks to verify models were saved\n",
    "if process_all:\n",
    "    verify_saved_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
