{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock Price Prediction Data Preparation for LSTM\n",
    "\n",
    "This notebook prepares stock data for prediction using LSTM models for three different time periods:\n",
    "1. Next day close price\n",
    "2. Next week average close price\n",
    "3. Next month average close price\n",
    "\n",
    "For each stock, we'll create three separate datasets specifically formatted for each prediction period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of stock symbols\n",
    "stocks = [\"AAPL\", \"MSFT\", \"GOOG\", \"AMZN\", \"TSLA\", \n",
    "          \"META\", \"NVDA\", \"SPY\", \"V\", \"DIS\",\n",
    "          \"NFLX\", \"PYPL\", \"BABA\", \"IBM\", \"AMD\",\n",
    "          \"BA\", \"INTC\", \"T\", \"GS\", \"NKE\"]\n",
    "\n",
    "# Path to the project root\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"../..\"))\n",
    "\n",
    "# Paths for input and output data\n",
    "input_folder = os.path.join(project_root, \"data\", \"lstm\",\"initial\")\n",
    "output_base_folder = os.path.join(project_root, \"data\", \"lstm\")\n",
    "\n",
    "# Create output folders for each prediction period\n",
    "output_folders = {\n",
    "    'day': os.path.join(output_base_folder, \"day\"),\n",
    "    'week': os.path.join(output_base_folder, \"week\"),\n",
    "    'month': os.path.join(output_base_folder, \"month\")\n",
    "}\n",
    "\n",
    "# Ensure output directories exist\n",
    "for folder in output_folders.values():\n",
    "    os.makedirs(folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions for Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_next_day_data_lstm(df):\n",
    "    \"\"\"\n",
    "    Prepare data for next day prediction using LSTM.\n",
    "    For LSTM, we keep all features but update the target values.\n",
    "    \"\"\"\n",
    "    # Make a copy to avoid modifying the original dataframe\n",
    "    lstm_df = df.copy()\n",
    "    \n",
    "    # The target for next day prediction is already in the dataset as 'next_day_close_scaled'\n",
    "    # No additional processing is needed\n",
    "    \n",
    "    return lstm_df\n",
    "\n",
    "def prepare_next_week_data_lstm(df):\n",
    "    \"\"\"\n",
    "    Prepare data for next week average prediction using LSTM.\n",
    "    We'll create a new target column that represents the average close price for the next 5 trading days.\n",
    "    \"\"\"\n",
    "    # Make a copy to avoid modifying the original dataframe\n",
    "    lstm_df = df.copy()\n",
    "    \n",
    "    # Ensure date column is datetime\n",
    "    lstm_df['date'] = pd.to_datetime(lstm_df['date'])\n",
    "    \n",
    "    # Sort by date\n",
    "    lstm_df = lstm_df.sort_values('date')\n",
    "    \n",
    "    # Calculate the average close price for the next 5 trading days (1 week)\n",
    "    # First, get the raw close prices for the calculation\n",
    "    close_values = lstm_df['close_scaled'].values\n",
    "    next_week_avg = []\n",
    "    \n",
    "    for i in range(len(close_values)):\n",
    "        if i + 5 < len(close_values):\n",
    "            # Calculate average of next 5 days\n",
    "            avg = np.mean(close_values[i+1:i+6])\n",
    "            next_week_avg.append(avg)\n",
    "        else:\n",
    "            # For the last 5 days, we can't calculate the average, so use NaN\n",
    "            next_week_avg.append(np.nan)\n",
    "    \n",
    "    # Add the calculated average as a new target column\n",
    "    lstm_df['next_week_close_scaled'] = next_week_avg\n",
    "    \n",
    "    # Calculate raw next week close price (not scaled) for reference\n",
    "    # Since the raw close is already in the dataframe, we can use the same approach\n",
    "    close_original_values = lstm_df['close_original'].values\n",
    "    next_week_avg_original = []\n",
    "    \n",
    "    for i in range(len(close_original_values)):\n",
    "        if i + 5 < len(close_original_values):\n",
    "            avg = np.mean(close_original_values[i+1:i+6])\n",
    "            next_week_avg_original.append(avg)\n",
    "        else:\n",
    "            next_week_avg_original.append(np.nan)\n",
    "    \n",
    "    lstm_df['next_week_close_original'] = next_week_avg_original\n",
    "    \n",
    "    # Add a column indicating whether the next week's average is higher than the current close\n",
    "    lstm_df['price_up_week'] = (lstm_df['next_week_close_scaled'] > lstm_df['close_scaled']).astype(int)\n",
    "    \n",
    "    # Drop rows with NaN values for the target\n",
    "    lstm_df = lstm_df.dropna(subset=['next_week_close_scaled'])\n",
    "    \n",
    "    return lstm_df\n",
    "\n",
    "def prepare_next_month_data_lstm(df):\n",
    "    \"\"\"\n",
    "    Prepare data for next month average prediction using LSTM.\n",
    "    We'll create a new target column that represents the average close price for the next 21 trading days.\n",
    "    \"\"\"\n",
    "    # Make a copy to avoid modifying the original dataframe\n",
    "    lstm_df = df.copy()\n",
    "    \n",
    "    # Ensure date column is datetime\n",
    "    lstm_df['date'] = pd.to_datetime(lstm_df['date'])\n",
    "    \n",
    "    # Sort by date\n",
    "    lstm_df = lstm_df.sort_values('date')\n",
    "    \n",
    "    # Calculate the average close price for the next 21 trading days (1 month)\n",
    "    close_values = lstm_df['close_scaled'].values\n",
    "    next_month_avg = []\n",
    "    \n",
    "    for i in range(len(close_values)):\n",
    "        if i + 21 < len(close_values):\n",
    "            # Calculate average of next 21 days\n",
    "            avg = np.mean(close_values[i+1:i+22])\n",
    "            next_month_avg.append(avg)\n",
    "        else:\n",
    "            # For the last 21 days, we can't calculate the average, so use NaN\n",
    "            next_month_avg.append(np.nan)\n",
    "    \n",
    "    # Add the calculated average as a new target column\n",
    "    lstm_df['next_month_close_scaled'] = next_month_avg\n",
    "    \n",
    "    # Calculate raw next month close price (not scaled) for reference\n",
    "    close_original_values = lstm_df['close_original'].values\n",
    "    next_month_avg_original = []\n",
    "    \n",
    "    for i in range(len(close_original_values)):\n",
    "        if i + 21 < len(close_original_values):\n",
    "            avg = np.mean(close_original_values[i+1:i+22])\n",
    "            next_month_avg_original.append(avg)\n",
    "        else:\n",
    "            next_month_avg_original.append(np.nan)\n",
    "    \n",
    "    lstm_df['next_month_close_original'] = next_month_avg_original\n",
    "    \n",
    "    # Add a column indicating whether the next month's average is higher than the current close\n",
    "    lstm_df['price_up_month'] = (lstm_df['next_month_close_scaled'] > lstm_df['close_scaled']).astype(int)\n",
    "    \n",
    "    # Drop rows with NaN values for the target\n",
    "    lstm_df = lstm_df.dropna(subset=['next_month_close_scaled'])\n",
    "    \n",
    "    return lstm_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Each Stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_stocks_lstm():\n",
    "    \"\"\"Process all stocks and create datasets for different prediction periods for LSTM model\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for stock in stocks:\n",
    "        try:\n",
    "            # Construct input file path\n",
    "            input_file = os.path.join(input_folder, f\"{stock}_lstm.csv\")\n",
    "            \n",
    "            # Read the stock data\n",
    "            df = pd.read_csv(input_file)\n",
    "            \n",
    "            # Check if 'close_original' column exists, if not, add it\n",
    "            if 'close_original' not in df.columns and 'close_scaled' in df.columns and 'close_min' in df.columns and 'close_max' in df.columns:\n",
    "                # Unscale the close price using min-max scaling formula: original = min + scaled * (max - min)\n",
    "                df['close_original'] = df['close_min'] + df['close_scaled'] * (df['close_max'] - df['close_min'])\n",
    "            \n",
    "            # Prepare data for different prediction periods\n",
    "            day_data = prepare_next_day_data_lstm(df)\n",
    "            week_data = prepare_next_week_data_lstm(df)\n",
    "            month_data = prepare_next_month_data_lstm(df)\n",
    "            \n",
    "            # Save the prepared data\n",
    "            day_data.to_csv(os.path.join(output_folders['day'], f\"{stock}_lstm_day.csv\"), index=False)\n",
    "            week_data.to_csv(os.path.join(output_folders['week'], f\"{stock}_lstm_week.csv\"), index=False)\n",
    "            month_data.to_csv(os.path.join(output_folders['month'], f\"{stock}_lstm_month.csv\"), index=False)\n",
    "            \n",
    "            results.append({\n",
    "                'stock': stock,\n",
    "                'status': 'Success',\n",
    "                'day_rows': len(day_data),\n",
    "                'week_rows': len(week_data),\n",
    "                'month_rows': len(month_data)\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            results.append({\n",
    "                'stock': stock,\n",
    "                'status': f'Error: {str(e)}',\n",
    "                'day_rows': 0,\n",
    "                'week_rows': 0,\n",
    "                'month_rows': 0\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "stock",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "status",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "day_rows",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "week_rows",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "month_rows",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "c5f30d5e-ceb0-408f-a5ac-d1cb6ed646c1",
       "rows": [
        [
         "0",
         "AAPL",
         "Success",
         "2513",
         "2508",
         "2492"
        ],
        [
         "1",
         "MSFT",
         "Success",
         "2513",
         "2508",
         "2492"
        ],
        [
         "2",
         "GOOG",
         "Success",
         "2513",
         "2508",
         "2492"
        ],
        [
         "3",
         "AMZN",
         "Success",
         "2513",
         "2508",
         "2492"
        ],
        [
         "4",
         "TSLA",
         "Success",
         "2513",
         "2508",
         "2492"
        ],
        [
         "5",
         "META",
         "Success",
         "2513",
         "2508",
         "2492"
        ],
        [
         "6",
         "NVDA",
         "Success",
         "2513",
         "2508",
         "2492"
        ],
        [
         "7",
         "SPY",
         "Success",
         "2513",
         "2508",
         "2492"
        ],
        [
         "8",
         "V",
         "Success",
         "2513",
         "2508",
         "2492"
        ],
        [
         "9",
         "DIS",
         "Success",
         "2513",
         "2508",
         "2492"
        ],
        [
         "10",
         "NFLX",
         "Success",
         "2513",
         "2508",
         "2492"
        ],
        [
         "11",
         "PYPL",
         "Success",
         "2477",
         "2472",
         "2456"
        ],
        [
         "12",
         "BABA",
         "Success",
         "2513",
         "2508",
         "2492"
        ],
        [
         "13",
         "IBM",
         "Success",
         "2513",
         "2508",
         "2492"
        ],
        [
         "14",
         "AMD",
         "Success",
         "2512",
         "2507",
         "2491"
        ],
        [
         "15",
         "BA",
         "Success",
         "2513",
         "2508",
         "2492"
        ],
        [
         "16",
         "INTC",
         "Success",
         "2513",
         "2508",
         "2492"
        ],
        [
         "17",
         "T",
         "Success",
         "2513",
         "2508",
         "2492"
        ],
        [
         "18",
         "GS",
         "Success",
         "2513",
         "2508",
         "2492"
        ],
        [
         "19",
         "NKE",
         "Success",
         "2513",
         "2508",
         "2492"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 20
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock</th>\n",
       "      <th>status</th>\n",
       "      <th>day_rows</th>\n",
       "      <th>week_rows</th>\n",
       "      <th>month_rows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>Success</td>\n",
       "      <td>2513</td>\n",
       "      <td>2508</td>\n",
       "      <td>2492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>Success</td>\n",
       "      <td>2513</td>\n",
       "      <td>2508</td>\n",
       "      <td>2492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GOOG</td>\n",
       "      <td>Success</td>\n",
       "      <td>2513</td>\n",
       "      <td>2508</td>\n",
       "      <td>2492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>Success</td>\n",
       "      <td>2513</td>\n",
       "      <td>2508</td>\n",
       "      <td>2492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>Success</td>\n",
       "      <td>2513</td>\n",
       "      <td>2508</td>\n",
       "      <td>2492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>META</td>\n",
       "      <td>Success</td>\n",
       "      <td>2513</td>\n",
       "      <td>2508</td>\n",
       "      <td>2492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NVDA</td>\n",
       "      <td>Success</td>\n",
       "      <td>2513</td>\n",
       "      <td>2508</td>\n",
       "      <td>2492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SPY</td>\n",
       "      <td>Success</td>\n",
       "      <td>2513</td>\n",
       "      <td>2508</td>\n",
       "      <td>2492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>V</td>\n",
       "      <td>Success</td>\n",
       "      <td>2513</td>\n",
       "      <td>2508</td>\n",
       "      <td>2492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DIS</td>\n",
       "      <td>Success</td>\n",
       "      <td>2513</td>\n",
       "      <td>2508</td>\n",
       "      <td>2492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>Success</td>\n",
       "      <td>2513</td>\n",
       "      <td>2508</td>\n",
       "      <td>2492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PYPL</td>\n",
       "      <td>Success</td>\n",
       "      <td>2477</td>\n",
       "      <td>2472</td>\n",
       "      <td>2456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>BABA</td>\n",
       "      <td>Success</td>\n",
       "      <td>2513</td>\n",
       "      <td>2508</td>\n",
       "      <td>2492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>IBM</td>\n",
       "      <td>Success</td>\n",
       "      <td>2513</td>\n",
       "      <td>2508</td>\n",
       "      <td>2492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>AMD</td>\n",
       "      <td>Success</td>\n",
       "      <td>2512</td>\n",
       "      <td>2507</td>\n",
       "      <td>2491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>BA</td>\n",
       "      <td>Success</td>\n",
       "      <td>2513</td>\n",
       "      <td>2508</td>\n",
       "      <td>2492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>INTC</td>\n",
       "      <td>Success</td>\n",
       "      <td>2513</td>\n",
       "      <td>2508</td>\n",
       "      <td>2492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>T</td>\n",
       "      <td>Success</td>\n",
       "      <td>2513</td>\n",
       "      <td>2508</td>\n",
       "      <td>2492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>GS</td>\n",
       "      <td>Success</td>\n",
       "      <td>2513</td>\n",
       "      <td>2508</td>\n",
       "      <td>2492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NKE</td>\n",
       "      <td>Success</td>\n",
       "      <td>2513</td>\n",
       "      <td>2508</td>\n",
       "      <td>2492</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stock   status  day_rows  week_rows  month_rows\n",
       "0   AAPL  Success      2513       2508        2492\n",
       "1   MSFT  Success      2513       2508        2492\n",
       "2   GOOG  Success      2513       2508        2492\n",
       "3   AMZN  Success      2513       2508        2492\n",
       "4   TSLA  Success      2513       2508        2492\n",
       "5   META  Success      2513       2508        2492\n",
       "6   NVDA  Success      2513       2508        2492\n",
       "7    SPY  Success      2513       2508        2492\n",
       "8      V  Success      2513       2508        2492\n",
       "9    DIS  Success      2513       2508        2492\n",
       "10  NFLX  Success      2513       2508        2492\n",
       "11  PYPL  Success      2477       2472        2456\n",
       "12  BABA  Success      2513       2508        2492\n",
       "13   IBM  Success      2513       2508        2492\n",
       "14   AMD  Success      2512       2507        2491\n",
       "15    BA  Success      2513       2508        2492\n",
       "16  INTC  Success      2513       2508        2492\n",
       "17     T  Success      2513       2508        2492\n",
       "18    GS  Success      2513       2508        2492\n",
       "19   NKE  Success      2513       2508        2492"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Process all stocks and display results\n",
    "results_df = process_stocks_lstm()\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Verification\n",
    "\n",
    "Let's verify the structure of one example from each prediction period to ensure the data is correctly formatted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day prediction data sample for AAPL:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "date",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "close_scaled",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "next_day_close_scaled",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "price_up",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "4bdcf72e-054c-4c52-8ced-d9adb848319c",
       "rows": [
        [
         "0",
         "2015-05-13 00:00:00-04:00",
         "0.0318596036212941",
         "0.0346291898455336",
         "1"
        ],
        [
         "1",
         "2015-05-14 00:00:00-04:00",
         "0.0346291898455336",
         "0.0344595994694666",
         "0"
        ],
        [
         "2",
         "2015-05-15 00:00:00-04:00",
         "0.0344595994694666",
         "0.0357973019482735",
         "1"
        ],
        [
         "3",
         "2015-05-18 00:00:00-04:00",
         "0.0357973019482735",
         "0.0356842764163049",
         "0"
        ],
        [
         "4",
         "2015-05-19 00:00:00-04:00",
         "0.0356842764163049",
         "0.035674846271616",
         "0"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>close_scaled</th>\n",
       "      <th>next_day_close_scaled</th>\n",
       "      <th>price_up</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-05-13 00:00:00-04:00</td>\n",
       "      <td>0.031860</td>\n",
       "      <td>0.034629</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-05-14 00:00:00-04:00</td>\n",
       "      <td>0.034629</td>\n",
       "      <td>0.034460</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-05-15 00:00:00-04:00</td>\n",
       "      <td>0.034460</td>\n",
       "      <td>0.035797</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-05-18 00:00:00-04:00</td>\n",
       "      <td>0.035797</td>\n",
       "      <td>0.035684</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-05-19 00:00:00-04:00</td>\n",
       "      <td>0.035684</td>\n",
       "      <td>0.035675</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        date  close_scaled  next_day_close_scaled  price_up\n",
       "0  2015-05-13 00:00:00-04:00      0.031860               0.034629         1\n",
       "1  2015-05-14 00:00:00-04:00      0.034629               0.034460         0\n",
       "2  2015-05-15 00:00:00-04:00      0.034460               0.035797         1\n",
       "3  2015-05-18 00:00:00-04:00      0.035797               0.035684         0\n",
       "4  2015-05-19 00:00:00-04:00      0.035684               0.035675         0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Week prediction data sample for AAPL:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "date",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "close_scaled",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "next_week_close_scaled",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "price_up_week",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "ce33566d-ccae-4789-8878-eeae731216fe",
       "rows": [
        [
         "0",
         "2015-05-13 00:00:00-04:00",
         "0.0318596036212941",
         "0.0352490427902389",
         "1"
        ],
        [
         "1",
         "2015-05-14 00:00:00-04:00",
         "0.0346291898455336",
         "0.0357087515276012",
         "1"
        ],
        [
         "2",
         "2015-05-15 00:00:00-04:00",
         "0.0344595994694666",
         "0.0364190441267235",
         "1"
        ],
        [
         "3",
         "2015-05-18 00:00:00-04:00",
         "0.0357973019482735",
         "0.0363116542479192",
         "1"
        ],
        [
         "4",
         "2015-05-19 00:00:00-04:00",
         "0.0356842764163049",
         "0.0366828061549953",
         "1"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>close_scaled</th>\n",
       "      <th>next_week_close_scaled</th>\n",
       "      <th>price_up_week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-05-13 00:00:00-04:00</td>\n",
       "      <td>0.031860</td>\n",
       "      <td>0.035249</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-05-14 00:00:00-04:00</td>\n",
       "      <td>0.034629</td>\n",
       "      <td>0.035709</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-05-15 00:00:00-04:00</td>\n",
       "      <td>0.034460</td>\n",
       "      <td>0.036419</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-05-18 00:00:00-04:00</td>\n",
       "      <td>0.035797</td>\n",
       "      <td>0.036312</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-05-19 00:00:00-04:00</td>\n",
       "      <td>0.035684</td>\n",
       "      <td>0.036683</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        date  close_scaled  next_week_close_scaled  \\\n",
       "0  2015-05-13 00:00:00-04:00      0.031860                0.035249   \n",
       "1  2015-05-14 00:00:00-04:00      0.034629                0.035709   \n",
       "2  2015-05-15 00:00:00-04:00      0.034460                0.036419   \n",
       "3  2015-05-18 00:00:00-04:00      0.035797                0.036312   \n",
       "4  2015-05-19 00:00:00-04:00      0.035684                0.036683   \n",
       "\n",
       "   price_up_week  \n",
       "0              1  \n",
       "1              1  \n",
       "2              1  \n",
       "3              1  \n",
       "4              1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Month prediction data sample for AAPL:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "date",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "close_scaled",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "next_month_close_scaled",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "price_up_month",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "b6f233dd-d311-4a96-96e9-d1708e2eb53c",
       "rows": [
        [
         "0",
         "2015-05-13 00:00:00-04:00",
         "0.0318596036212941",
         "0.0353572392121461",
         "1"
        ],
        [
         "1",
         "2015-05-14 00:00:00-04:00",
         "0.0346291898455336",
         "0.0352661750018826",
         "1"
        ],
        [
         "2",
         "2015-05-15 00:00:00-04:00",
         "0.0344595994694666",
         "0.035213691708453",
         "1"
        ],
        [
         "3",
         "2015-05-18 00:00:00-04:00",
         "0.0357973019482735",
         "0.0350840500150776",
         "0"
        ],
        [
         "4",
         "2015-05-19 00:00:00-04:00",
         "0.0356842764163049",
         "0.0349858081816385",
         "0"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>close_scaled</th>\n",
       "      <th>next_month_close_scaled</th>\n",
       "      <th>price_up_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-05-13 00:00:00-04:00</td>\n",
       "      <td>0.031860</td>\n",
       "      <td>0.035357</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-05-14 00:00:00-04:00</td>\n",
       "      <td>0.034629</td>\n",
       "      <td>0.035266</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-05-15 00:00:00-04:00</td>\n",
       "      <td>0.034460</td>\n",
       "      <td>0.035214</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-05-18 00:00:00-04:00</td>\n",
       "      <td>0.035797</td>\n",
       "      <td>0.035084</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-05-19 00:00:00-04:00</td>\n",
       "      <td>0.035684</td>\n",
       "      <td>0.034986</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        date  close_scaled  next_month_close_scaled  \\\n",
       "0  2015-05-13 00:00:00-04:00      0.031860                 0.035357   \n",
       "1  2015-05-14 00:00:00-04:00      0.034629                 0.035266   \n",
       "2  2015-05-15 00:00:00-04:00      0.034460                 0.035214   \n",
       "3  2015-05-18 00:00:00-04:00      0.035797                 0.035084   \n",
       "4  2015-05-19 00:00:00-04:00      0.035684                 0.034986   \n",
       "\n",
       "   price_up_month  \n",
       "0               1  \n",
       "1               1  \n",
       "2               1  \n",
       "3               0  \n",
       "4               0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sample stock for verification\n",
    "sample_stock = \"AAPL\"\n",
    "\n",
    "try:\n",
    "    # Load samples from each prediction period\n",
    "    day_sample = pd.read_csv(os.path.join(output_folders['day'], f\"{sample_stock}_lstm_day.csv\"))\n",
    "    week_sample = pd.read_csv(os.path.join(output_folders['week'], f\"{sample_stock}_lstm_week.csv\"))\n",
    "    month_sample = pd.read_csv(os.path.join(output_folders['month'], f\"{sample_stock}_lstm_month.csv\"))\n",
    "    \n",
    "    # Display first few rows of each sample\n",
    "    print(f\"Day prediction data sample for {sample_stock}:\")\n",
    "    display(day_sample.head()[['date', 'close_scaled', 'next_day_close_scaled', 'price_up']])\n",
    "    \n",
    "    print(f\"\\nWeek prediction data sample for {sample_stock}:\")\n",
    "    display(week_sample.head()[['date', 'close_scaled', 'next_week_close_scaled', 'price_up_week']])\n",
    "    \n",
    "    print(f\"\\nMonth prediction data sample for {sample_stock}:\")\n",
    "    display(month_sample.head()[['date', 'close_scaled', 'next_month_close_scaled', 'price_up_month']])\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error during verification: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis\n",
    "\n",
    "Let's analyze the data to understand the difference between the different prediction targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_lstm_prediction_targets(stock):\n",
    "    \"\"\"Analyze and compare the different prediction targets for a given stock\"\"\"\n",
    "    try:\n",
    "        # Load data\n",
    "        day_data = pd.read_csv(os.path.join(output_folders['day'], f\"{stock}_lstm_day.csv\"))\n",
    "        week_data = pd.read_csv(os.path.join(output_folders['week'], f\"{stock}_lstm_week.csv\"))\n",
    "        month_data = pd.read_csv(os.path.join(output_folders['month'], f\"{stock}_lstm_month.csv\"))\n",
    "        \n",
    "        # Convert dates to datetime for consistent comparison\n",
    "        day_data['date'] = pd.to_datetime(day_data['date'])\n",
    "        week_data['date'] = pd.to_datetime(week_data['date'])\n",
    "        month_data['date'] = pd.to_datetime(month_data['date'])\n",
    "        \n",
    "        # Find common date range\n",
    "        start_date = max(day_data['date'].min(), week_data['date'].min(), month_data['date'].min())\n",
    "        end_date = min(day_data['date'].max(), week_data['date'].max(), month_data['date'].max())\n",
    "        \n",
    "        # Filter data to common date range\n",
    "        day_filtered = day_data[(day_data['date'] >= start_date) & (day_data['date'] <= end_date)]\n",
    "        week_filtered = week_data[(week_data['date'] >= start_date) & (week_data['date'] <= end_date)]\n",
    "        month_filtered = month_data[(month_data['date'] >= start_date) & (month_data['date'] <= end_date)]\n",
    "        \n",
    "        # Merge datasets on date to analyze relationships between targets\n",
    "        # First, select only necessary columns\n",
    "        day_slim = day_filtered[['date', 'close_scaled', 'next_day_close_scaled', 'price_up']]\n",
    "        week_slim = week_filtered[['date', 'next_week_close_scaled', 'price_up_week']]\n",
    "        month_slim = month_filtered[['date', 'next_month_close_scaled', 'price_up_month']]\n",
    "        \n",
    "        # Merge\n",
    "        merged = pd.merge(day_slim, week_slim, on='date')\n",
    "        merged = pd.merge(merged, month_slim, on='date')\n",
    "        \n",
    "        # Calculate statistics about the targets\n",
    "        stats = {\n",
    "            'day_mean': merged['next_day_close_scaled'].mean(),\n",
    "            'week_mean': merged['next_week_close_scaled'].mean(),\n",
    "            'month_mean': merged['next_month_close_scaled'].mean(),\n",
    "            'day_std': merged['next_day_close_scaled'].std(),\n",
    "            'week_std': merged['next_week_close_scaled'].std(),\n",
    "            'month_std': merged['next_month_close_scaled'].std(),\n",
    "            'day_week_corr': merged['next_day_close_scaled'].corr(merged['next_week_close_scaled']),\n",
    "            'day_month_corr': merged['next_day_close_scaled'].corr(merged['next_month_close_scaled']),\n",
    "            'week_month_corr': merged['next_week_close_scaled'].corr(merged['next_month_close_scaled']),\n",
    "            'price_up_day_pct': merged['price_up'].mean() * 100,\n",
    "            'price_up_week_pct': merged['price_up_week'].mean() * 100,\n",
    "            'price_up_month_pct': merged['price_up_month'].mean() * 100\n",
    "        }\n",
    "        \n",
    "        return stats\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing {stock}: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze a sample stock\n",
    "try:\n",
    "    sample_analysis = analyze_lstm_prediction_targets(\"AAPL\")\n",
    "    if sample_analysis:\n",
    "        pd.DataFrame([sample_analysis]).T.rename(columns={0: 'Value'})\n",
    "    else:\n",
    "        print(\"Analysis failed or no data available.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Analysis\n",
    "\n",
    "Let's examine the differences in features between the three datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_feature_distributions(stock):\n",
    "    \"\"\"Compare the distribution of features across the three prediction datasets\"\"\"\n",
    "    try:\n",
    "        # Load data\n",
    "        day_data = pd.read_csv(os.path.join(output_folders['day'], f\"{stock}_lstm_day.csv\"))\n",
    "        week_data = pd.read_csv(os.path.join(output_folders['week'], f\"{stock}_lstm_week.csv\"))\n",
    "        month_data = pd.read_csv(os.path.join(output_folders['month'], f\"{stock}_lstm_month.csv\"))\n",
    "        \n",
    "        # Get common numeric features to compare (excluding target variables and non-numeric columns)\n",
    "        numeric_cols = [col for col in day_data.columns if \n",
    "                        col in week_data.columns and \n",
    "                        col in month_data.columns and\n",
    "                        pd.api.types.is_numeric_dtype(day_data[col]) and\n",
    "                        'next_' not in col and\n",
    "                        'price_up' not in col and\n",
    "                        col not in ['date']]\n",
    "        \n",
    "        # Create a summary of distribution differences\n",
    "        summary = {}\n",
    "        for col in numeric_cols[:10]:  # Limit to first 10 features to avoid information overload\n",
    "            summary[col] = {\n",
    "                'day_mean': day_data[col].mean(),\n",
    "                'week_mean': week_data[col].mean(),\n",
    "                'month_mean': month_data[col].mean(),\n",
    "                'day_std': day_data[col].std(),\n",
    "                'week_std': week_data[col].std(),\n",
    "                'month_std': month_data[col].std()\n",
    "            }\n",
    "        \n",
    "        return pd.DataFrame(summary).T\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error comparing features for {stock}: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare feature distributions for a sample stock\n",
    "try:\n",
    "    feature_comparison = compare_feature_distributions(\"AAPL\")\n",
    "    if feature_comparison is not None:\n",
    "        display(feature_comparison)\n",
    "    else:\n",
    "        print(\"Feature comparison failed or no data available.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook has successfully prepared stock data for prediction using LSTM models for three different time periods:\n",
    "\n",
    "1. Next day close price (daily prediction)\n",
    "2. Next week average close price (weekly prediction)\n",
    "3. Next month average close price (monthly prediction)\n",
    "\n",
    "For each stock, we've created three separate datasets specifically formatted for each prediction period. The data has been saved in the following folders:\n",
    "\n",
    "- `data/lstm/day/` - Contains data for next-day predictions\n",
    "- `data/lstm/week/` - Contains data for next-week predictions\n",
    "- `data/lstm/month/` - Contains data for next-month predictions\n",
    "\n",
    "Each file follows the naming convention: `stockname_lstm_period.csv` where period is day, week, or month.\n",
    "\n",
    "The key differences between the datasets are:\n",
    "\n",
    "1. Day prediction: Uses `next_day_close_scaled` as the target\n",
    "2. Week prediction: Creates and uses `next_week_close_scaled` (average of next 5 days) as the target\n",
    "3. Month prediction: Creates and uses `next_month_close_scaled` (average of next 21 days) as the target\n",
    "\n",
    "Additionally, each dataset contains a binary indicator for whether the price goes up in the respective prediction period."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
