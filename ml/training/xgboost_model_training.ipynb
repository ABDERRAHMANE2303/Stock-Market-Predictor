{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock Price Prediction Data Preparation for XGBoost\n",
    "\n",
    "This notebook prepares stock data for prediction using XGBoost models for three different time periods:\n",
    "1. Next day close price\n",
    "2. Next week average close price\n",
    "3. Next month average close price\n",
    "\n",
    "For each stock, we'll create three separate datasets specifically formatted for each prediction period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of stock symbols\n",
    "stocks = [\"AAPL\", \"MSFT\", \"GOOG\", \"AMZN\", \"TSLA\", \n",
    "          \"META\", \"NVDA\", \"SPY\", \"V\", \"DIS\",\n",
    "          \"NFLX\", \"PYPL\", \"BABA\", \"IBM\", \"AMD\",\n",
    "          \"BA\", \"INTC\", \"T\", \"GS\", \"NKE\"]\n",
    "\n",
    "# Path to the project root\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"../..\"))\n",
    "\n",
    "# Paths for input and output data\n",
    "input_folder = os.path.join(project_root, \"data\", \"xgboost\",\"initial\")\n",
    "output_base_folder = os.path.join(project_root, \"data\", \"xgboost\")\n",
    "\n",
    "# Create output folders for each prediction period\n",
    "output_folders = {\n",
    "    'day': os.path.join(output_base_folder, \"day\"),\n",
    "    'week': os.path.join(output_base_folder, \"week\"),\n",
    "    'month': os.path.join(output_base_folder, \"month\")\n",
    "}\n",
    "\n",
    "# Ensure output directories exist\n",
    "for folder in output_folders.values():\n",
    "    os.makedirs(folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_daily_prediction_data(df, stock_symbol):\n",
    "    \"\"\"\n",
    "    Prepare data for next day close price prediction.\n",
    "    The next_day_close and next_day_close_original columns are already present.\n",
    "    \"\"\"\n",
    "    # Make a copy to avoid modifications to the original dataframe\n",
    "    daily_df = df.copy()\n",
    "    \n",
    "    # Rename target columns for clarity\n",
    "    daily_df = daily_df.rename(columns={\n",
    "        'next_day_close': 'target',\n",
    "        'next_day_close_original': 'target_original',\n",
    "        'pct_change_next_day': 'pct_change_target'\n",
    "    })\n",
    "    \n",
    "    # Drop rows with NaN target values (typically the last row)\n",
    "    daily_df = daily_df.dropna(subset=['target'])\n",
    "    \n",
    "    # Save to CSV\n",
    "    output_path = os.path.join(output_folders['day'], f\"{stock_symbol}_xgboost_day.csv\")\n",
    "    daily_df.to_csv(output_path, index=False)\n",
    "    \n",
    "    return output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_weekly_prediction_data(df, stock_symbol):\n",
    "    \"\"\"\n",
    "    Prepare data for next week average close price prediction.\n",
    "    We'll calculate the average close price for the next 5 trading days.\n",
    "    \"\"\"\n",
    "    # Make a copy to avoid modifications to the original dataframe\n",
    "    weekly_df = df.copy()\n",
    "    \n",
    "    # Calculate the average close price for the next 5 trading days\n",
    "    # First, get the original close prices (non-normalized)\n",
    "    close_original = weekly_df['close_original'].values\n",
    "    \n",
    "    # Initialize arrays for targets\n",
    "    next_week_close = np.full(len(weekly_df), np.nan)\n",
    "    next_week_close_original = np.full(len(weekly_df), np.nan)\n",
    "    pct_change_next_week = np.full(len(weekly_df), np.nan)\n",
    "    \n",
    "    # For each day, calculate the average of the next 5 trading days\n",
    "    for i in range(len(weekly_df) - 5):\n",
    "        next_week_close[i] = np.mean(weekly_df['close'].values[i+1:i+6])\n",
    "        next_week_close_original[i] = np.mean(close_original[i+1:i+6])\n",
    "        # Calculate percentage change from current close to next week average\n",
    "        pct_change_next_week[i] = (next_week_close_original[i] / close_original[i]) - 1\n",
    "    \n",
    "    # Add target columns\n",
    "    weekly_df['target'] = next_week_close\n",
    "    weekly_df['target_original'] = next_week_close_original\n",
    "    weekly_df['pct_change_target'] = pct_change_next_week\n",
    "    \n",
    "    # Create binary target for price movement direction\n",
    "    weekly_df['price_up'] = (weekly_df['pct_change_target'] > 0).astype(int)\n",
    "    \n",
    "    # Drop rows with NaN target values\n",
    "    weekly_df = weekly_df.dropna(subset=['target'])\n",
    "    \n",
    "    # Save to CSV\n",
    "    output_path = os.path.join(output_folders['week'], f\"{stock_symbol}_xgboost_week.csv\")\n",
    "    weekly_df.to_csv(output_path, index=False)\n",
    "    \n",
    "    return output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_monthly_prediction_data(df, stock_symbol):\n",
    "    \"\"\"\n",
    "    Prepare data for next month average close price prediction.\n",
    "    We'll calculate the average close price for the next 21 trading days (approx. one month).\n",
    "    \"\"\"\n",
    "    # Make a copy to avoid modifications to the original dataframe\n",
    "    monthly_df = df.copy()\n",
    "    \n",
    "    # Calculate the average close price for the next 21 trading days\n",
    "    # First, get the original close prices (non-normalized)\n",
    "    close_original = monthly_df['close_original'].values\n",
    "    \n",
    "    # Initialize arrays for targets\n",
    "    next_month_close = np.full(len(monthly_df), np.nan)\n",
    "    next_month_close_original = np.full(len(monthly_df), np.nan)\n",
    "    pct_change_next_month = np.full(len(monthly_df), np.nan)\n",
    "    \n",
    "    # For each day, calculate the average of the next 21 trading days\n",
    "    for i in range(len(monthly_df) - 21):\n",
    "        next_month_close[i] = np.mean(monthly_df['close'].values[i+1:i+22])\n",
    "        next_month_close_original[i] = np.mean(close_original[i+1:i+22])\n",
    "        # Calculate percentage change from current close to next month average\n",
    "        pct_change_next_month[i] = (next_month_close_original[i] / close_original[i]) - 1\n",
    "    \n",
    "    # Add target columns\n",
    "    monthly_df['target'] = next_month_close\n",
    "    monthly_df['target_original'] = next_month_close_original\n",
    "    monthly_df['pct_change_target'] = pct_change_next_month\n",
    "    \n",
    "    # Create binary target for price movement direction\n",
    "    monthly_df['price_up'] = (monthly_df['pct_change_target'] > 0).astype(int)\n",
    "    \n",
    "    # Drop rows with NaN target values\n",
    "    monthly_df = monthly_df.dropna(subset=['target'])\n",
    "    \n",
    "    # Save to CSV\n",
    "    output_path = os.path.join(output_folders['month'], f\"{stock_symbol}_xgboost_month.csv\")\n",
    "    monthly_df.to_csv(output_path, index=False)\n",
    "    \n",
    "    return output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_stock(stock_symbol):\n",
    "    \"\"\"\n",
    "    Process a single stock symbol to create all three prediction datasets.\n",
    "    \"\"\"\n",
    "    print(f\"Processing {stock_symbol}...\")\n",
    "    \n",
    "    # Construct the input file path\n",
    "    input_file = os.path.join(input_folder, f\"{stock_symbol}_xgboost.csv\")\n",
    "    \n",
    "    # Check if the file exists\n",
    "    if not os.path.exists(input_file):\n",
    "        print(f\"Warning: {input_file} not found. Skipping {stock_symbol}.\")\n",
    "        return None\n",
    "    \n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(input_file, parse_dates=['date'])\n",
    "    \n",
    "    # Process data for each prediction period\n",
    "    daily_output = prepare_daily_prediction_data(df, stock_symbol)\n",
    "    weekly_output = prepare_weekly_prediction_data(df, stock_symbol)\n",
    "    monthly_output = prepare_monthly_prediction_data(df, stock_symbol)\n",
    "    \n",
    "    print(f\"Created prediction datasets for {stock_symbol}:\")\n",
    "    print(f\"  - Daily: {daily_output}\")\n",
    "    print(f\"  - Weekly: {weekly_output}\")\n",
    "    print(f\"  - Monthly: {monthly_output}\")\n",
    "    \n",
    "    return {\n",
    "        'day': daily_output,\n",
    "        'week': weekly_output,\n",
    "        'month': monthly_output\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing AAPL...\n",
      "Created prediction datasets for AAPL:\n",
      "  - Daily: /home/abderrahmane/Stock-Market-Predictor/data/xgboost/day/AAPL_xgboost_day.csv\n",
      "  - Weekly: /home/abderrahmane/Stock-Market-Predictor/data/xgboost/week/AAPL_xgboost_week.csv\n",
      "  - Monthly: /home/abderrahmane/Stock-Market-Predictor/data/xgboost/month/AAPL_xgboost_month.csv\n",
      "Processing MSFT...\n",
      "Created prediction datasets for MSFT:\n",
      "  - Daily: /home/abderrahmane/Stock-Market-Predictor/data/xgboost/day/MSFT_xgboost_day.csv\n",
      "  - Weekly: /home/abderrahmane/Stock-Market-Predictor/data/xgboost/week/MSFT_xgboost_week.csv\n",
      "  - Monthly: /home/abderrahmane/Stock-Market-Predictor/data/xgboost/month/MSFT_xgboost_month.csv\n",
      "Processing GOOG...\n",
      "Created prediction datasets for GOOG:\n",
      "  - Daily: /home/abderrahmane/Stock-Market-Predictor/data/xgboost/day/GOOG_xgboost_day.csv\n",
      "  - Weekly: /home/abderrahmane/Stock-Market-Predictor/data/xgboost/week/GOOG_xgboost_week.csv\n",
      "  - Monthly: /home/abderrahmane/Stock-Market-Predictor/data/xgboost/month/GOOG_xgboost_month.csv\n",
      "Processing AMZN...\n",
      "Created prediction datasets for AMZN:\n",
      "  - Daily: /home/abderrahmane/Stock-Market-Predictor/data/xgboost/day/AMZN_xgboost_day.csv\n",
      "  - Weekly: /home/abderrahmane/Stock-Market-Predictor/data/xgboost/week/AMZN_xgboost_week.csv\n",
      "  - Monthly: /home/abderrahmane/Stock-Market-Predictor/data/xgboost/month/AMZN_xgboost_month.csv\n",
      "Processing TSLA...\n",
      "Created prediction datasets for TSLA:\n",
      "  - Daily: /home/abderrahmane/Stock-Market-Predictor/data/xgboost/day/TSLA_xgboost_day.csv\n",
      "  - Weekly: /home/abderrahmane/Stock-Market-Predictor/data/xgboost/week/TSLA_xgboost_week.csv\n",
      "  - Monthly: /home/abderrahmane/Stock-Market-Predictor/data/xgboost/month/TSLA_xgboost_month.csv\n",
      "Processing META...\n",
      "Created prediction datasets for META:\n",
      "  - Daily: /home/abderrahmane/Stock-Market-Predictor/data/xgboost/day/META_xgboost_day.csv\n",
      "  - Weekly: /home/abderrahmane/Stock-Market-Predictor/data/xgboost/week/META_xgboost_week.csv\n",
      "  - Monthly: /home/abderrahmane/Stock-Market-Predictor/data/xgboost/month/META_xgboost_month.csv\n",
      "Processing NVDA...\n",
      "Created prediction datasets for NVDA:\n",
      "  - Daily: /home/abderrahmane/Stock-Market-Predictor/data/xgboost/day/NVDA_xgboost_day.csv\n",
      "  - Weekly: /home/abderrahmane/Stock-Market-Predictor/data/xgboost/week/NVDA_xgboost_week.csv\n",
      "  - Monthly: /home/abderrahmane/Stock-Market-Predictor/data/xgboost/month/NVDA_xgboost_month.csv\n",
      "Processing SPY...\n",
      "Created prediction datasets for SPY:\n",
      "  - Daily: /home/abderrahmane/Stock-Market-Predictor/data/xgboost/day/SPY_xgboost_day.csv\n",
      "  - Weekly: /home/abderrahmane/Stock-Market-Predictor/data/xgboost/week/SPY_xgboost_week.csv\n",
      "  - Monthly: /home/abderrahmane/Stock-Market-Predictor/data/xgboost/month/SPY_xgboost_month.csv\n",
      "Processing V...\n",
      "Created prediction datasets for V:\n",
      "  - Daily: /home/abderrahmane/Stock-Market-Predictor/data/xgboost/day/V_xgboost_day.csv\n",
      "  - Weekly: /home/abderrahmane/Stock-Market-Predictor/data/xgboost/week/V_xgboost_week.csv\n",
      "  - Monthly: /home/abderrahmane/Stock-Market-Predictor/data/xgboost/month/V_xgboost_month.csv\n",
      "Processing DIS...\n",
      "Created prediction datasets for DIS:\n",
      "  - Daily: /home/abderrahmane/Stock-Market-Predictor/data/xgboost/day/DIS_xgboost_day.csv\n",
      "  - Weekly: /home/abderrahmane/Stock-Market-Predictor/data/xgboost/week/DIS_xgboost_week.csv\n",
      "  - Monthly: /home/abderrahmane/Stock-Market-Predictor/data/xgboost/month/DIS_xgboost_month.csv\n",
      "Processing NFLX...\n",
      "Created prediction datasets for NFLX:\n",
      "  - Daily: /home/abderrahmane/Stock-Market-Predictor/data/xgboost/day/NFLX_xgboost_day.csv\n",
      "  - Weekly: /home/abderrahmane/Stock-Market-Predictor/data/xgboost/week/NFLX_xgboost_week.csv\n",
      "  - Monthly: /home/abderrahmane/Stock-Market-Predictor/data/xgboost/month/NFLX_xgboost_month.csv\n",
      "Processing PYPL...\n",
      "Created prediction datasets for PYPL:\n",
      "  - Daily: /home/abderrahmane/Stock-Market-Predictor/data/xgboost/day/PYPL_xgboost_day.csv\n",
      "  - Weekly: /home/abderrahmane/Stock-Market-Predictor/data/xgboost/week/PYPL_xgboost_week.csv\n",
      "  - Monthly: /home/abderrahmane/Stock-Market-Predictor/data/xgboost/month/PYPL_xgboost_month.csv\n",
      "Processing BABA...\n",
      "Created prediction datasets for BABA:\n",
      "  - Daily: /home/abderrahmane/Stock-Market-Predictor/data/xgboost/day/BABA_xgboost_day.csv\n",
      "  - Weekly: /home/abderrahmane/Stock-Market-Predictor/data/xgboost/week/BABA_xgboost_week.csv\n",
      "  - Monthly: /home/abderrahmane/Stock-Market-Predictor/data/xgboost/month/BABA_xgboost_month.csv\n",
      "Processing IBM...\n",
      "Created prediction datasets for IBM:\n",
      "  - Daily: /home/abderrahmane/Stock-Market-Predictor/data/xgboost/day/IBM_xgboost_day.csv\n",
      "  - Weekly: /home/abderrahmane/Stock-Market-Predictor/data/xgboost/week/IBM_xgboost_week.csv\n",
      "  - Monthly: /home/abderrahmane/Stock-Market-Predictor/data/xgboost/month/IBM_xgboost_month.csv\n",
      "Processing AMD...\n",
      "Created prediction datasets for AMD:\n",
      "  - Daily: /home/abderrahmane/Stock-Market-Predictor/data/xgboost/day/AMD_xgboost_day.csv\n",
      "  - Weekly: /home/abderrahmane/Stock-Market-Predictor/data/xgboost/week/AMD_xgboost_week.csv\n",
      "  - Monthly: /home/abderrahmane/Stock-Market-Predictor/data/xgboost/month/AMD_xgboost_month.csv\n",
      "Processing BA...\n",
      "Created prediction datasets for BA:\n",
      "  - Daily: /home/abderrahmane/Stock-Market-Predictor/data/xgboost/day/BA_xgboost_day.csv\n",
      "  - Weekly: /home/abderrahmane/Stock-Market-Predictor/data/xgboost/week/BA_xgboost_week.csv\n",
      "  - Monthly: /home/abderrahmane/Stock-Market-Predictor/data/xgboost/month/BA_xgboost_month.csv\n",
      "Processing INTC...\n",
      "Created prediction datasets for INTC:\n",
      "  - Daily: /home/abderrahmane/Stock-Market-Predictor/data/xgboost/day/INTC_xgboost_day.csv\n",
      "  - Weekly: /home/abderrahmane/Stock-Market-Predictor/data/xgboost/week/INTC_xgboost_week.csv\n",
      "  - Monthly: /home/abderrahmane/Stock-Market-Predictor/data/xgboost/month/INTC_xgboost_month.csv\n",
      "Processing T...\n",
      "Created prediction datasets for T:\n",
      "  - Daily: /home/abderrahmane/Stock-Market-Predictor/data/xgboost/day/T_xgboost_day.csv\n",
      "  - Weekly: /home/abderrahmane/Stock-Market-Predictor/data/xgboost/week/T_xgboost_week.csv\n",
      "  - Monthly: /home/abderrahmane/Stock-Market-Predictor/data/xgboost/month/T_xgboost_month.csv\n",
      "Processing GS...\n",
      "Created prediction datasets for GS:\n",
      "  - Daily: /home/abderrahmane/Stock-Market-Predictor/data/xgboost/day/GS_xgboost_day.csv\n",
      "  - Weekly: /home/abderrahmane/Stock-Market-Predictor/data/xgboost/week/GS_xgboost_week.csv\n",
      "  - Monthly: /home/abderrahmane/Stock-Market-Predictor/data/xgboost/month/GS_xgboost_month.csv\n",
      "Processing NKE...\n",
      "Created prediction datasets for NKE:\n",
      "  - Daily: /home/abderrahmane/Stock-Market-Predictor/data/xgboost/day/NKE_xgboost_day.csv\n",
      "  - Weekly: /home/abderrahmane/Stock-Market-Predictor/data/xgboost/week/NKE_xgboost_week.csv\n",
      "  - Monthly: /home/abderrahmane/Stock-Market-Predictor/data/xgboost/month/NKE_xgboost_month.csv\n"
     ]
    }
   ],
   "source": [
    "# Process all stocks\n",
    "results = {}\n",
    "for stock in stocks:\n",
    "    results[stock] = process_stock(stock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Summary:\n",
      "Total stocks processed: 20\n",
      "Failed to process: 0\n"
     ]
    }
   ],
   "source": [
    "# Print summary\n",
    "print(\"\\nProcessing Summary:\")\n",
    "print(f\"Total stocks processed: {len([r for r in results.values() if r is not None])}\")\n",
    "print(f\"Failed to process: {len([r for r in results.values() if r is None])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_datasets():\n",
    "    \"\"\"\n",
    "    Validate the created datasets to ensure they have the expected structure.\n",
    "    \"\"\"\n",
    "    print(\"\\nValidating datasets...\")\n",
    "    \n",
    "    for period in ['day', 'week', 'month']:\n",
    "        folder = output_folders[period]\n",
    "        files = os.listdir(folder)\n",
    "        if not files:\n",
    "            print(f\"Warning: No files found in {folder}\")\n",
    "            continue\n",
    "            \n",
    "        # Check the first file as a sample\n",
    "        sample_file = os.path.join(folder, files[0])\n",
    "        sample_df = pd.read_csv(sample_file)\n",
    "        \n",
    "        # Check for required columns\n",
    "        required_cols = ['date', 'target', 'target_original', 'pct_change_target', 'price_up']\n",
    "        missing = [col for col in required_cols if col not in sample_df.columns]\n",
    "        \n",
    "        if missing:\n",
    "            print(f\"Warning: {period} datasets are missing columns: {missing}\")\n",
    "        else:\n",
    "            print(f\"{period} datasets validation passed!\")\n",
    "            print(f\"  - Sample file: {files[0]}\")\n",
    "            print(f\"  - Row count: {len(sample_df)}\")\n",
    "            print(f\"  - Target mean: {sample_df['target'].mean():.4f}\")\n",
    "    \n",
    "    print(\"\\nValidation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validating datasets...\n",
      "day datasets validation passed!\n",
      "  - Sample file: V_xgboost_day.csv\n",
      "  - Row count: 2513\n",
      "  - Target mean: 173.3284\n",
      "week datasets validation passed!\n",
      "  - Sample file: NKE_xgboost_week.csv\n",
      "  - Row count: 2508\n",
      "  - Target mean: 0.0023\n",
      "month datasets validation passed!\n",
      "  - Sample file: AMD_xgboost_month.csv\n",
      "  - Row count: 2491\n",
      "  - Target mean: 0.0024\n",
      "\n",
      "Validation complete!\n"
     ]
    }
   ],
   "source": [
    "# Run validation\n",
    "validate_datasets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Analysis\n",
    "\n",
    "Let's examine a sample of the generated datasets to confirm they're structured correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample analysis for AAPL:\n",
      "\n",
      "Day prediction dataset:\n",
      "  - Shape: (2513, 38)\n",
      "  - Date range: 2015-05-13 04:00:00+00:00 to 2025-05-08 04:00:00+00:00\n",
      "  - Percent of price increases: 52.96%\n",
      "\n",
      "Sample rows:\n",
      "                       date  close_original  target_original  \\\n",
      "0 2015-05-13 04:00:00+00:00       28.259068        28.918398   \n",
      "1 2015-05-14 04:00:00+00:00       28.918398        28.878025   \n",
      "2 2015-05-15 04:00:00+00:00       28.878025        29.196480   \n",
      "3 2015-05-18 04:00:00+00:00       29.196480        29.169573   \n",
      "4 2015-05-19 04:00:00+00:00       29.169573        29.167328   \n",
      "\n",
      "   pct_change_target  price_up  \n",
      "0          -0.001396         1  \n",
      "1           0.011028         0  \n",
      "2          -0.000922         1  \n",
      "3          -0.000077         0  \n",
      "4           0.010226         0  \n",
      "\n",
      "Week prediction dataset:\n",
      "  - Shape: (2508, 41)\n",
      "  - Date range: 2015-05-13 04:00:00+00:00 to 2025-05-01 04:00:00+00:00\n",
      "  - Percent of price increases: 57.58%\n",
      "\n",
      "Sample rows:\n",
      "                       date  close_original  target_original  \\\n",
      "0 2015-05-13 04:00:00+00:00       28.259068        29.065961   \n",
      "1 2015-05-14 04:00:00+00:00       28.918398        29.175399   \n",
      "2 2015-05-15 04:00:00+00:00       28.878025        29.344492   \n",
      "3 2015-05-18 04:00:00+00:00       29.196480        29.318927   \n",
      "4 2015-05-19 04:00:00+00:00       29.169573        29.407284   \n",
      "\n",
      "   pct_change_target  price_up  \n",
      "0           0.028553         1  \n",
      "1           0.008887         1  \n",
      "2           0.016153         1  \n",
      "3           0.004194         1  \n",
      "4           0.008149         1  \n",
      "\n",
      "Month prediction dataset:\n",
      "  - Shape: (2492, 41)\n",
      "  - Date range: 2015-05-13 04:00:00+00:00 to 2025-04-08 04:00:00+00:00\n",
      "  - Percent of price increases: 61.96%\n",
      "\n",
      "Sample rows:\n",
      "                       date  close_original  target_original  \\\n",
      "0 2015-05-13 04:00:00+00:00       28.259068        29.091718   \n",
      "1 2015-05-14 04:00:00+00:00       28.918398        29.070039   \n",
      "2 2015-05-15 04:00:00+00:00       28.878025        29.057545   \n",
      "3 2015-05-18 04:00:00+00:00       29.196480        29.026682   \n",
      "4 2015-05-19 04:00:00+00:00       29.169573        29.003295   \n",
      "\n",
      "   pct_change_target  price_up  \n",
      "0           0.029465         1  \n",
      "1           0.005244         1  \n",
      "2           0.006216         1  \n",
      "3          -0.005816         0  \n",
      "4          -0.005700         0  \n"
     ]
    }
   ],
   "source": [
    "# Try to load and display samples from each time period if available\n",
    "try:\n",
    "    # Get first available stock\n",
    "    available_stocks = [stock for stock in stocks if results.get(stock) is not None]\n",
    "    if available_stocks:\n",
    "        sample_stock = available_stocks[0]\n",
    "        \n",
    "        print(f\"Sample analysis for {sample_stock}:\")\n",
    "        \n",
    "        # Load samples from each period\n",
    "        for period in ['day', 'week', 'month']:\n",
    "            file_path = os.path.join(output_folders[period], f\"{sample_stock}_xgboost_{period}.csv\")\n",
    "            if os.path.exists(file_path):\n",
    "                df = pd.read_csv(file_path, parse_dates=['date'])\n",
    "                print(f\"\\n{period.capitalize()} prediction dataset:\")\n",
    "                print(f\"  - Shape: {df.shape}\")\n",
    "                print(f\"  - Date range: {df['date'].min()} to {df['date'].max()}\")\n",
    "                print(f\"  - Percent of price increases: {df['price_up'].mean()*100:.2f}%\")\n",
    "                print(\"\\nSample rows:\")\n",
    "                print(df[['date', 'close_original', 'target_original', 'pct_change_target', 'price_up']].head())\n",
    "    else:\n",
    "        print(\"No processed stocks available for sample analysis.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during sample analysis: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
