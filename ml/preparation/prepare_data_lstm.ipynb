{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation for LSTM Model\n",
    "\n",
    "This notebook prepares the cleaned stock data for use with the LSTM model. LSTM requires sequential data formatted in a specific way:\n",
    "- Input sequences of fixed length (lookback window)\n",
    "- Data scaled to a consistent range (typically 0-1)\n",
    "- Target values for each sequence\n",
    "\n",
    "We'll process each of the 20 stock datasets and save them in the appropriate format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define Stock List and Data Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "source": [
    "# List of stock symbols\n",
    "stocks = [\"AAPL\", \"MSFT\", \"GOOG\", \"AMZN\", \"TSLA\", \n",
    "          \"META\", \"NVDA\", \"SPY\", \"V\", \"DIS\",\n",
    "          \"NFLX\", \"PYPL\", \"BABA\", \"IBM\", \"AMD\",\n",
    "          \"BA\", \"INTC\", \"T\", \"GS\", \"NKE\"]\n",
    "\n",
    "# Paths for input and output data\n",
    "input_folder = \"data/cleaned\"\n",
    "output_folder = \"data/lstm\"\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(output_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. LSTM Data Preparation Function\n",
    "\n",
    "For LSTM, we need to:\n",
    "1. Select relevant features\n",
    "2. Scale all features to a consistent range (0-1)\n",
    "3. Include date information for reference, although it won't be used in the model directly\n",
    "4. Add both next-day price and binary direction (up/down) targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "source": [
    "def prepare_lstm_data(df):\n",
    "    \"\"\"\n",
    "    Prepare stock data for LSTM model.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: Cleaned dataframe with stock data\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame formatted for LSTM\n",
    "    \"\"\"\n",
    "    # Create a copy to avoid modifying the original\n",
    "    lstm_df = df.copy()\n",
    "    \n",
    "    # Ensure date is in datetime format\n",
    "    lstm_df['date'] = pd.to_datetime(lstm_df['date'])\n",
    "    \n",
    "    # Select features to use for LSTM\n",
    "    feature_columns = [\n",
    "        'open',\n",
    "        'high',\n",
    "        'low',\n",
    "        'close',\n",
    "        'volume',\n",
    "        'return',\n",
    "        'ma5',\n",
    "        'ma20',\n",
    "        'ma50',\n",
    "        'volatility',\n",
    "        'volume_ma20',\n",
    "        'day_of_week',\n",
    "        'month',\n",
    "    ]\n",
    "    \n",
    "    # Filter features to those that exist in the dataset\n",
    "    features = [col for col in feature_columns if col in lstm_df.columns]\n",
    "    \n",
    "    # Create a separate dataframe for scaling\n",
    "    scaling_df = lstm_df[features].copy()\n",
    "    \n",
    "    # Initialize scaler\n",
    "    scaler = MinMaxScaler()\n",
    "    \n",
    "    # Scale the features\n",
    "    scaled_features = scaler.fit_transform(scaling_df)\n",
    "    \n",
    "    # Convert back to dataframe with proper column names\n",
    "    scaled_df = pd.DataFrame(scaled_features, columns=[f\"{col}_scaled\" for col in features])\n",
    "    \n",
    "    # Add date column back\n",
    "    scaled_df['date'] = lstm_df['date'].values\n",
    "    \n",
    "    # Add target variables\n",
    "    if 'next_day_close' in lstm_df.columns:\n",
    "        scaled_df['next_day_close'] = lstm_df['next_day_close']\n",
    "        \n",
    "        # Create a scaler just for the closing price\n",
    "        close_scaler = MinMaxScaler()\n",
    "        close_values = lstm_df[['close']].values\n",
    "        close_scaler.fit(close_values)\n",
    "        \n",
    "        # Scale next day close\n",
    "        next_day_values = lstm_df[['next_day_close']].values\n",
    "        scaled_df['next_day_close_scaled'] = close_scaler.transform(next_day_values).flatten()\n",
    "    \n",
    "    # Add price direction (binary classification target)\n",
    "    if 'price_up' in lstm_df.columns:\n",
    "        scaled_df['price_up'] = lstm_df['price_up']\n",
    "    \n",
    "    # Add scaler parameters as metadata columns (for inverse scaling later)\n",
    "    # We'll add min and max for each feature\n",
    "    for i, feature in enumerate(features):\n",
    "        scaled_df[f\"{feature}_min\"] = scaler.data_min_[i]\n",
    "        scaled_df[f\"{feature}_max\"] = scaler.data_max_[i]\n",
    "    \n",
    "    # Add close_scaler parameters (most important for predictions)\n",
    "    if 'next_day_close' in lstm_df.columns:\n",
    "        scaled_df['close_min'] = close_scaler.data_min_[0]\n",
    "        scaled_df['close_max'] = close_scaler.data_max_[0]\n",
    "    \n",
    "    return scaled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Process Each Stock and Save LSTM Format Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "source": [
    "results_summary = []\n",
    "\n",
    "for stock in stocks:\n",
    "    try:\n",
    "        # Input file path\n",
    "        input_file = f\"{input_folder}/{stock}_cleaned.csv\"\n",
    "        \n",
    "        # Check if file exists\n",
    "        if not os.path.exists(input_file):\n",
    "            print(f\"Warning: {input_file} does not exist. Skipping {stock}.\")\n",
    "            continue\n",
    "        \n",
    "        # Read cleaned data\n",
    "        df = pd.read_csv(input_file)\n",
    "        \n",
    "        # Prepare data for LSTM\n",
    "        lstm_df = prepare_lstm_data(df)\n",
    "        \n",
    "        # Output file path\n",
    "        output_file = f\"{output_folder}/{stock}_lstm.csv\"\n",
    "        \n",
    "        # Save to CSV\n",
    "        lstm_df.to_csv(output_file, index=False)\n",
    "        \n",
    "        # Collect summary statistics\n",
    "        summary = {\n",
    "            'stock': stock,\n",
    "            'rows': len(lstm_df),\n",
    "            'features': int((len(lstm_df.columns) - lstm_df.columns.str.contains('_min|_max|date|next_day|price_up').sum()) / 2),  # Divide by 2 because of _scaled columns\n",
    "            'start_date': lstm_df['date'].min().strftime('%Y-%m-%d') if isinstance(lstm_df['date'].iloc[0], pd.Timestamp) else pd.to_datetime(lstm_df['date'].min()).strftime('%Y-%m-%d'),\n",
    "            'end_date': lstm_df['date'].max().strftime('%Y-%m-%d') if isinstance(lstm_df['date'].iloc[0], pd.Timestamp) else pd.to_datetime(lstm_df['date'].max()).strftime('%Y-%m-%d'),\n",
    "            'file_size_kb': round(os.path.getsize(output_file) / 1024, 2)\n",
    "        }\n",
    "        \n",
    "        results_summary.append(summary)\n",
    "        print(f\"Processed {stock}: {len(lstm_df)} rows saved to {output_file}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {stock}: {str(e)}\")\n",
    "\n",
    "# Create a summary DataFrame\n",
    "summary_df = pd.DataFrame(results_summary)\n",
    "print(\"\\nData preparation for LSTM completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Display Summary of Prepared Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "source": [
    "# Display summary table\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Examine a Sample Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "source": [
    "# Load sample dataset (AAPL)\n",
    "sample_file = f\"{output_folder}/AAPL_lstm.csv\"\n",
    "if os.path.exists(sample_file):\n",
    "    sample_df = pd.read_csv(sample_file)\n",
    "    print(f\"Sample from AAPL_lstm.csv (First 5 rows):\")\n",
    "    \n",
    "    # Show first few rows (limited columns for readability)\n",
    "    display_cols = [col for col in sample_df.columns if 'min' not in col and 'max' not in col][:10]  # First 10 non-min/max columns\n",
    "    display_cols.append('price_up')  # Add target\n",
    "    display(sample_df[display_cols].head())\n",
    "    \n",
    "    # Plot the scaled closing prices\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sample_df['date'] = pd.to_datetime(sample_df['date'])\n",
    "    \n",
    "    if 'close_scaled' in sample_df.columns:\n",
    "        plt.plot(sample_df['date'], sample_df['close_scaled'], label='Scaled Close')\n",
    "        plt.title('AAPL Scaled Stock Price')\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Scaled Value (0-1)')\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"Sample file not found. Please run the data preparation first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Helper Function to Create LSTM Sequences\n",
    "\n",
    "This function shows how to create the input sequences for LSTM models from the prepared data. This will be used in the training notebook but is included here for reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "source": [
    "def create_sequences(df, feature_cols, target_col, sequence_length=60):\n",
    "    \"\"\"\n",
    "    Create sequences for LSTM training from prepared data.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: Prepared DataFrame with scaled features\n",
    "    - feature_cols: List of feature column names to use\n",
    "    - target_col: Name of the target column\n",
    "    - sequence_length: Number of time steps in each sequence\n",
    "    \n",
    "    Returns:\n",
    "    - X: Input sequences (3D array)\n",
    "    - y: Target values\n",
    "    \"\"\"\n",
    "    # Extract feature and target data\n",
    "    data = df[feature_cols].values\n",
    "    target = df[target_col].values\n",
    "    \n",
    "    X, y = [], []\n",
    "    \n",
    "    # Create sequences\n",
    "    for i in range(len(data) - sequence_length):\n",
    "        X.append(data[i:i + sequence_length])\n",
    "        y.append(target[i + sequence_length])\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "# Example usage (commented out)\n",
    "\"\"\"\n",
    "# Example for when you're building the LSTM model:\n",
    "if os.path.exists(sample_file):\n",
    "    # Get all scaled feature columns\n",
    "    feature_cols = [col for col in sample_df.columns if col.endswith('_scaled') and col != 'next_day_close_scaled']\n",
    "    \n",
    "    # Create sequences for regression (predict next day price)\n",
    "    X_price, y_price = create_sequences(sample_df, feature_cols, 'next_day_close_scaled', sequence_length=30)\n",
    "    print(f\"Regression sequences shape: {X_price.shape}, Target shape: {y_price.shape}\")\n",
    "    \n",
    "    # Create sequences for classification (predict direction)\n",
    "    X_dir, y_dir = create_sequences(sample_df, feature_cols, 'price_up', sequence_length=30)\n",
    "    print(f\"Classification sequences shape: {X_dir.shape}, Target shape: {y_dir.shape}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Data Ready for LSTM\n",
    "\n",
    "Our data is now ready for training LSTM models. The prepared datasets include:\n",
    "\n",
    "1. Scaled features (using MinMaxScaler)\n",
    "2. Date information for reference\n",
    "3. Next day price information (both raw and scaled)\n",
    "4. Price direction binary target (0/1)\n",
    "5. Scaling parameters (min/max) for each feature to use for inverse scaling predictions\n",
    "\n",
    "The data is saved in the `/data/lstm/` directory with filenames like `STOCK_lstm.csv`.\n",
    "\n",
    "In the LSTM model training notebook, we'll use the `create_sequences` function to generate the input sequences needed for training."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}