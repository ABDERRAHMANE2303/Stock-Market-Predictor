{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock Data Preparation for LSTM Models\n",
    "\n",
    "## Objective\n",
    "This notebook prepares data from cleaned stock CSVs specifically for training LSTM models. For each stock, we prepare 3 separate datasets for predicting:\n",
    "- Next day price direction (up/down)\n",
    "- Next week price direction (up/down)\n",
    "- Next month price direction (up/down)\n",
    "\n",
    "## Input\n",
    "- Cleaned stock CSVs from `../data/cleaned/{stock}.csv`\n",
    "\n",
    "## Output\n",
    "- Processed datasets ready for LSTM at `../data/lstm/{period}/{stock}_lstm_{period}.csv`\n",
    "  - Where period is one of: 'day', 'week', 'month'\n",
    "\n",
    "## Steps\n",
    "1. Import libraries and define functions\n",
    "2. Select and engineer features suitable for LSTM\n",
    "3. Create sequences of data for time series input\n",
    "4. Scale features appropriately\n",
    "5. Split data into train/validation\n",
    "6. Save prepared datasets\n",
    "7. Perform quality checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "np.set_printoptions(precision=3, suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define Important Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data, seq_length):\n",
    "    \"\"\"\n",
    "    Create sequences of data with a specific length for LSTM input.\n",
    "    \n",
    "    Parameters:\n",
    "    - data: DataFrame with features\n",
    "    - seq_length: Number of time steps in each sequence\n",
    "    \n",
    "    Returns:\n",
    "    - X: numpy array of sequences (samples, seq_length, features)\n",
    "    - y: numpy array of target values\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    # Extract features and target\n",
    "    features = data.drop('target', axis=1).values\n",
    "    targets = data['target'].values\n",
    "    \n",
    "    # Create sequences\n",
    "    for i in range(len(features) - seq_length):\n",
    "        X.append(features[i:i+seq_length])\n",
    "        y.append(targets[i+seq_length])\n",
    "        \n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_features_by_target_correlation(df, corr_threshold=0.8):\n",
    "    \"\"\"\n",
    "    Select features based on correlation with target while removing multicollinearity.\n",
    "    \n",
    "    For each group of highly correlated features, keeps the one with the\n",
    "    highest correlation with the target.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: DataFrame with features and 'target' column\n",
    "    - corr_threshold: Correlation threshold for considering features as highly correlated\n",
    "    \n",
    "    Returns:\n",
    "    - List of features to drop\n",
    "    \"\"\"\n",
    "    # Calculate correlation matrix\n",
    "    corr_matrix = df.corr().abs()\n",
    "    \n",
    "    # Get correlation with target\n",
    "    target_corr = corr_matrix['target'].drop('target')\n",
    "    \n",
    "    # Get upper triangle of correlations\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "    \n",
    "    # Find feature groups with high correlation\n",
    "    to_drop = set()\n",
    "    \n",
    "    # For each column\n",
    "    for c in upper.columns:\n",
    "        if c == 'target':\n",
    "            continue\n",
    "            \n",
    "        # Find highly correlated features\n",
    "        correlated_features = [\n",
    "            r for r in upper.index \n",
    "            if upper.loc[r, c] > corr_threshold and r != 'target' and c != 'target'\n",
    "        ]\n",
    "        \n",
    "        # If we found any\n",
    "        if correlated_features:\n",
    "            # Add column c and all its correlated features to a group\n",
    "            corr_group = [c] + correlated_features\n",
    "            \n",
    "            # Find correlations with target for this group\n",
    "            target_corrs = {feat: target_corr[feat] for feat in corr_group}\n",
    "            \n",
    "            # Sort by correlation with target (descending)\n",
    "            sorted_group = sorted(target_corrs.items(), key=lambda x: x[1], reverse=True)\n",
    "            \n",
    "            # Keep the feature with highest correlation with target\n",
    "            to_keep = sorted_group[0][0]\n",
    "            \n",
    "            # Mark the rest for removal\n",
    "            for feat in corr_group:\n",
    "                if feat != to_keep:\n",
    "                    to_drop.add(feat)\n",
    "    \n",
    "    # Return list of features to drop\n",
    "    return list(to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_stock_data(input_file, output_dir, period, seq_length=10):\n",
    "    \"\"\"\n",
    "    Prepare stock data for LSTM model.\n",
    "    \n",
    "    Parameters:\n",
    "    - input_file: Path to input CSV file\n",
    "    - output_dir: Directory to save prepared data\n",
    "    - period: Prediction period ('day', 'week', 'month')\n",
    "    - seq_length: Length of sequences for LSTM (default: 10)\n",
    "    \"\"\"\n",
    "    print(f\"Processing {os.path.basename(input_file)} for {period} prediction...\")\n",
    "    \n",
    "    try:\n",
    "        # Read data and ensure chronological order\n",
    "        df = pd.read_csv(input_file)\n",
    "        \n",
    "        # Handle date column properly - fix timezone issues\n",
    "        try:\n",
    "            # Try parsing with UTC=True to avoid timezone warnings\n",
    "            df['date'] = pd.to_datetime(df['date'], utc=True)\n",
    "        except:\n",
    "            try:\n",
    "                # If that fails, try converting the string format directly\n",
    "                df['date'] = pd.to_datetime(df['date'].str.split('-04:00').str[0], errors='coerce')\n",
    "            except:\n",
    "                # Last resort - just use the date part and ignore time\n",
    "                print(\"Warning: Date parsing issue. Converting to datetime without timezone info.\")\n",
    "                df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "        \n",
    "        # Make sure date is properly converted\n",
    "        if df['date'].dtype != 'datetime64[ns]' and df['date'].dtype != 'datetime64[ns, UTC]':\n",
    "            raise ValueError(\"Failed to convert date column to datetime\")\n",
    "            \n",
    "        # Sort by date\n",
    "        df = df.sort_values('date')\n",
    "        \n",
    "        # Define target column based on period\n",
    "        if period == 'day':\n",
    "            target_col = 'next_day_direction'\n",
    "        elif period == 'week':\n",
    "            target_col = 'next_week_direction'\n",
    "        elif period == 'month':\n",
    "            target_col = 'next_month_direction'\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid period: {period}. Use 'day', 'week', or 'month'.\")\n",
    "        \n",
    "        # Calculate all features on the original time series BEFORE selecting subset\n",
    "        \n",
    "        # 1. Daily change features\n",
    "        df['day_change'] = df['close'] - df['open']\n",
    "        df['day_change_pct'] = (df['close'] - df['open']) / df['open']\n",
    "        \n",
    "        # 2. Calculate short-term volatility (to capture recent changes better)\n",
    "        df['volatility_5'] = df['return'].rolling(window=5).std()\n",
    "        \n",
    "        # 3. Rate of change over different periods (original series)\n",
    "        df['roc_3'] = df['close'].pct_change(3)\n",
    "        df['roc_5'] = df['close'].pct_change(5)\n",
    "        df['roc_10'] = df['close'].pct_change(10)\n",
    "        \n",
    "        # 4. Momentum indicators (original series)\n",
    "        df['momentum_3'] = df['close'] - df['close'].shift(3)\n",
    "        df['momentum_5'] = df['close'] - df['close'].shift(5)\n",
    "        df['momentum_10'] = df['close'] - df['close'].shift(10)\n",
    "        \n",
    "        # 5. RSI changes (original series)\n",
    "        df['rsi_diff'] = df['rsi'] - df['rsi'].shift(1)\n",
    "        df['rsi_diff_3'] = df['rsi'] - df['rsi'].shift(3)\n",
    "        df['rsi_ma_diff'] = df['rsi'] - df['rsi'].rolling(window=5).mean()\n",
    "        \n",
    "        # 6. Moving average differences - capturing recent trends\n",
    "        df['ma5_diff'] = df['ma5'] - df['ma5'].shift(1)\n",
    "        df['ma20_diff'] = df['ma20'] - df['ma20'].shift(1)\n",
    "        \n",
    "        # 7. Price-to-MA differences - rate of change in trend strength\n",
    "        df['price_to_ma5_diff'] = df['price_to_ma5'] - df['price_to_ma5'].shift(1)\n",
    "        df['price_to_ma20_diff'] = df['price_to_ma20'] - df['price_to_ma20'].shift(1)\n",
    "        \n",
    "        # 8. Volatility ratios - recalculated with better window handling\n",
    "        df['volatility_ratio'] = df['volatility'] / df['volatility'].rolling(window=10).mean()\n",
    "        df['volatility_change'] = df['volatility'] - df['volatility'].shift(1)\n",
    "        \n",
    "        # 9. Volume changes\n",
    "        df['volume_diff'] = df['volume'] - df['volume'].shift(1)\n",
    "        df['rel_volume_diff'] = df['rel_volume'] - df['rel_volume'].shift(1)\n",
    "        \n",
    "        # 10. Add temporal features - SAFER VERSION\n",
    "        # Extract date components directly from date column to avoid .dt accessor issues\n",
    "        try:\n",
    "            # Only add these if date parsing worked correctly\n",
    "            if df['date'].dtype == 'datetime64[ns]' or df['date'].dtype == 'datetime64[ns, UTC]':\n",
    "                df['day_of_week'] = df['date'].dt.dayofweek\n",
    "                df['day_of_week_sin'] = np.sin(2 * np.pi * df['date'].dt.dayofweek / 7)\n",
    "                df['day_of_week_cos'] = np.cos(2 * np.pi * df['date'].dt.dayofweek / 7)\n",
    "                df['month'] = df['date'].dt.month\n",
    "                df['month_sin'] = np.sin(2 * np.pi * df['date'].dt.month / 12)\n",
    "                df['month_cos'] = np.cos(2 * np.pi * df['date'].dt.month / 12)\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not create temporal features: {str(e)}\")\n",
    "            print(\"Continuing without temporal features.\")\n",
    "        \n",
    "        # Select relevant base features plus the new engineered features\n",
    "        selected_features = [\n",
    "            # Basic price metrics\n",
    "            'close', 'return', \n",
    "            \n",
    "            # Moving averages\n",
    "            'ma5', 'ma20', 'ma50',\n",
    "            \n",
    "            # Price to MA relationships\n",
    "            'price_to_ma5', 'price_to_ma20', 'price_to_ma50',\n",
    "            \n",
    "            # Crossover signals\n",
    "            'ma5_cross_ma20', 'ma20_cross_ma50',\n",
    "            \n",
    "            # Volatility measures\n",
    "            'volatility', 'volatility_5',\n",
    "            \n",
    "            # Volume indicators\n",
    "            'rel_volume',\n",
    "            \n",
    "            # RSI indicators\n",
    "            'rsi', 'rsi_diff',\n",
    "            \n",
    "            # Dynamic changes in indicators\n",
    "            'ma5_diff', 'ma20_diff',\n",
    "            'price_to_ma5_diff', 'price_to_ma20_diff',\n",
    "            \n",
    "            # Rate of change indicators\n",
    "            'roc_3', 'roc_5', 'roc_10',\n",
    "            \n",
    "            # Momentum indicators\n",
    "            'momentum_3', 'momentum_5', \n",
    "            \n",
    "            # Daily changes\n",
    "            'day_change_pct',\n",
    "            \n",
    "            # Volatility dynamics\n",
    "            'volatility_change',\n",
    "            \n",
    "            # Volume dynamics\n",
    "            'rel_volume_diff',\n",
    "            \n",
    "            # Temporal features (if available)\n",
    "            'day_of_week_sin', 'day_of_week_cos',\n",
    "            'month_sin', 'month_cos'\n",
    "        ]\n",
    "        \n",
    "        # Handle missing values with FORWARD fill only (no backfill to avoid leakage)\n",
    "        df = df.fillna(method='ffill')\n",
    "        \n",
    "        # Create a new dataframe with only selected features and target\n",
    "        valid_features = [f for f in selected_features if f in df.columns]\n",
    "        lstm_df = df[valid_features + [target_col]].copy()\n",
    "        lstm_df.rename(columns={target_col: 'target'}, inplace=True)\n",
    "        \n",
    "        # Remove any remaining NaNs after feature engineering\n",
    "        lstm_df = lstm_df.dropna()\n",
    "        \n",
    "        # IMPROVED FEATURE SELECTION: Use the new function to remove highly correlated features\n",
    "        # while keeping those most correlated with the target\n",
    "        to_drop = select_features_by_target_correlation(lstm_df, corr_threshold=0.8)\n",
    "        \n",
    "        if to_drop:\n",
    "            print(f\"Removing highly correlated features: {to_drop}\")\n",
    "            print(\"(Keeping the feature in each correlated group that has highest correlation with target)\")\n",
    "            lstm_df = lstm_df.drop(to_drop, axis=1)\n",
    "        \n",
    "        # Split features and target\n",
    "        features = lstm_df.drop('target', axis=1)\n",
    "        target = lstm_df['target']\n",
    "        \n",
    "        # Scale features using MinMaxScaler\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        scaled_features = scaler.fit_transform(features)\n",
    "        \n",
    "        # Create DataFrame with scaled features\n",
    "        scaled_df = pd.DataFrame(scaled_features, columns=features.columns)\n",
    "        scaled_df['target'] = target.values\n",
    "        \n",
    "        # Create directory if it doesn't exist\n",
    "        os.makedirs(os.path.join(output_dir, period), exist_ok=True)\n",
    "        \n",
    "        # Create output filename\n",
    "        stock_name = os.path.basename(input_file).split('.')[0]\n",
    "        output_file = os.path.join(output_dir, period, f\"{stock_name}_lstm_{period}.csv\")\n",
    "        \n",
    "        # Save prepared data\n",
    "        scaled_df.to_csv(output_file, index=False)\n",
    "        \n",
    "        print(f\"Saved prepared data to {output_file}\")\n",
    "        print(f\"Data shape: {scaled_df.shape}\")\n",
    "        print(f\"Features: {', '.join(scaled_df.columns[:-1])}\")\n",
    "        print(f\"Target balance: {scaled_df['target'].value_counts(normalize=True).to_dict()}\")\n",
    "        \n",
    "        # Perform a quick check for static values\n",
    "        print(\"\\nChecking for static features...\")\n",
    "        static_check = scaled_df.iloc[:5].copy()\n",
    "        static_features = []\n",
    "        \n",
    "        for col in static_check.columns:\n",
    "            if col != 'target' and static_check[col].nunique() == 1:\n",
    "                static_features.append(col)\n",
    "        \n",
    "        if static_features:\n",
    "            print(f\"Warning: The following features appear static in the first 5 rows: {static_features}\")\n",
    "        else:\n",
    "            print(\"No static features detected in sample rows. Data looks good!\")\n",
    "        \n",
    "        return scaled_df, output_file\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {os.path.basename(input_file)}: {str(e)}\")\n",
    "        print(\"Traceback:\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define Paths and Process All Stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20 stock files\n"
     ]
    }
   ],
   "source": [
    "# Define input and output directories\n",
    "input_dir = '../data/cleaned/'\n",
    "output_dir = '../data/lstm/'\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Get list of cleaned stock files\n",
    "stock_files = [f for f in os.listdir(input_dir) if f.endswith('.csv')]\n",
    "\n",
    "print(f\"Found {len(stock_files)} stock files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process each stock for all periods\n",
    "periods = ['day', 'week', 'month']\n",
    "results = {}\n",
    "\n",
    "for stock_file in stock_files:\n",
    "    stock_name = stock_file.split('.')[0]\n",
    "    input_file = os.path.join(input_dir, stock_file)\n",
    "    \n",
    "    results[stock_name] = {}\n",
    "    \n",
    "    for period in periods:\n",
    "        scaled_df, output_file = prepare_stock_data(input_file, output_dir, period)\n",
    "        results[stock_name][period] = {\n",
    "            'df': scaled_df,\n",
    "            'file': output_file\n",
    "        }\n",
    "        print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Quality Checks on Prepared Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_quality_checks(results):\n",
    "    \"\"\"\n",
    "    Perform quality checks on prepared data.\n",
    "    \n",
    "    Parameters:\n",
    "    - results: Dictionary of prepared data results\n",
    "    \"\"\"\n",
    "    print(\"\\n=== Data Quality Checks ===\")\n",
    "    \n",
    "    # 1. Check for class imbalance\n",
    "    class_balance = {period: {} for period in periods}\n",
    "    \n",
    "    for stock_name, stock_data in results.items():\n",
    "        for period, period_data in stock_data.items():\n",
    "            df = period_data['df']\n",
    "            up_pct = df['target'].mean() * 100\n",
    "            class_balance[period][stock_name] = up_pct\n",
    "    \n",
    "    # Display class balance summary\n",
    "    for period, stocks in class_balance.items():\n",
    "        avg_balance = sum(stocks.values()) / len(stocks)\n",
    "        min_balance = min(stocks.values())\n",
    "        max_balance = max(stocks.values())\n",
    "        \n",
    "        print(f\"\\n{period.capitalize()} prediction class balance:\")\n",
    "        print(f\"  Average % Up: {avg_balance:.2f}%\")\n",
    "        print(f\"  Range: {min_balance:.2f}% - {max_balance:.2f}%\")\n",
    "        print(f\"  Stocks with extreme imbalance (<30% or >70%): \", end=\"\")\n",
    "        \n",
    "        extreme = [s for s, v in stocks.items() if v < 30 or v > 70]\n",
    "        if extreme:\n",
    "            print(\", \".join(extreme))\n",
    "        else:\n",
    "            print(\"None\")\n",
    "    \n",
    "    # 2. Check a sample dataset to verify scaling is correct\n",
    "    sample_stock = list(results.keys())[0]\n",
    "    sample_period = 'day'\n",
    "    sample_df = results[sample_stock][sample_period]['df']\n",
    "    \n",
    "    print(\"\\nVerifying scaling for sample dataset:\")\n",
    "    print(f\"  Stock: {sample_stock}, Period: {sample_period}\")\n",
    "    \n",
    "    # Check min and max values for each feature\n",
    "    feature_ranges = {}\n",
    "    for feature in sample_df.columns:\n",
    "        if feature != 'target':\n",
    "            min_val = sample_df[feature].min()\n",
    "            max_val = sample_df[feature].max()\n",
    "            feature_ranges[feature] = (min_val, max_val)\n",
    "    \n",
    "    # Print ranges for first 5 features\n",
    "    for feature, (min_val, max_val) in list(feature_ranges.items())[:5]:\n",
    "        print(f\"  {feature}: Min={min_val:.4f}, Max={max_val:.4f}\")\n",
    "    \n",
    "    print(f\"  All features in [0,1] range: {all(0 <= min_val <= max_val <= 1 for min_val, max_val in feature_ranges.values())}\")\n",
    "    \n",
    "    # 3. Check for correlation among features in the sample dataset\n",
    "    corr_matrix = sample_df.drop('target', axis=1).corr()\n",
    "    \n",
    "    # Count highly correlated feature pairs\n",
    "    high_corr_count = 0\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i+1, len(corr_matrix.columns)):\n",
    "            if abs(corr_matrix.iloc[i, j]) > 0.8:\n",
    "                high_corr_count += 1\n",
    "    \n",
    "    print(f\"\\nCorrelation check for sample dataset:\")\n",
    "    print(f\"  Number of highly correlated feature pairs (>0.8): {high_corr_count}\")\n",
    "    if high_corr_count > 0:\n",
    "        print(\"  Some features are still highly correlated, consider further feature selection\")\n",
    "    else:\n",
    "        print(\"  No high correlation issues detected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Data Quality Checks ===\n",
      "\n",
      "Day prediction class balance:\n",
      "  Average % Up: 52.23%\n",
      "  Range: 49.34% - 55.08%\n",
      "  Stocks with extreme imbalance (<30% or >70%): None\n",
      "\n",
      "Week prediction class balance:\n",
      "  Average % Up: 55.10%\n",
      "  Range: 51.02% - 59.94%\n",
      "  Stocks with extreme imbalance (<30% or >70%): None\n",
      "\n",
      "Month prediction class balance:\n",
      "  Average % Up: 58.29%\n",
      "  Range: 49.46% - 66.04%\n",
      "  Stocks with extreme imbalance (<30% or >70%): None\n",
      "\n",
      "Verifying scaling for sample dataset:\n",
      "  Stock: PYPL, Period: day\n",
      "  close: Min=0.0000, Max=1.0000\n",
      "  return: Min=0.0000, Max=1.0000\n",
      "  price_to_ma5: Min=0.0000, Max=1.0000\n",
      "  price_to_ma20: Min=0.0000, Max=1.0000\n",
      "  ma5_cross_ma20: Min=0.0000, Max=1.0000\n",
      "  All features in [0,1] range: False\n",
      "\n",
      "Correlation check for sample dataset:\n",
      "  Number of highly correlated feature pairs (>0.8): 0\n",
      "  No high correlation issues detected\n"
     ]
    }
   ],
   "source": [
    "# Perform quality checks\n",
    "perform_quality_checks(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Sample Sequence Creation for LSTM\n",
    "\n",
    "Now let's demonstrate how to create sequences for LSTM input using the prepared data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demonstrate_sequence_creation(results):\n",
    "    \"\"\"\n",
    "    Demonstrate sequence creation for LSTM models.\n",
    "    \n",
    "    Parameters:\n",
    "    - results: Dictionary of prepared data results\n",
    "    \"\"\"\n",
    "    # Select a sample stock and period\n",
    "    sample_stock = list(results.keys())[0]\n",
    "    sample_period = 'day'\n",
    "    sample_df = results[sample_stock][sample_period]['df']\n",
    "    \n",
    "    print(f\"\\n=== Sequence Creation Demonstration for {sample_stock}, {sample_period} ===\\n\")\n",
    "    \n",
    "    # Create sequences with length 10\n",
    "    seq_length = 10\n",
    "    X, y = create_sequences(sample_df, seq_length)\n",
    "    \n",
    "    # Print information about the sequences\n",
    "    print(f\"Input shape: {X.shape}\")\n",
    "    print(f\"Target shape: {y.shape}\")\n",
    "    print(f\"Number of sequences: {len(X)}\")\n",
    "    print(f\"Sequence length: {X.shape[1]}\")\n",
    "    print(f\"Number of features: {X.shape[2]}\")\n",
    "    \n",
    "    # Calculate class distribution in targets\n",
    "    unique, counts = np.unique(y, return_counts=True)\n",
    "    class_dist = dict(zip(unique, counts))\n",
    "    total = sum(counts)\n",
    "    \n",
    "    print(\"\\nTarget class distribution:\")\n",
    "    for cls, count in class_dist.items():\n",
    "        print(f\"  Class {int(cls)}: {count} samples ({count/total*100:.2f}%)\")\n",
    "    \n",
    "    # Show an example of how these sequences will be used for LSTM training\n",
    "    print(\"\\nExample sequence (first 3 time steps, first 5 features):\")\n",
    "    example_seq = X[0, :3, :5]  # First sequence, first 3 time steps, first 5 features\n",
    "    print(example_seq)\n",
    "    print(f\"Target for this sequence: {int(y[0])}\")\n",
    "    \n",
    "    print(\"\\nThis demonstrates how sequences are prepared for LSTM input.\")\n",
    "    print(\"Each sequence consists of 10 consecutive days of data, with the target being the direction prediction\")\n",
    "    print(\"for the day immediately following the sequence.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Sequence Creation Demonstration for PYPL, day ===\n",
      "\n",
      "Input shape: (2438, 10, 19)\n",
      "Target shape: (2438,)\n",
      "Number of sequences: 2438\n",
      "Sequence length: 10\n",
      "Number of features: 19\n",
      "\n",
      "Target class distribution:\n",
      "  Class 0: 1164 samples (47.74%)\n",
      "  Class 1: 1274 samples (52.26%)\n",
      "\n",
      "Example sequence (first 3 time steps, first 5 features):\n",
      "[[0.011 0.752 0.    0.    0.313]\n",
      " [0.011 0.623 0.    0.    0.313]\n",
      " [0.011 0.534 0.    0.    0.313]]\n",
      "Target for this sequence: 0\n",
      "\n",
      "This demonstrates how sequences are prepared for LSTM input.\n",
      "Each sequence consists of 10 consecutive days of data, with the target being the direction prediction\n",
      "for the day immediately following the sequence.\n"
     ]
    }
   ],
   "source": [
    "# Demonstrate sequence creation\n",
    "demonstrate_sequence_creation(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "close",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "return",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "price_to_ma5",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "price_to_ma20",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ma5_cross_ma20",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ma20_cross_ma50",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "volatility",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "rel_volume",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "roc_5",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "volatility_ratio",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "rsi_diff",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "rsi_ma_diff",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "target",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "2a26dc41-a33d-4dd9-b488-387b2537a441",
       "rows": [
        [
         "0",
         "0.0357973497335699",
         "0.4530289221937241",
         "0.6058773745962398",
         "0.4943097040188182",
         "0.0",
         "0.0",
         "0.0673586730128248",
         "0.1452224068516769",
         "0.5420009374973569",
         "0.2906944949129666",
         "0.5112079491915787",
         "0.5368063963687925",
         "0"
        ],
        [
         "1",
         "0.0356842601063669",
         "0.4530289221937241",
         "0.6058773745962398",
         "0.4943097040188182",
         "0.0",
         "0.0",
         "0.0673586730128248",
         "0.1452224068516769",
         "0.5420009374973569",
         "0.2906944949129666",
         "0.5112079491915787",
         "0.5368063963687925",
         "0"
        ],
        [
         "2",
         "0.0356748299617535",
         "0.4560265669791609",
         "0.6058773745962398",
         "0.4943097040188182",
         "0.0",
         "0.0",
         "0.0673586730128248",
         "0.1452224068516769",
         "0.5420009374973569",
         "0.2906944949129666",
         "0.5112079491915787",
         "0.5368063963687925",
         "1"
        ],
        [
         "3",
         "0.0369277332364798",
         "0.4925705183085228",
         "0.6058773745962398",
         "0.4943097040188182",
         "0.0",
         "0.0",
         "0.0673586730128248",
         "0.1452224068516769",
         "0.5420009374973569",
         "0.2906944949129666",
         "0.5112079491915787",
         "0.5368063963687925",
         "1"
        ],
        [
         "4",
         "0.0380110701725503",
         "0.4873441857534162",
         "0.6058773745962398",
         "0.4943097040188182",
         "0.0",
         "0.0",
         "0.0673586730128248",
         "0.1452224068516769",
         "0.5420009374973569",
         "0.2906944949129666",
         "0.5112079491915787",
         "0.5368063963687925",
         "0"
        ]
       ],
       "shape": {
        "columns": 13,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close</th>\n",
       "      <th>return</th>\n",
       "      <th>price_to_ma5</th>\n",
       "      <th>price_to_ma20</th>\n",
       "      <th>ma5_cross_ma20</th>\n",
       "      <th>ma20_cross_ma50</th>\n",
       "      <th>volatility</th>\n",
       "      <th>rel_volume</th>\n",
       "      <th>roc_5</th>\n",
       "      <th>volatility_ratio</th>\n",
       "      <th>rsi_diff</th>\n",
       "      <th>rsi_ma_diff</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.035797</td>\n",
       "      <td>0.453029</td>\n",
       "      <td>0.605877</td>\n",
       "      <td>0.49431</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.067359</td>\n",
       "      <td>0.145222</td>\n",
       "      <td>0.542001</td>\n",
       "      <td>0.290694</td>\n",
       "      <td>0.511208</td>\n",
       "      <td>0.536806</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.035684</td>\n",
       "      <td>0.453029</td>\n",
       "      <td>0.605877</td>\n",
       "      <td>0.49431</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.067359</td>\n",
       "      <td>0.145222</td>\n",
       "      <td>0.542001</td>\n",
       "      <td>0.290694</td>\n",
       "      <td>0.511208</td>\n",
       "      <td>0.536806</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.035675</td>\n",
       "      <td>0.456027</td>\n",
       "      <td>0.605877</td>\n",
       "      <td>0.49431</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.067359</td>\n",
       "      <td>0.145222</td>\n",
       "      <td>0.542001</td>\n",
       "      <td>0.290694</td>\n",
       "      <td>0.511208</td>\n",
       "      <td>0.536806</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.036928</td>\n",
       "      <td>0.492571</td>\n",
       "      <td>0.605877</td>\n",
       "      <td>0.49431</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.067359</td>\n",
       "      <td>0.145222</td>\n",
       "      <td>0.542001</td>\n",
       "      <td>0.290694</td>\n",
       "      <td>0.511208</td>\n",
       "      <td>0.536806</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.038011</td>\n",
       "      <td>0.487344</td>\n",
       "      <td>0.605877</td>\n",
       "      <td>0.49431</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.067359</td>\n",
       "      <td>0.145222</td>\n",
       "      <td>0.542001</td>\n",
       "      <td>0.290694</td>\n",
       "      <td>0.511208</td>\n",
       "      <td>0.536806</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      close    return  price_to_ma5  price_to_ma20  ma5_cross_ma20  \\\n",
       "0  0.035797  0.453029      0.605877        0.49431             0.0   \n",
       "1  0.035684  0.453029      0.605877        0.49431             0.0   \n",
       "2  0.035675  0.456027      0.605877        0.49431             0.0   \n",
       "3  0.036928  0.492571      0.605877        0.49431             0.0   \n",
       "4  0.038011  0.487344      0.605877        0.49431             0.0   \n",
       "\n",
       "   ma20_cross_ma50  volatility  rel_volume     roc_5  volatility_ratio  \\\n",
       "0              0.0    0.067359    0.145222  0.542001          0.290694   \n",
       "1              0.0    0.067359    0.145222  0.542001          0.290694   \n",
       "2              0.0    0.067359    0.145222  0.542001          0.290694   \n",
       "3              0.0    0.067359    0.145222  0.542001          0.290694   \n",
       "4              0.0    0.067359    0.145222  0.542001          0.290694   \n",
       "\n",
       "   rsi_diff  rsi_ma_diff  target  \n",
       "0  0.511208     0.536806       0  \n",
       "1  0.511208     0.536806       0  \n",
       "2  0.511208     0.536806       1  \n",
       "3  0.511208     0.536806       1  \n",
       "4  0.511208     0.536806       0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_day=pd.read_csv('../data/lstm/day/AAPL_lstm_day.csv')\n",
    "sample_week=pd.read_csv('../data/lstm/week/AAPL_lstm_week.csv')\n",
    "sample_month=pd.read_csv('../data/lstm/month/AAPL_lstm_month.csv')\n",
    "sample_day.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "close",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "return",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "price_to_ma5",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "price_to_ma20",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ma5_cross_ma20",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ma20_cross_ma50",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "volatility",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "rel_volume",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "roc_5",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "volatility_ratio",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "rsi_diff",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "rsi_ma_diff",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "target",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "28a6bedd-8752-4f35-a9cc-447e36f75694",
       "rows": [
        [
         "0",
         "0.0357973497335699",
         "0.4530289221937241",
         "0.6058773745962398",
         "0.4943097040188182",
         "0.0",
         "0.0",
         "0.0673586730128248",
         "0.1452224068516769",
         "0.5420009374973569",
         "0.2906944949129666",
         "0.5112079491915787",
         "0.5368063963687925",
         "1"
        ],
        [
         "1",
         "0.0356842601063669",
         "0.4530289221937241",
         "0.6058773745962398",
         "0.4943097040188182",
         "0.0",
         "0.0",
         "0.0673586730128248",
         "0.1452224068516769",
         "0.5420009374973569",
         "0.2906944949129666",
         "0.5112079491915787",
         "0.5368063963687925",
         "1"
        ],
        [
         "2",
         "0.0356748299617535",
         "0.4560265669791609",
         "0.6058773745962398",
         "0.4943097040188182",
         "0.0",
         "0.0",
         "0.0673586730128248",
         "0.1452224068516769",
         "0.5420009374973569",
         "0.2906944949129666",
         "0.5112079491915787",
         "0.5368063963687925",
         "1"
        ],
        [
         "3",
         "0.0369277332364798",
         "0.4925705183085228",
         "0.6058773745962398",
         "0.4943097040188182",
         "0.0",
         "0.0",
         "0.0673586730128248",
         "0.1452224068516769",
         "0.5420009374973569",
         "0.2906944949129666",
         "0.5112079491915787",
         "0.5368063963687925",
         "0"
        ],
        [
         "4",
         "0.0380110701725503",
         "0.4873441857534162",
         "0.6058773745962398",
         "0.4943097040188182",
         "0.0",
         "0.0",
         "0.0673586730128248",
         "0.1452224068516769",
         "0.5420009374973569",
         "0.2906944949129666",
         "0.5112079491915787",
         "0.5368063963687925",
         "0"
        ]
       ],
       "shape": {
        "columns": 13,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close</th>\n",
       "      <th>return</th>\n",
       "      <th>price_to_ma5</th>\n",
       "      <th>price_to_ma20</th>\n",
       "      <th>ma5_cross_ma20</th>\n",
       "      <th>ma20_cross_ma50</th>\n",
       "      <th>volatility</th>\n",
       "      <th>rel_volume</th>\n",
       "      <th>roc_5</th>\n",
       "      <th>volatility_ratio</th>\n",
       "      <th>rsi_diff</th>\n",
       "      <th>rsi_ma_diff</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.035797</td>\n",
       "      <td>0.453029</td>\n",
       "      <td>0.605877</td>\n",
       "      <td>0.49431</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.067359</td>\n",
       "      <td>0.145222</td>\n",
       "      <td>0.542001</td>\n",
       "      <td>0.290694</td>\n",
       "      <td>0.511208</td>\n",
       "      <td>0.536806</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.035684</td>\n",
       "      <td>0.453029</td>\n",
       "      <td>0.605877</td>\n",
       "      <td>0.49431</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.067359</td>\n",
       "      <td>0.145222</td>\n",
       "      <td>0.542001</td>\n",
       "      <td>0.290694</td>\n",
       "      <td>0.511208</td>\n",
       "      <td>0.536806</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.035675</td>\n",
       "      <td>0.456027</td>\n",
       "      <td>0.605877</td>\n",
       "      <td>0.49431</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.067359</td>\n",
       "      <td>0.145222</td>\n",
       "      <td>0.542001</td>\n",
       "      <td>0.290694</td>\n",
       "      <td>0.511208</td>\n",
       "      <td>0.536806</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.036928</td>\n",
       "      <td>0.492571</td>\n",
       "      <td>0.605877</td>\n",
       "      <td>0.49431</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.067359</td>\n",
       "      <td>0.145222</td>\n",
       "      <td>0.542001</td>\n",
       "      <td>0.290694</td>\n",
       "      <td>0.511208</td>\n",
       "      <td>0.536806</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.038011</td>\n",
       "      <td>0.487344</td>\n",
       "      <td>0.605877</td>\n",
       "      <td>0.49431</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.067359</td>\n",
       "      <td>0.145222</td>\n",
       "      <td>0.542001</td>\n",
       "      <td>0.290694</td>\n",
       "      <td>0.511208</td>\n",
       "      <td>0.536806</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      close    return  price_to_ma5  price_to_ma20  ma5_cross_ma20  \\\n",
       "0  0.035797  0.453029      0.605877        0.49431             0.0   \n",
       "1  0.035684  0.453029      0.605877        0.49431             0.0   \n",
       "2  0.035675  0.456027      0.605877        0.49431             0.0   \n",
       "3  0.036928  0.492571      0.605877        0.49431             0.0   \n",
       "4  0.038011  0.487344      0.605877        0.49431             0.0   \n",
       "\n",
       "   ma20_cross_ma50  volatility  rel_volume     roc_5  volatility_ratio  \\\n",
       "0              0.0    0.067359    0.145222  0.542001          0.290694   \n",
       "1              0.0    0.067359    0.145222  0.542001          0.290694   \n",
       "2              0.0    0.067359    0.145222  0.542001          0.290694   \n",
       "3              0.0    0.067359    0.145222  0.542001          0.290694   \n",
       "4              0.0    0.067359    0.145222  0.542001          0.290694   \n",
       "\n",
       "   rsi_diff  rsi_ma_diff  target  \n",
       "0  0.511208     0.536806       1  \n",
       "1  0.511208     0.536806       1  \n",
       "2  0.511208     0.536806       1  \n",
       "3  0.511208     0.536806       0  \n",
       "4  0.511208     0.536806       0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_week.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "close",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "return",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "price_to_ma5",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "price_to_ma20",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ma5_cross_ma20",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ma20_cross_ma50",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "volatility",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "rel_volume",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "roc_5",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "volatility_ratio",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "rsi_diff",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "rsi_ma_diff",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "target",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "7f6b5994-c2a5-4dd0-8ed3-2b5262028e4e",
       "rows": [
        [
         "0",
         "0.0357973497335699",
         "0.4530289221937241",
         "0.6058773745962398",
         "0.4943097040188182",
         "0.0",
         "0.0",
         "0.0673586730128248",
         "0.1452224068516769",
         "0.5420009374973569",
         "0.2906944949129666",
         "0.5112079491915787",
         "0.5368063963687925",
         "0"
        ],
        [
         "1",
         "0.0356842601063669",
         "0.4530289221937241",
         "0.6058773745962398",
         "0.4943097040188182",
         "0.0",
         "0.0",
         "0.0673586730128248",
         "0.1452224068516769",
         "0.5420009374973569",
         "0.2906944949129666",
         "0.5112079491915787",
         "0.5368063963687925",
         "0"
        ],
        [
         "2",
         "0.0356748299617535",
         "0.4560265669791609",
         "0.6058773745962398",
         "0.4943097040188182",
         "0.0",
         "0.0",
         "0.0673586730128248",
         "0.1452224068516769",
         "0.5420009374973569",
         "0.2906944949129666",
         "0.5112079491915787",
         "0.5368063963687925",
         "0"
        ],
        [
         "3",
         "0.0369277332364798",
         "0.4925705183085228",
         "0.6058773745962398",
         "0.4943097040188182",
         "0.0",
         "0.0",
         "0.0673586730128248",
         "0.1452224068516769",
         "0.5420009374973569",
         "0.2906944949129666",
         "0.5112079491915787",
         "0.5368063963687925",
         "0"
        ],
        [
         "4",
         "0.0380110701725503",
         "0.4873441857534162",
         "0.6058773745962398",
         "0.4943097040188182",
         "0.0",
         "0.0",
         "0.0673586730128248",
         "0.1452224068516769",
         "0.5420009374973569",
         "0.2906944949129666",
         "0.5112079491915787",
         "0.5368063963687925",
         "0"
        ]
       ],
       "shape": {
        "columns": 13,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close</th>\n",
       "      <th>return</th>\n",
       "      <th>price_to_ma5</th>\n",
       "      <th>price_to_ma20</th>\n",
       "      <th>ma5_cross_ma20</th>\n",
       "      <th>ma20_cross_ma50</th>\n",
       "      <th>volatility</th>\n",
       "      <th>rel_volume</th>\n",
       "      <th>roc_5</th>\n",
       "      <th>volatility_ratio</th>\n",
       "      <th>rsi_diff</th>\n",
       "      <th>rsi_ma_diff</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.035797</td>\n",
       "      <td>0.453029</td>\n",
       "      <td>0.605877</td>\n",
       "      <td>0.49431</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.067359</td>\n",
       "      <td>0.145222</td>\n",
       "      <td>0.542001</td>\n",
       "      <td>0.290694</td>\n",
       "      <td>0.511208</td>\n",
       "      <td>0.536806</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.035684</td>\n",
       "      <td>0.453029</td>\n",
       "      <td>0.605877</td>\n",
       "      <td>0.49431</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.067359</td>\n",
       "      <td>0.145222</td>\n",
       "      <td>0.542001</td>\n",
       "      <td>0.290694</td>\n",
       "      <td>0.511208</td>\n",
       "      <td>0.536806</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.035675</td>\n",
       "      <td>0.456027</td>\n",
       "      <td>0.605877</td>\n",
       "      <td>0.49431</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.067359</td>\n",
       "      <td>0.145222</td>\n",
       "      <td>0.542001</td>\n",
       "      <td>0.290694</td>\n",
       "      <td>0.511208</td>\n",
       "      <td>0.536806</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.036928</td>\n",
       "      <td>0.492571</td>\n",
       "      <td>0.605877</td>\n",
       "      <td>0.49431</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.067359</td>\n",
       "      <td>0.145222</td>\n",
       "      <td>0.542001</td>\n",
       "      <td>0.290694</td>\n",
       "      <td>0.511208</td>\n",
       "      <td>0.536806</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.038011</td>\n",
       "      <td>0.487344</td>\n",
       "      <td>0.605877</td>\n",
       "      <td>0.49431</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.067359</td>\n",
       "      <td>0.145222</td>\n",
       "      <td>0.542001</td>\n",
       "      <td>0.290694</td>\n",
       "      <td>0.511208</td>\n",
       "      <td>0.536806</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      close    return  price_to_ma5  price_to_ma20  ma5_cross_ma20  \\\n",
       "0  0.035797  0.453029      0.605877        0.49431             0.0   \n",
       "1  0.035684  0.453029      0.605877        0.49431             0.0   \n",
       "2  0.035675  0.456027      0.605877        0.49431             0.0   \n",
       "3  0.036928  0.492571      0.605877        0.49431             0.0   \n",
       "4  0.038011  0.487344      0.605877        0.49431             0.0   \n",
       "\n",
       "   ma20_cross_ma50  volatility  rel_volume     roc_5  volatility_ratio  \\\n",
       "0              0.0    0.067359    0.145222  0.542001          0.290694   \n",
       "1              0.0    0.067359    0.145222  0.542001          0.290694   \n",
       "2              0.0    0.067359    0.145222  0.542001          0.290694   \n",
       "3              0.0    0.067359    0.145222  0.542001          0.290694   \n",
       "4              0.0    0.067359    0.145222  0.542001          0.290694   \n",
       "\n",
       "   rsi_diff  rsi_ma_diff  target  \n",
       "0  0.511208     0.536806       0  \n",
       "1  0.511208     0.536806       0  \n",
       "2  0.511208     0.536806       0  \n",
       "3  0.511208     0.536806       0  \n",
       "4  0.511208     0.536806       0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_month.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Conclusion\n",
    "\n",
    "We have successfully prepared and saved the data for LSTM models:\n",
    "\n",
    "1. Selected appropriate features for time series prediction\n",
    "2. Added engineered features relevant for stock price direction prediction\n",
    "3. Removed highly correlated features to reduce dimensionality\n",
    "4. Scaled all features to [0,1] range for LSTM\n",
    "5. Created separate datasets for day, week, and month prediction horizons\n",
    "6. Demonstrated how to create sequences for LSTM input\n",
    "\n",
    "The prepared data is saved in the following structure:\n",
    "- `../data/lstm/day/{stock}_lstm_day.csv`\n",
    "- `../data/lstm/week/{stock}_lstm_week.csv`\n",
    "- `../data/lstm/month/{stock}_lstm_month.csv`\n",
    "\n",
    "These datasets are now ready to be used for training LSTM models for stock direction prediction."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
