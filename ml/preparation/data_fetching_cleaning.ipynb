{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock Data Preprocessing Pipeline\n",
    "\n",
    "This notebook implements a comprehensive preprocessing pipeline for stock data to prepare it for machine learning models including Prophet, LSTM, and XGBoost.\n",
    "\n",
    "## Pipeline Steps:\n",
    "1. Fetch daily stock data using yfinance\n",
    "2. Clean the data (handle missing values, sort by date, etc.)\n",
    "3. Engineer features (returns, moving averages, technical indicators, etc.)\n",
    "4. Create target variables for classification\n",
    "5. Save processed data to CSV files\n",
    "\n",
    "The processed data will follow the project's structure conventions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries\n",
    "\n",
    "This cell imports all the necessary Python libraries for the preprocessing pipeline. \n",
    "- `yfinance` is used for fetching historical stock market data.\n",
    "- `pandas` is essential for data manipulation and analysis, primarily using DataFrames.\n",
    "- `numpy` provides support for numerical operations, especially for arrays and mathematical functions.\n",
    "- `matplotlib.pyplot` is imported for basic plotting, although not extensively used in this script, it's good practice for data exploration.\n",
    "- `os` allows interaction with the operating system, used here for creating directories.\n",
    "- `datetime` from the `datetime` module is used for handling date and time information, particularly for setting default end dates.\n",
    "- `warnings` is used to control how warning messages are handled; `warnings.filterwarnings('ignore')` suppresses warnings to keep the output clean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Stock Tickers\n",
    "\n",
    "This cell defines a list named `tickers`. This list contains the stock ticker symbols for 20 companies and one ETF (SPY) that will be processed by this notebook. Each ticker represents a specific stock (e.g., 'AAPL' for Apple Inc.) or an ETF (e.g., 'SPY' for SPDR S&P 500 ETF Trust). This list will be iterated over to fetch, process, and save data for each specified entity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = [\n",
    "    'AAPL',  # Apple Inc.\n",
    "    'MSFT',  # Microsoft Corporation\n",
    "    'GOOG',  # Alphabet Inc. (Google)\n",
    "    'AMZN',  # Amazon.com, Inc.\n",
    "    'TSLA',  # Tesla, Inc.\n",
    "    'META',  # Meta Platforms, Inc. (formerly Facebook)\n",
    "    'NVDA',  # NVIDIA Corporation\n",
    "    'SPY',   # SPDR S&P 500 ETF Trust\n",
    "    'V',     # Visa Inc.\n",
    "    'DIS',   # The Walt Disney Company\n",
    "    'NFLX',  # Netflix, Inc.\n",
    "    'PYPL',  # PayPal Holdings, Inc.\n",
    "    'BABA',  # Alibaba Group\n",
    "    'IBM',   # International Business Machines Corporation\n",
    "    'AMD',   # Advanced Micro Devices, Inc.\n",
    "    'BA',    # The Boeing Company\n",
    "    'INTC',  # Intel Corporation\n",
    "    'T',     # AT&T Inc.\n",
    "    'GS',    # Goldman Sachs Group, Inc.\n",
    "    'NKE'    # Nike, Inc.\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Helper Functions\n",
    "\n",
    "The following cells define various helper functions that encapsulate specific steps of the data preprocessing pipeline. This modular approach makes the code more organized, reusable, and easier to understand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `fetch_stock_data` Function\n",
    "\n",
    "This cell defines the `fetch_stock_data` function. Its purpose is to retrieve historical stock data for a specified ticker symbol using the `yfinance` library.\n",
    "\n",
    "**Parameters:**\n",
    "- `ticker` (str): The stock ticker symbol (e.g., 'AAPL').\n",
    "- `start_date` (str): The start date for fetching data, in 'YYYY-MM-DD' format. Defaults to '2010-01-01'.\n",
    "- `end_date` (str): The end date for fetching data, in 'YYYY-MM-DD' format. If not provided, it defaults to the current day.\n",
    "\n",
    "**Functionality:**\n",
    "1. Sets the `end_date` to today's date if it's not specified.\n",
    "2. Creates a `yf.Ticker` object for the given stock symbol.\n",
    "3. Calls the `history()` method on the Ticker object to download the stock data for the specified period.\n",
    "4. Prints a confirmation message indicating the number of rows fetched and the date range.\n",
    "5. Prints the first 5 rows of the fetched data for a quick check.\n",
    "\n",
    "**Returns:**\n",
    "- `pandas.DataFrame`: A DataFrame containing the historical stock data, typically including columns like Open, High, Low, Close, Volume, Dividends, and Stock Splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_stock_data(ticker, start_date='2010-01-01', end_date=None):\n",
    "    \"\"\"\n",
    "    Fetch stock data for a given ticker using yfinance\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    ticker : str\n",
    "        Stock ticker symbol\n",
    "    start_date : str\n",
    "        Start date in 'YYYY-MM-DD' format\n",
    "    end_date : str\n",
    "        End date in 'YYYY-MM-DD' format, default is today\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        DataFrame containing stock data\n",
    "    \"\"\"\n",
    "    if end_date is None:\n",
    "        end_date = datetime.today().strftime('%Y-%m-%d')\n",
    "        \n",
    "    stock = yf.Ticker(ticker)\n",
    "    data = stock.history(start=start_date, end=end_date)\n",
    "    \n",
    "    print(f\"Fetched {len(data)} rows of data for {ticker} from {start_date} to {end_date}\")\n",
    "    print(data.head(5))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `clean_stock_data` Function\n",
    "\n",
    "This cell defines the `clean_stock_data` function. This function is responsible for performing several data cleaning operations on the raw stock data DataFrame obtained from `yfinance`.\n",
    "\n",
    "**Parameters:**\n",
    "- `df` (pandas.DataFrame): The input DataFrame containing raw stock data, with a 'Date' index.\n",
    "\n",
    "**Functionality:**\n",
    "1. Creates a copy of the input DataFrame to avoid modifying the original data in place.\n",
    "2. Resets the index so that 'Date' becomes a regular column. This is often necessary for certain operations like timezone localization and sorting.\n",
    "3. Removes timezone information from the 'Date' column using `dt.tz_localize(None)`. This standardizes the date format.\n",
    "4. Sorts the DataFrame by the 'Date' column in ascending order and resets the index again, dropping the old index.\n",
    "5. Drops any duplicate rows based on the 'Date' column to ensure each trading day has only one entry.\n",
    "6. Replaces any 'Volume' entries that are 0 with `np.nan` (Not a Number). Zero volume can indicate missing data or non-trading days and is better handled as NaN for imputation.\n",
    "7. Handles missing values (NaNs) in the price columns ('Open', 'High', 'Low', 'Close') using forward fill (`ffill()`). This means missing values are replaced by the last known valid value.\n",
    "8. Forward fills missing values in the 'Volume' column as well.\n",
    "9. Drops any remaining rows that still contain NaN values after the fill operations. This ensures the DataFrame is free of missing data.\n",
    "10. Converts the 'Volume' column to an integer data type.\n",
    "11. Sets the 'Date' column back as the DataFrame's index, which is a common convention for time-series data and useful for subsequent feature engineering steps.\n",
    "\n",
    "**Returns:**\n",
    "- `pandas.DataFrame`: A cleaned DataFrame with handled missing values, sorted dates, and 'Date' as the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_stock_data(df):\n",
    "    \"\"\"\n",
    "    Clean stock data by handling missing values, sorting by date, etc.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        DataFrame containing stock data\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        Cleaned DataFrame\n",
    "    \"\"\"\n",
    "    # Make a copy to avoid modifying the original data\n",
    "    df = df.copy()\n",
    "\n",
    "    # Rename columns cuz they were not fetched (always 0)\n",
    "    df = df.drop(['Dividends', 'Stock Splits'], axis=1)\n",
    "    \n",
    "    # Reset index to keep Date as a column\n",
    "    df = df.reset_index()\n",
    "    \n",
    "    # Remove timezone info from Date column\n",
    "    df['Date'] = df['Date'].dt.tz_localize(None)\n",
    "    \n",
    "    # Sort data by date (ascending) and reset index\n",
    "    df = df.sort_values('Date').reset_index(drop=True)\n",
    "    \n",
    "    # Drop duplicate rows\n",
    "    df = df.drop_duplicates(subset=['Date'])\n",
    "    \n",
    "    # Replace Volume = 0 with NaN\n",
    "    df.loc[df['Volume'] == 0, 'Volume'] = np.nan\n",
    "    \n",
    "    # Handle missing values: Forward fill for price columns\n",
    "    for col in ['Open', 'High', 'Low', 'Close']:\n",
    "        df[col] = df[col].ffill()\n",
    "    \n",
    "    # Forward fill for Volume\n",
    "    df['Volume'] = df['Volume'].ffill()\n",
    "    \n",
    "    # Drop any remaining rows with NaNs\n",
    "    df = df.dropna()\n",
    "    \n",
    "    # Ensure integer type for Volume\n",
    "    df['Volume'] = df['Volume'].astype(int)\n",
    "    \n",
    "    # Set Date as index again for feature engineering\n",
    "    df = df.set_index('Date')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `add_technical_indicators` Function\n",
    "\n",
    "This cell defines the `add_technical_indicators` function. Its purpose is to calculate and add several common technical indicators to the stock data DataFrame. These indicators can provide insights into market trends, momentum, and volatility, and are often used as features in financial machine learning models.\n",
    "\n",
    "**Parameters:**\n",
    "- `df` (pandas.DataFrame): The input DataFrame containing cleaned stock data, with 'Date' as the index and at least a 'Close' price column.\n",
    "\n",
    "**Functionality:**\n",
    "1. Creates a copy of the input DataFrame.\n",
    "2. **RSI (Relative Strength Index):** Calculates the 14-period RSI. This involves:\n",
    "   - Calculating price differences (`delta`).\n",
    "   - Separating gains and losses.\n",
    "   - Calculating the average gain and average loss over a 14-day window.\n",
    "   - Computing the Relative Strength (RS) and then the RSI value.\n",
    "3. **MACD (Moving Average Convergence Divergence):** Calculates the MACD line, MACD signal line, and MACD histogram.\n",
    "   - `MACD`: Difference between the 12-period Exponential Moving Average (EMA) and the 26-period EMA of the 'Close' price.\n",
    "   - `MACD_Signal`: 9-period EMA of the MACD line.\n",
    "   - `MACD_Hist`: Difference between the MACD line and the MACD signal line.\n",
    "4. **Bollinger Bands:** Calculates the 20-period Bollinger Bands.\n",
    "   - `MA_20`: 20-day Simple Moving Average (SMA) of the 'Close' price.\n",
    "   - `BB_Upper`: Upper Bollinger Band (MA_20 + 2 * 20-day standard deviation of 'Close' price).\n",
    "   - `BB_Lower`: Lower Bollinger Band (MA_20 - 2 * 20-day standard deviation of 'Close' price).\n",
    "5. **Bollinger Band Width and Position:**\n",
    "   - `BB_Width`: Measures the width of the Bollinger Bands relative to the middle band (`(BB_Upper - BB_Lower) / MA_20`).\n",
    "   - `BB_Position`: Indicates where the 'Close' price is relative to the Bollinger Bands (`(Close - BB_Lower) / (BB_Upper - BB_Lower)`).\n",
    "6. **Volatility (Historical):** Calculates historical volatility based on the standard deviation of daily returns over different periods, annualized by multiplying by the square root of 252 (approximate number of trading days in a year).\n",
    "   - `Daily_Return`: Percentage change in 'Close' price from the previous day.\n",
    "   - `Volatility_10D`: Annualized 10-day rolling standard deviation of daily returns.\n",
    "   - `Volatility_30D`: Annualized 30-day rolling standard deviation of daily returns.\n",
    "\n",
    "**Returns:**\n",
    "- `pandas.DataFrame`: The DataFrame with the newly added technical indicator columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_technical_indicators(df):\n",
    "    \"\"\"\n",
    "    Add technical indicators to the DataFrame\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        DataFrame containing stock data\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        DataFrame with added technical indicators\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Calculate RSI (Relative Strength Index)\n",
    "    delta = df['Close'].diff()\n",
    "    gain = delta.where(delta > 0, 0)\n",
    "    loss = -delta.where(delta < 0, 0)\n",
    "    \n",
    "    avg_gain = gain.rolling(window=14).mean()\n",
    "    avg_loss = loss.rolling(window=14).mean()\n",
    "    \n",
    "    rs = avg_gain / avg_loss\n",
    "    df['RSI'] = 100 - (100 / (1 + rs))\n",
    "    \n",
    "    # Calculate MACD (Moving Average Convergence Divergence)\n",
    "    exp1 = df['Close'].ewm(span=12, adjust=False).mean()\n",
    "    exp2 = df['Close'].ewm(span=26, adjust=False).mean()\n",
    "    df['MACD'] = exp1 - exp2\n",
    "    df['MACD_Signal'] = df['MACD'].ewm(span=9, adjust=False).mean()\n",
    "    df['MACD_Hist'] = df['MACD'] - df['MACD_Signal']\n",
    "    \n",
    "    # Calculate Bollinger Bands\n",
    "    df['MA_20'] = df['Close'].rolling(window=20).mean()\n",
    "    df['BB_Upper'] = df['MA_20'] + (df['Close'].rolling(window=20).std() * 2)\n",
    "    df['BB_Lower'] = df['MA_20'] - (df['Close'].rolling(window=20).std() * 2)\n",
    "    \n",
    "    # Calculate BB width and position\n",
    "    df['BB_Width'] = (df['BB_Upper'] - df['BB_Lower']) / df['MA_20']\n",
    "    df['BB_Position'] = (df['Close'] - df['BB_Lower']) / (df['BB_Upper'] - df['BB_Lower'])\n",
    "    \n",
    "    # Calculate Volatility (historical) - Daily returns standard deviation over different windows\n",
    "    df['Daily_Return'] = df['Close'].pct_change()\n",
    "    df['Volatility_10D'] = df['Daily_Return'].rolling(window=10).std() * np.sqrt(252)  # Annualized\n",
    "    df['Volatility_30D'] = df['Daily_Return'].rolling(window=30).std() * np.sqrt(252)  # Annualized\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `engineer_features` Function\n",
    "\n",
    "This cell defines the `engineer_features` function. This function is responsible for creating a variety of features from the stock data, building upon the cleaned data and technical indicators. These features are designed to capture different aspects of price movements, trends, volatility, and seasonality, which can be beneficial for machine learning models.\n",
    "\n",
    "**Parameters:**\n",
    "- `df` (pandas.DataFrame): The input DataFrame, typically the output from `clean_stock_data` or further processed, with 'Date' as the index.\n",
    "\n",
    "**Functionality:**\n",
    "1. Creates a copy of the input DataFrame.\n",
    "2. **Technical Indicators:** Calls the `add_technical_indicators` function to add RSI, MACD, Bollinger Bands, and volatility measures to the DataFrame.\n",
    "3. **Returns:**\n",
    "   - `Daily_Return`: This is already calculated within `add_technical_indicators`.\n",
    "   - `Weekly_Return`: Calculates the percentage change in the 'Close' price over the last 5 trading days.\n",
    "   - `Monthly_Return`: Calculates the percentage change in the 'Close' price over the last 21 trading days (approximating a month).\n",
    "4. **Moving Averages (MA):**\n",
    "   - `MA_20`: Already calculated as part of Bollinger Bands in `add_technical_indicators`.\n",
    "   - Calculates Simple Moving Averages (SMAs) of the 'Close' price for various window sizes: 5-day (`MA_5`), 10-day (`MA_10`), 50-day (`MA_50`), 100-day (`MA_100`), and 200-day (`MA_200`).\n",
    "5. **Rolling Standard Deviation (STD):**\n",
    "   - Calculates the rolling standard deviation of the 'Close' price for 5-day (`STD_5`) and 20-day (`STD_20`) windows. This serves as another measure of price volatility.\n",
    "6. **Average Volume:**\n",
    "   - `Volume_MA_20`: Calculates the 20-day Simple Moving Average of the 'Volume'.\n",
    "7. **Price Range:**\n",
    "   - `Price_Range`: Calculates the difference between the 'High' and 'Low' prices for each day, representing the intraday trading range.\n",
    "8. **Daily Change:**\n",
    "   - `Daily_Change`: Calculates the difference between the 'Close' and 'Open' prices for each day.\n",
    "9. **Time-based Features:**\n",
    "   - Resets the index to make 'Date' a column temporarily.\n",
    "   - `DayOfWeek`: Extracts the day of the week (0 for Monday, 6 for Sunday) from the 'Date'.\n",
    "   - `Month`: Extracts the month (1 for January, 12 for December) from the 'Date'.\n",
    "   - Sets 'Date' back as the DataFrame's index.\n",
    "\n",
    "**Returns:**\n",
    "- `pandas.DataFrame`: The DataFrame enriched with a comprehensive set of engineered features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def engineer_features(df):\n",
    "    \"\"\"\n",
    "    Engineer features for machine learning models\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        DataFrame containing clean stock data\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        DataFrame with engineered features\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # --- Technical indicators ---\n",
    "    df = add_technical_indicators(df)\n",
    "    \n",
    "    # --- Returns ---\n",
    "    # Daily return (already calculated in technical indicators function)\n",
    "    \n",
    "    # Weekly return (5 trading days)\n",
    "    df['Weekly_Return'] = df['Close'].pct_change(5)\n",
    "    \n",
    "    # Monthly return (21 trading days)\n",
    "    df['Monthly_Return'] = df['Close'].pct_change(21)\n",
    "    \n",
    "    # --- Moving averages ---\n",
    "    # MA_20 is already calculated for Bollinger Bands\n",
    "    df['MA_5'] = df['Close'].rolling(window=5).mean()\n",
    "    df['MA_10'] = df['Close'].rolling(window=10).mean()\n",
    "    df['MA_50'] = df['Close'].rolling(window=50).mean()\n",
    "    df['MA_100'] = df['Close'].rolling(window=100).mean()\n",
    "    df['MA_200'] = df['Close'].rolling(window=200).mean()\n",
    "    \n",
    "    # --- Rolling standard deviation ---\n",
    "    df['STD_5'] = df['Close'].rolling(window=5).std()\n",
    "    df['STD_20'] = df['Close'].rolling(window=20).std()\n",
    "    \n",
    "    # --- Average volume ---\n",
    "    df['Volume_MA_20'] = df['Volume'].rolling(window=20).mean()\n",
    "    \n",
    "    # --- Price range ---\n",
    "    df['Price_Range'] = df['High'] - df['Low']\n",
    "    \n",
    "    # --- Daily change ---\n",
    "    df['Daily_Change'] = df['Close'] - df['Open']\n",
    "    \n",
    "    # --- Time-based features ---\n",
    "    # Reset index to get the Date as a column for time-based features\n",
    "    df = df.reset_index()\n",
    "    df['DayOfWeek'] = df['Date'].dt.dayofweek\n",
    "    df['Month'] = df['Date'].dt.month\n",
    "    \n",
    "    # Set Date back as index\n",
    "    df = df.set_index('Date')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `create_target_variables` Function\n",
    "\n",
    "This cell defines the `create_target_variables` function. The purpose of this function is to generate target variables (labels) for supervised machine learning, specifically for classification tasks aimed at predicting future price movements.\n",
    "\n",
    "**Parameters:**\n",
    "- `df` (pandas.DataFrame): The input DataFrame, which should contain engineered features and a 'Close' price column, with 'Date' as the index.\n",
    "\n",
    "**Functionality:**\n",
    "1. Creates a copy of the input DataFrame.\n",
    "2. **Target for Next Day (`Target_1D`):**\n",
    "   - Shifts the 'Close' price column by -1. This brings the next day's closing price to the current day's row.\n",
    "   - Compares this future 'Close' price with the current day's 'Close' price.\n",
    "   - Assigns `1` if the next day's 'Close' is higher than the current day's 'Close' (price increased), and `0` otherwise (price decreased or stayed the same).\n",
    "3. **Target for Next Week (`Target_1W`):**\n",
    "   - Shifts the 'Close' price column by -5 (approximating 5 trading days in a week).\n",
    "   - Compares the 'Close' price 5 days ahead with the current day's 'Close' price.\n",
    "   - Assigns `1` if the 'Close' price 5 days ahead is higher, and `0` otherwise.\n",
    "4. **Target for Next Month (`Target_1M`):**\n",
    "   - Shifts the 'Close' price column by -21 (approximating 21 trading days in a month).\n",
    "   - Compares the 'Close' price 21 days ahead with the current day's 'Close' price.\n",
    "   - Assigns `1` if the 'Close' price 21 days ahead is higher, and `0` otherwise.\n",
    "\n",
    "**Note:** Using `shift(-n)` to create target variables will result in `NaN` values for the last `n` rows of these target columns, as there is no future data available for them. These rows are typically dropped before model training.\n",
    "\n",
    "**Returns:**\n",
    "- `pandas.DataFrame`: The DataFrame with the newly added target variable columns (`Target_1D`, `Target_1W`, `Target_1M`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_target_variables(df):\n",
    "    \"\"\"\n",
    "    Create target variables for classification\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        DataFrame with engineered features\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        DataFrame with target variables\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Target for next day (1 day ahead)\n",
    "    df['Target_1D'] = np.where(df['Close'].shift(-1) > df['Close'], 1, 0)\n",
    "    \n",
    "    # Target for next week (5 trading days ahead)\n",
    "    df['Target_1W'] = np.where(df['Close'].shift(-5) > df['Close'], 1, 0)\n",
    "    \n",
    "    # Target for next month (21 trading days ahead)\n",
    "    df['Target_1M'] = np.where(df['Close'].shift(-21) > df['Close'], 1, 0)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `create_directories` Function\n",
    "\n",
    "This cell defines the `create_directories` function. Its sole purpose is to create the necessary directory structure where the processed data files will be saved. This helps in organizing the project files.\n",
    "\n",
    "**Functionality:**\n",
    "1. Uses `os.makedirs('../data/cleaned', exist_ok=True)`.\n",
    "   - `os.makedirs()`: Creates a directory. If intermediate directories in the path do not exist, it creates them as well.\n",
    "   - `'../data/cleaned'`: Specifies the path of the directory to be created. This path suggests a project structure where the current notebook is in a subdirectory (e.g., `notebooks`), and the data is stored in a parallel `data` directory, with a `cleaned` subfolder for processed files.\n",
    "   - `exist_ok=True`: If the directory already exists, this argument prevents the function from raising an error. The operation will simply be skipped.\n",
    "2. Prints a confirmation message indicating that the directory has been created (or was already present).\n",
    "\n",
    "This function is typically called once at the beginning of the main processing script to ensure the output location is ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_directories():\n",
    "    \"\"\"\n",
    "    Create directories for storing processed data\n",
    "    \"\"\"\n",
    "    os.makedirs('../data/cleaned', exist_ok=True)\n",
    "    print(\"Created directory: ../data/cleaned\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `process_stock` Function\n",
    "\n",
    "This cell defines the `process_stock` function, which serves as a master orchestrator for processing the data of a single stock ticker. It integrates all the previously defined helper functions (fetch, clean, feature engineer, create targets) into a sequential pipeline.\n",
    "\n",
    "**Parameters:**\n",
    "- `ticker` (str): The stock ticker symbol (e.g., 'AAPL').\n",
    "- `start_date` (str): The start date for fetching data, in 'YYYY-MM-DD' format. Defaults to '2010-01-01'.\n",
    "- `end_date` (str): The end date for fetching data, in 'YYYY-MM-DD' format. If `None`, it defaults to the current day (handled by `fetch_stock_data`).\n",
    "\n",
    "**Functionality:**\n",
    "1. Prints a header to clearly indicate which ticker is currently being processed.\n",
    "2. **Fetch Data:** Calls `fetch_stock_data(ticker, start_date, end_date)` to download the raw historical data for the specified ticker and period.\n",
    "3. **Clean Data:** Calls `clean_stock_data(df)` to clean the raw data (handle missing values, sort, etc.). Prints the shape of the DataFrame after cleaning.\n",
    "4. **Engineer Features:** Calls `engineer_features(df_clean)` to add technical indicators, returns, moving averages, and other relevant features. Prints the shape after feature engineering.\n",
    "5. **Create Target Variables:** Calls `create_target_variables(df_featured)` to generate binary classification targets for different future time horizons. Prints the shape after adding targets.\n",
    "6. **Drop NaNs:** Removes rows with any NaN values. NaN values are typically introduced at the beginning of the series due to rolling window calculations (e.g., moving averages, RSI) and at the end of the series due to shifting for target variable creation.\n",
    "7. Prints the final shape of the DataFrame after dropping NaNs.\n",
    "8. **Reset Index:** Resets the DataFrame's index. This converts the 'Date' index back into a regular column, which is often preferred when saving to a CSV file.\n",
    "\n",
    "**Returns:**\n",
    "- `pandas.DataFrame`: A fully processed DataFrame for the given stock, ready for model training or saving to a file. It includes cleaned data, engineered features, and target variables, with 'Date' as a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_stock(ticker, start_date='2010-01-01', end_date=None):\n",
    "    \"\"\"\n",
    "    Process stock data for a given ticker through the entire pipeline\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    ticker : str\n",
    "        Stock ticker symbol\n",
    "    start_date : str\n",
    "        Start date in 'YYYY-MM-DD' format\n",
    "    end_date : str\n",
    "        End date in 'YYYY-MM-DD' format, default is today\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        Processed DataFrame ready for use in models\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*80}\\nProcessing {ticker}\\n{'='*80}\")\n",
    "    \n",
    "    # 1. Fetch data\n",
    "    df = fetch_stock_data(ticker, start_date, end_date)\n",
    "    \n",
    "    # 2. Clean data\n",
    "    print(f\"\\nCleaning data for {ticker}...\")\n",
    "    df_clean = clean_stock_data(df)\n",
    "    print(f\"Shape after cleaning: {df_clean.shape}\")\n",
    "    \n",
    "    # 3. Engineer features\n",
    "    print(f\"\\nEngineering features for {ticker}...\")\n",
    "    df_featured = engineer_features(df_clean)\n",
    "    print(f\"Shape after feature engineering: {df_featured.shape}\")\n",
    "    \n",
    "    # 4. Create target variables\n",
    "    print(f\"\\nCreating target variables for {ticker}...\")\n",
    "    df_with_targets = create_target_variables(df_featured)\n",
    "    print(f\"Shape after adding targets: {df_with_targets.shape}\")\n",
    "    \n",
    "    # 5. Drop rows with NaNs (due to rolling windows and shifting)\n",
    "    df_final = df_with_targets.dropna()\n",
    "    print(f\"\\nFinal shape after dropping NaNs: {df_final.shape}\")\n",
    "    \n",
    "    # 6. Reset index to make Date a column again before saving\n",
    "    df_final = df_final.reset_index()\n",
    "    \n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Directories\n",
    "\n",
    "This cell executes the `create_directories` function defined earlier. Its purpose is to ensure that the target directory (`../data/cleaned/`) for saving the processed stock data CSV files exists before the main processing loop begins. If the directory doesn't exist, it will be created. If it already exists, the function does nothing due to the `exist_ok=True` parameter used in `os.makedirs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created directory: ../data/cleaned\n"
     ]
    }
   ],
   "source": [
    "create_directories()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process All Stocks\n",
    "\n",
    "This section defines and then calls a function to process all stock tickers specified in the `tickers` list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `process_all_stocks` Function Definition\n",
    "\n",
    "This cell defines the `process_all_stocks` function. This function iterates through a list of stock tickers, processes each one using the `process_stock` function, and then saves the resulting DataFrame to a CSV file.\n",
    "\n",
    "**Parameters:**\n",
    "- `tickers` (list): A list of stock ticker symbols to process.\n",
    "- `start_date` (str): The start date for fetching data, passed to `process_stock`. Defaults to '2010-01-01'.\n",
    "- `end_date` (str): The end date for fetching data, passed to `process_stock`. If `None`, it defaults to the current day (handled by `fetch_stock_data` within `process_stock`).\n",
    "\n",
    "**Functionality:**\n",
    "1. Iterates through each `ticker` in the provided `tickers` list.\n",
    "2. **Process Stock:** For each ticker, it calls `process_stock(ticker, start_date, end_date)` to perform the complete data fetching, cleaning, feature engineering, and target creation pipeline.\n",
    "3. **Save to CSV:**\n",
    "   - Defines an `output_path` for the CSV file, naming it `{ticker}.csv` and placing it in the `../data/cleaned/` directory.\n",
    "   - Saves the processed DataFrame (`df`) to this path using `df.to_csv(output_path, index=False)`. `index=False` prevents pandas from writing the DataFrame index as a column in the CSV file (since 'Date' is already a column).\n",
    "   - Prints a confirmation message indicating where the data was saved.\n",
    "4. **Error Handling:** Includes a `try-except` block to catch any exceptions that might occur during the processing of a single stock (e.g., data not available for a ticker, network issues). If an error occurs, it prints an error message and uses `continue` to proceed to the next ticker in the list, ensuring that the failure of one stock doesn't halt the entire process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_all_stocks(tickers, start_date='2010-01-01', end_date=None):\n",
    "    \"\"\"\n",
    "    Process all stocks in the list and save the results to CSV files\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    tickers : list\n",
    "        List of stock ticker symbols\n",
    "    start_date : str\n",
    "        Start date in 'YYYY-MM-DD' format\n",
    "    end_date : str\n",
    "        End date in 'YYYY-MM-DD' format, default is today\n",
    "    \"\"\"\n",
    "    for ticker in tickers:\n",
    "        try:\n",
    "            # Process the stock\n",
    "            df = process_stock(ticker, start_date, end_date)\n",
    "            \n",
    "            # Save to CSV\n",
    "            output_path = f'../data/cleaned/{ticker}.csv'\n",
    "            df.to_csv(output_path, index=False)\n",
    "            print(f\"\\nSaved processed data to {output_path}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\nError processing {ticker}: {e}\")\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Executing `process_all_stocks`\n",
    "\n",
    "This cell calls the `process_all_stocks` function, passing it the `tickers` list defined earlier in the notebook. This action initiates the main data processing loop for all the specified stocks. The `start_date` and `end_date` parameters will use their default values ('2010-01-01' and today, respectively) as they are not explicitly provided in this call.\n",
    "\n",
    "The line is commented out (`# process_all_stocks(tickers)`), meaning it will not run automatically when the notebook is executed from top to bottom. The user needs to uncomment this line to start the processing of all stocks. This is a common practice to prevent accidental long-running operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Processing AAPL\n",
      "================================================================================\n",
      "Fetched 3864 rows of data for AAPL from 2010-01-01 to 2025-05-14\n",
      "                               Open      High       Low     Close     Volume  \\\n",
      "Date                                                                           \n",
      "2010-01-04 00:00:00-05:00  6.414465  6.446623  6.382908  6.431896  493729600   \n",
      "2010-01-05 00:00:00-05:00  6.449627  6.479381  6.409054  6.443015  601904800   \n",
      "2010-01-06 00:00:00-05:00  6.443017  6.468563  6.333920  6.340532  552160000   \n",
      "2010-01-07 00:00:00-05:00  6.363973  6.371487  6.282827  6.328809  477131200   \n",
      "2010-01-08 00:00:00-05:00  6.320395  6.371487  6.283128  6.370886  447610800   \n",
      "\n",
      "                           Dividends  Stock Splits  \n",
      "Date                                                \n",
      "2010-01-04 00:00:00-05:00        0.0           0.0  \n",
      "2010-01-05 00:00:00-05:00        0.0           0.0  \n",
      "2010-01-06 00:00:00-05:00        0.0           0.0  \n",
      "2010-01-07 00:00:00-05:00        0.0           0.0  \n",
      "2010-01-08 00:00:00-05:00        0.0           0.0  \n",
      "\n",
      "Cleaning data for AAPL...\n",
      "Shape after cleaning: (3864, 5)\n",
      "\n",
      "Engineering features for AAPL...\n",
      "Shape after feature engineering: (3864, 31)\n",
      "\n",
      "Creating target variables for AAPL...\n",
      "Shape after adding targets: (3864, 34)\n",
      "\n",
      "Final shape after dropping NaNs: (3665, 34)\n",
      "\n",
      "Saved processed data to ../data/cleaned/AAPL.csv\n",
      "\n",
      "================================================================================\n",
      "Processing MSFT\n",
      "================================================================================\n",
      "Fetched 3864 rows of data for MSFT from 2010-01-01 to 2025-05-14\n",
      "                                Open       High        Low      Close  \\\n",
      "Date                                                                    \n",
      "2010-01-04 00:00:00-05:00  23.006116  23.366760  22.983575  23.254059   \n",
      "2010-01-05 00:00:00-05:00  23.178914  23.366749  23.021131  23.261560   \n",
      "2010-01-06 00:00:00-05:00  23.201465  23.351734  22.930983  23.118818   \n",
      "2010-01-07 00:00:00-05:00  23.013624  23.066219  22.683034  22.878384   \n",
      "2010-01-08 00:00:00-05:00  22.750656  23.201460  22.720601  23.036165   \n",
      "\n",
      "                             Volume  Dividends  Stock Splits  \n",
      "Date                                                          \n",
      "2010-01-04 00:00:00-05:00  38409100        0.0           0.0  \n",
      "2010-01-05 00:00:00-05:00  49749600        0.0           0.0  \n",
      "2010-01-06 00:00:00-05:00  58182400        0.0           0.0  \n",
      "2010-01-07 00:00:00-05:00  50559700        0.0           0.0  \n",
      "2010-01-08 00:00:00-05:00  51197400        0.0           0.0  \n",
      "\n",
      "Cleaning data for MSFT...\n",
      "Shape after cleaning: (3864, 5)\n",
      "\n",
      "Engineering features for MSFT...\n",
      "Shape after feature engineering: (3864, 31)\n",
      "\n",
      "Creating target variables for MSFT...\n",
      "Shape after adding targets: (3864, 34)\n",
      "\n",
      "Final shape after dropping NaNs: (3665, 34)\n",
      "\n",
      "Saved processed data to ../data/cleaned/MSFT.csv\n",
      "\n",
      "================================================================================\n",
      "Processing GOOG\n",
      "================================================================================\n",
      "Fetched 3864 rows of data for GOOG from 2010-01-01 to 2025-05-14\n",
      "                                Open       High        Low      Close  \\\n",
      "Date                                                                    \n",
      "2010-01-04 00:00:00-05:00  15.541608  15.605068  15.474429  15.536651   \n",
      "2010-01-05 00:00:00-05:00  15.547309  15.563670  15.407498  15.468232   \n",
      "2010-01-06 00:00:00-05:00  15.514588  15.514588  15.031198  15.078298   \n",
      "2010-01-07 00:00:00-05:00  15.106557  15.121431  14.691337  14.727282   \n",
      "2010-01-08 00:00:00-05:00  14.675225  14.954104  14.603585  14.923614   \n",
      "\n",
      "                              Volume  Dividends  Stock Splits  \n",
      "Date                                                           \n",
      "2010-01-04 00:00:00-05:00   78541293        0.0           0.0  \n",
      "2010-01-05 00:00:00-05:00  120638494        0.0           0.0  \n",
      "2010-01-06 00:00:00-05:00  159744526        0.0           0.0  \n",
      "2010-01-07 00:00:00-05:00  257533695        0.0           0.0  \n",
      "2010-01-08 00:00:00-05:00  189680313        0.0           0.0  \n",
      "\n",
      "Cleaning data for GOOG...\n",
      "Shape after cleaning: (3864, 5)\n",
      "\n",
      "Engineering features for GOOG...\n",
      "Shape after feature engineering: (3864, 31)\n",
      "\n",
      "Creating target variables for GOOG...\n",
      "Shape after adding targets: (3864, 34)\n",
      "\n",
      "Final shape after dropping NaNs: (3665, 34)\n",
      "\n",
      "Saved processed data to ../data/cleaned/GOOG.csv\n",
      "\n",
      "================================================================================\n",
      "Processing AMZN\n",
      "================================================================================\n",
      "Fetched 3864 rows of data for AMZN from 2010-01-01 to 2025-05-14\n",
      "                             Open    High     Low   Close     Volume  \\\n",
      "Date                                                                   \n",
      "2010-01-04 00:00:00-05:00  6.8125  6.8305  6.6570  6.6950  151998000   \n",
      "2010-01-05 00:00:00-05:00  6.6715  6.7740  6.5905  6.7345  177038000   \n",
      "2010-01-06 00:00:00-05:00  6.7300  6.7365  6.5825  6.6125  143576000   \n",
      "2010-01-07 00:00:00-05:00  6.6005  6.6160  6.4400  6.5000  220604000   \n",
      "2010-01-08 00:00:00-05:00  6.5280  6.6840  6.4515  6.6760  196610000   \n",
      "\n",
      "                           Dividends  Stock Splits  \n",
      "Date                                                \n",
      "2010-01-04 00:00:00-05:00        0.0           0.0  \n",
      "2010-01-05 00:00:00-05:00        0.0           0.0  \n",
      "2010-01-06 00:00:00-05:00        0.0           0.0  \n",
      "2010-01-07 00:00:00-05:00        0.0           0.0  \n",
      "2010-01-08 00:00:00-05:00        0.0           0.0  \n",
      "\n",
      "Cleaning data for AMZN...\n",
      "Shape after cleaning: (3864, 5)\n",
      "\n",
      "Engineering features for AMZN...\n",
      "Shape after feature engineering: (3864, 31)\n",
      "\n",
      "Creating target variables for AMZN...\n",
      "Shape after adding targets: (3864, 34)\n",
      "\n",
      "Final shape after dropping NaNs: (3665, 34)\n",
      "\n",
      "Saved processed data to ../data/cleaned/AMZN.csv\n",
      "\n",
      "================================================================================\n",
      "Processing TSLA\n",
      "================================================================================\n",
      "Fetched 3742 rows of data for TSLA from 2010-01-01 to 2025-05-14\n",
      "                               Open      High       Low     Close     Volume  \\\n",
      "Date                                                                           \n",
      "2010-06-29 00:00:00-04:00  1.266667  1.666667  1.169333  1.592667  281494500   \n",
      "2010-06-30 00:00:00-04:00  1.719333  2.028000  1.553333  1.588667  257806500   \n",
      "2010-07-01 00:00:00-04:00  1.666667  1.728000  1.351333  1.464000  123282000   \n",
      "2010-07-02 00:00:00-04:00  1.533333  1.540000  1.247333  1.280000   77097000   \n",
      "2010-07-06 00:00:00-04:00  1.333333  1.333333  1.055333  1.074000  103003500   \n",
      "\n",
      "                           Dividends  Stock Splits  \n",
      "Date                                                \n",
      "2010-06-29 00:00:00-04:00        0.0           0.0  \n",
      "2010-06-30 00:00:00-04:00        0.0           0.0  \n",
      "2010-07-01 00:00:00-04:00        0.0           0.0  \n",
      "2010-07-02 00:00:00-04:00        0.0           0.0  \n",
      "2010-07-06 00:00:00-04:00        0.0           0.0  \n",
      "\n",
      "Cleaning data for TSLA...\n",
      "Shape after cleaning: (3742, 5)\n",
      "\n",
      "Engineering features for TSLA...\n",
      "Shape after feature engineering: (3742, 31)\n",
      "\n",
      "Creating target variables for TSLA...\n",
      "Shape after adding targets: (3742, 34)\n",
      "\n",
      "Final shape after dropping NaNs: (3543, 34)\n",
      "\n",
      "Saved processed data to ../data/cleaned/TSLA.csv\n",
      "\n",
      "================================================================================\n",
      "Processing META\n",
      "================================================================================\n",
      "Fetched 3265 rows of data for META from 2010-01-01 to 2025-05-14\n",
      "                                Open       High        Low      Close  \\\n",
      "Date                                                                    \n",
      "2012-05-18 00:00:00-04:00  41.852747  44.788910  37.821746  38.050667   \n",
      "2012-05-21 00:00:00-04:00  36.358642  36.488033  32.845202  33.870369   \n",
      "2012-05-22 00:00:00-04:00  32.457028  33.432430  30.794862  30.854580   \n",
      "2012-05-23 00:00:00-04:00  31.222848  32.347546  31.212894  31.849892   \n",
      "2012-05-24 00:00:00-04:00  32.795438  33.054217  31.620973  32.875061   \n",
      "\n",
      "                              Volume  Dividends  Stock Splits  \n",
      "Date                                                           \n",
      "2012-05-18 00:00:00-04:00  573576400        0.0           0.0  \n",
      "2012-05-21 00:00:00-04:00  168192700        0.0           0.0  \n",
      "2012-05-22 00:00:00-04:00  101786600        0.0           0.0  \n",
      "2012-05-23 00:00:00-04:00   73600000        0.0           0.0  \n",
      "2012-05-24 00:00:00-04:00   50237200        0.0           0.0  \n",
      "\n",
      "Cleaning data for META...\n",
      "Shape after cleaning: (3265, 5)\n",
      "\n",
      "Engineering features for META...\n",
      "Shape after feature engineering: (3265, 31)\n",
      "\n",
      "Creating target variables for META...\n",
      "Shape after adding targets: (3265, 34)\n",
      "\n",
      "Final shape after dropping NaNs: (3066, 34)\n",
      "\n",
      "Saved processed data to ../data/cleaned/META.csv\n",
      "\n",
      "================================================================================\n",
      "Processing NVDA\n",
      "================================================================================\n",
      "Fetched 3864 rows of data for NVDA from 2010-01-01 to 2025-05-14\n",
      "                               Open      High       Low     Close     Volume  \\\n",
      "Date                                                                           \n",
      "2010-01-04 00:00:00-05:00  0.424342  0.426864  0.415172  0.423884  800204000   \n",
      "2010-01-05 00:00:00-05:00  0.422279  0.434658  0.422279  0.430073  728648000   \n",
      "2010-01-06 00:00:00-05:00  0.429844  0.433741  0.425718  0.432824  649168000   \n",
      "2010-01-07 00:00:00-05:00  0.430532  0.432366  0.421133  0.424342  547792000   \n",
      "2010-01-08 00:00:00-05:00  0.420903  0.428239  0.418382  0.425259  478168000   \n",
      "\n",
      "                           Dividends  Stock Splits  \n",
      "Date                                                \n",
      "2010-01-04 00:00:00-05:00        0.0           0.0  \n",
      "2010-01-05 00:00:00-05:00        0.0           0.0  \n",
      "2010-01-06 00:00:00-05:00        0.0           0.0  \n",
      "2010-01-07 00:00:00-05:00        0.0           0.0  \n",
      "2010-01-08 00:00:00-05:00        0.0           0.0  \n",
      "\n",
      "Cleaning data for NVDA...\n",
      "Shape after cleaning: (3864, 5)\n",
      "\n",
      "Engineering features for NVDA...\n",
      "Shape after feature engineering: (3864, 31)\n",
      "\n",
      "Creating target variables for NVDA...\n",
      "Shape after adding targets: (3864, 34)\n",
      "\n",
      "Final shape after dropping NaNs: (3665, 34)\n",
      "\n",
      "Saved processed data to ../data/cleaned/NVDA.csv\n",
      "\n",
      "================================================================================\n",
      "Processing SPY\n",
      "================================================================================\n",
      "Fetched 3864 rows of data for SPY from 2010-01-01 to 2025-05-14\n",
      "                                Open       High        Low      Close  \\\n",
      "Date                                                                    \n",
      "2010-01-04 00:00:00-05:00  85.041918  85.813854  84.391067  85.768448   \n",
      "2010-01-05 00:00:00-05:00  85.715470  86.033326  85.405178  85.995483   \n",
      "2010-01-06 00:00:00-05:00  85.912244  86.267942  85.844134  86.056038   \n",
      "2010-01-07 00:00:00-05:00  85.897085  86.525233  85.654909  86.419281   \n",
      "2010-01-08 00:00:00-05:00  86.192253  86.744721  86.018191  86.706879   \n",
      "\n",
      "                              Volume  Dividends  Stock Splits  Capital Gains  \n",
      "Date                                                                          \n",
      "2010-01-04 00:00:00-05:00  118944600        0.0           0.0            0.0  \n",
      "2010-01-05 00:00:00-05:00  111579900        0.0           0.0            0.0  \n",
      "2010-01-06 00:00:00-05:00  116074400        0.0           0.0            0.0  \n",
      "2010-01-07 00:00:00-05:00  131091100        0.0           0.0            0.0  \n",
      "2010-01-08 00:00:00-05:00  126402800        0.0           0.0            0.0  \n",
      "\n",
      "Cleaning data for SPY...\n",
      "Shape after cleaning: (3864, 6)\n",
      "\n",
      "Engineering features for SPY...\n",
      "Shape after feature engineering: (3864, 32)\n",
      "\n",
      "Creating target variables for SPY...\n",
      "Shape after adding targets: (3864, 35)\n",
      "\n",
      "Final shape after dropping NaNs: (3665, 35)\n",
      "\n",
      "Saved processed data to ../data/cleaned/SPY.csv\n",
      "\n",
      "================================================================================\n",
      "Processing V\n",
      "================================================================================\n",
      "Fetched 3864 rows of data for V from 2010-01-01 to 2025-05-14\n",
      "                                Open       High        Low      Close  \\\n",
      "Date                                                                    \n",
      "2010-01-04 00:00:00-05:00  19.720578  19.893132  19.599565  19.751951   \n",
      "2010-01-05 00:00:00-05:00  19.563717  19.615259  19.272390  19.525620   \n",
      "2010-01-06 00:00:00-05:00  19.498725  19.514412  19.249977  19.263422   \n",
      "2010-01-07 00:00:00-05:00  19.265670  19.496490  19.171549  19.442707   \n",
      "2010-01-08 00:00:00-05:00  19.456151  19.583886  19.323934  19.496489   \n",
      "\n",
      "                             Volume  Dividends  Stock Splits  \n",
      "Date                                                          \n",
      "2010-01-04 00:00:00-05:00  20180000        0.0           0.0  \n",
      "2010-01-05 00:00:00-05:00  25833600        0.0           0.0  \n",
      "2010-01-06 00:00:00-05:00  16254000        0.0           0.0  \n",
      "2010-01-07 00:00:00-05:00  27841200        0.0           0.0  \n",
      "2010-01-08 00:00:00-05:00  11907200        0.0           0.0  \n",
      "\n",
      "Cleaning data for V...\n",
      "Shape after cleaning: (3864, 5)\n",
      "\n",
      "Engineering features for V...\n",
      "Shape after feature engineering: (3864, 31)\n",
      "\n",
      "Creating target variables for V...\n",
      "Shape after adding targets: (3864, 34)\n",
      "\n",
      "Final shape after dropping NaNs: (3665, 34)\n",
      "\n",
      "Saved processed data to ../data/cleaned/V.csv\n",
      "\n",
      "================================================================================\n",
      "Processing DIS\n",
      "================================================================================\n",
      "Fetched 3864 rows of data for DIS from 2010-01-01 to 2025-05-14\n",
      "                                Open       High        Low      Close  \\\n",
      "Date                                                                    \n",
      "2010-01-04 00:00:00-05:00  27.963015  28.178115  27.420963  27.593042   \n",
      "2010-01-05 00:00:00-05:00  27.593048  27.670484  27.274700  27.524216   \n",
      "2010-01-06 00:00:00-05:00  27.446783  27.532823  27.257495  27.377951   \n",
      "2010-01-07 00:00:00-05:00  27.334927  27.412364  27.137036  27.386551   \n",
      "2010-01-08 00:00:00-05:00  27.240285  27.481198  27.128434  27.429573   \n",
      "\n",
      "                             Volume  Dividends  Stock Splits  \n",
      "Date                                                          \n",
      "2010-01-04 00:00:00-05:00  13700400        0.0           0.0  \n",
      "2010-01-05 00:00:00-05:00  10307700        0.0           0.0  \n",
      "2010-01-06 00:00:00-05:00  10709500        0.0           0.0  \n",
      "2010-01-07 00:00:00-05:00   8202100        0.0           0.0  \n",
      "2010-01-08 00:00:00-05:00   7657500        0.0           0.0  \n",
      "\n",
      "Cleaning data for DIS...\n",
      "Shape after cleaning: (3864, 5)\n",
      "\n",
      "Engineering features for DIS...\n",
      "Shape after feature engineering: (3864, 31)\n",
      "\n",
      "Creating target variables for DIS...\n",
      "Shape after adding targets: (3864, 34)\n",
      "\n",
      "Final shape after dropping NaNs: (3665, 34)\n",
      "\n",
      "Saved processed data to ../data/cleaned/DIS.csv\n",
      "\n",
      "================================================================================\n",
      "Processing NFLX\n",
      "================================================================================\n",
      "Fetched 3864 rows of data for NFLX from 2010-01-01 to 2025-05-14\n",
      "                               Open      High       Low     Close    Volume  \\\n",
      "Date                                                                          \n",
      "2010-01-04 00:00:00-05:00  7.931429  7.961429  7.565714  7.640000  17239600   \n",
      "2010-01-05 00:00:00-05:00  7.652857  7.657143  7.258571  7.358571  23753100   \n",
      "2010-01-06 00:00:00-05:00  7.361429  7.672857  7.197143  7.617143  23290400   \n",
      "2010-01-07 00:00:00-05:00  7.731429  7.757143  7.462857  7.485714   9955400   \n",
      "2010-01-08 00:00:00-05:00  7.498571  7.742857  7.465714  7.614286   8180900   \n",
      "\n",
      "                           Dividends  Stock Splits  \n",
      "Date                                                \n",
      "2010-01-04 00:00:00-05:00        0.0           0.0  \n",
      "2010-01-05 00:00:00-05:00        0.0           0.0  \n",
      "2010-01-06 00:00:00-05:00        0.0           0.0  \n",
      "2010-01-07 00:00:00-05:00        0.0           0.0  \n",
      "2010-01-08 00:00:00-05:00        0.0           0.0  \n",
      "\n",
      "Cleaning data for NFLX...\n",
      "Shape after cleaning: (3864, 5)\n",
      "\n",
      "Engineering features for NFLX...\n",
      "Shape after feature engineering: (3864, 31)\n",
      "\n",
      "Creating target variables for NFLX...\n",
      "Shape after adding targets: (3864, 34)\n",
      "\n",
      "Final shape after dropping NaNs: (3665, 34)\n",
      "\n",
      "Saved processed data to ../data/cleaned/NFLX.csv\n",
      "\n",
      "================================================================================\n",
      "Processing PYPL\n",
      "================================================================================\n",
      "Fetched 2480 rows of data for PYPL from 2010-01-01 to 2025-05-14\n",
      "                                Open       High        Low      Close  \\\n",
      "Date                                                                    \n",
      "2015-07-06 00:00:00-04:00  38.000000  39.750000  36.000000  36.709999   \n",
      "2015-07-07 00:00:00-04:00  37.720001  37.810001  36.000000  36.619999   \n",
      "2015-07-08 00:00:00-04:00  36.340000  36.360001  34.529999  34.700001   \n",
      "2015-07-09 00:00:00-04:00  35.099998  35.520000  33.990002  34.500000   \n",
      "2015-07-10 00:00:00-04:00  34.660000  35.189999  33.980000  34.689999   \n",
      "\n",
      "                            Volume  Dividends  Stock Splits  \n",
      "Date                                                         \n",
      "2015-07-06 00:00:00-04:00  5866600        0.0           0.0  \n",
      "2015-07-07 00:00:00-04:00  7359000        0.0           0.0  \n",
      "2015-07-08 00:00:00-04:00  5387700        0.0           0.0  \n",
      "2015-07-09 00:00:00-04:00  3760100        0.0           0.0  \n",
      "2015-07-10 00:00:00-04:00  4472800        0.0           0.0  \n",
      "\n",
      "Cleaning data for PYPL...\n",
      "Shape after cleaning: (2480, 5)\n",
      "\n",
      "Engineering features for PYPL...\n",
      "Shape after feature engineering: (2480, 31)\n",
      "\n",
      "Creating target variables for PYPL...\n",
      "Shape after adding targets: (2480, 34)\n",
      "\n",
      "Final shape after dropping NaNs: (2281, 34)\n",
      "\n",
      "Saved processed data to ../data/cleaned/PYPL.csv\n",
      "\n",
      "================================================================================\n",
      "Processing BABA\n",
      "================================================================================\n",
      "Fetched 2678 rows of data for BABA from 2010-01-01 to 2025-05-14\n",
      "                                Open       High        Low      Close  \\\n",
      "Date                                                                    \n",
      "2014-09-19 00:00:00-04:00  89.524709  96.284936  86.868906  90.673950   \n",
      "2014-09-22 00:00:00-04:00  89.524712  89.766149  86.434326  86.810966   \n",
      "2014-09-23 00:00:00-04:00  85.893503  87.380754  83.652972  84.184128   \n",
      "2014-09-24 00:00:00-04:00  85.439608  87.467674  84.232424  87.467674   \n",
      "2014-09-25 00:00:00-04:00  87.969852  88.365812  85.468572  85.874184   \n",
      "\n",
      "                              Volume  Dividends  Stock Splits  \n",
      "Date                                                           \n",
      "2014-09-19 00:00:00-04:00  271879400        0.0           0.0  \n",
      "2014-09-22 00:00:00-04:00   66657800        0.0           0.0  \n",
      "2014-09-23 00:00:00-04:00   39009800        0.0           0.0  \n",
      "2014-09-24 00:00:00-04:00   32088000        0.0           0.0  \n",
      "2014-09-25 00:00:00-04:00   28598000        0.0           0.0  \n",
      "\n",
      "Cleaning data for BABA...\n",
      "Shape after cleaning: (2678, 5)\n",
      "\n",
      "Engineering features for BABA...\n",
      "Shape after feature engineering: (2678, 31)\n",
      "\n",
      "Creating target variables for BABA...\n",
      "Shape after adding targets: (2678, 34)\n",
      "\n",
      "Final shape after dropping NaNs: (2479, 34)\n",
      "\n",
      "Saved processed data to ../data/cleaned/BABA.csv\n",
      "\n",
      "================================================================================\n",
      "Processing IBM\n",
      "================================================================================\n",
      "Fetched 3864 rows of data for IBM from 2010-01-01 to 2025-05-14\n",
      "                                Open       High        Low      Close  \\\n",
      "Date                                                                    \n",
      "2010-01-04 00:00:00-05:00  73.071379  74.068465  72.887561  73.778809   \n",
      "2010-01-05 00:00:00-05:00  73.349869  73.444567  72.469761  72.887535   \n",
      "2010-01-06 00:00:00-05:00  72.792881  73.244079  72.308267  72.414101   \n",
      "2010-01-07 00:00:00-05:00  72.341669  72.553341  71.806922  72.163422   \n",
      "2010-01-08 00:00:00-05:00  71.896019  72.926525  71.884879  72.887535   \n",
      "\n",
      "                            Volume  Dividends  Stock Splits  \n",
      "Date                                                         \n",
      "2010-01-04 00:00:00-05:00  6438444        0.0           0.0  \n",
      "2010-01-05 00:00:00-05:00  7156104        0.0           0.0  \n",
      "2010-01-06 00:00:00-05:00  5863144        0.0           0.0  \n",
      "2010-01-07 00:00:00-05:00  6109268        0.0           0.0  \n",
      "2010-01-08 00:00:00-05:00  4390271        0.0           0.0  \n",
      "\n",
      "Cleaning data for IBM...\n",
      "Shape after cleaning: (3864, 5)\n",
      "\n",
      "Engineering features for IBM...\n",
      "Shape after feature engineering: (3864, 31)\n",
      "\n",
      "Creating target variables for IBM...\n",
      "Shape after adding targets: (3864, 34)\n",
      "\n",
      "Final shape after dropping NaNs: (3665, 34)\n",
      "\n",
      "Saved processed data to ../data/cleaned/IBM.csv\n",
      "\n",
      "================================================================================\n",
      "Processing AMD\n",
      "================================================================================\n",
      "Fetched 3864 rows of data for AMD from 2010-01-01 to 2025-05-14\n",
      "                           Open  High   Low  Close    Volume  Dividends  \\\n",
      "Date                                                                      \n",
      "2010-01-04 00:00:00-05:00  9.79  9.90  9.68   9.70  18748700        0.0   \n",
      "2010-01-05 00:00:00-05:00  9.71  9.90  9.68   9.71  22145700        0.0   \n",
      "2010-01-06 00:00:00-05:00  9.68  9.76  9.55   9.57  18643400        0.0   \n",
      "2010-01-07 00:00:00-05:00  9.51  9.55  9.18   9.47  26806800        0.0   \n",
      "2010-01-08 00:00:00-05:00  9.37  9.47  9.29   9.43  13752800        0.0   \n",
      "\n",
      "                           Stock Splits  \n",
      "Date                                     \n",
      "2010-01-04 00:00:00-05:00           0.0  \n",
      "2010-01-05 00:00:00-05:00           0.0  \n",
      "2010-01-06 00:00:00-05:00           0.0  \n",
      "2010-01-07 00:00:00-05:00           0.0  \n",
      "2010-01-08 00:00:00-05:00           0.0  \n",
      "\n",
      "Cleaning data for AMD...\n",
      "Shape after cleaning: (3864, 5)\n",
      "\n",
      "Engineering features for AMD...\n",
      "Shape after feature engineering: (3864, 31)\n",
      "\n",
      "Creating target variables for AMD...\n",
      "Shape after adding targets: (3864, 34)\n",
      "\n",
      "Final shape after dropping NaNs: (3665, 34)\n",
      "\n",
      "Saved processed data to ../data/cleaned/AMD.csv\n",
      "\n",
      "================================================================================\n",
      "Processing BA\n",
      "================================================================================\n",
      "Fetched 3864 rows of data for BA from 2010-01-01 to 2025-05-14\n",
      "                                Open       High        Low      Close  \\\n",
      "Date                                                                    \n",
      "2010-01-04 00:00:00-05:00  43.419101  43.941189  42.702201  43.777550   \n",
      "2010-01-05 00:00:00-05:00  43.832095  45.413946  43.637286  45.211346   \n",
      "2010-01-06 00:00:00-05:00  45.374985  46.746444  45.102253  46.582802   \n",
      "2010-01-07 00:00:00-05:00  46.372402  48.554268  45.990577  48.468552   \n",
      "2010-01-08 00:00:00-05:00  47.954262  48.141278  47.424381  48.001015   \n",
      "\n",
      "                             Volume  Dividends  Stock Splits  \n",
      "Date                                                          \n",
      "2010-01-04 00:00:00-05:00   6186700        0.0           0.0  \n",
      "2010-01-05 00:00:00-05:00   8867800        0.0           0.0  \n",
      "2010-01-06 00:00:00-05:00   8836500        0.0           0.0  \n",
      "2010-01-07 00:00:00-05:00  14379100        0.0           0.0  \n",
      "2010-01-08 00:00:00-05:00   7146600        0.0           0.0  \n",
      "\n",
      "Cleaning data for BA...\n",
      "Shape after cleaning: (3864, 5)\n",
      "\n",
      "Engineering features for BA...\n",
      "Shape after feature engineering: (3864, 31)\n",
      "\n",
      "Creating target variables for BA...\n",
      "Shape after adding targets: (3864, 34)\n",
      "\n",
      "Final shape after dropping NaNs: (3665, 34)\n",
      "\n",
      "Saved processed data to ../data/cleaned/BA.csv\n",
      "\n",
      "================================================================================\n",
      "Processing INTC\n",
      "================================================================================\n",
      "Fetched 3864 rows of data for INTC from 2010-01-01 to 2025-05-14\n",
      "                                Open       High        Low      Close  \\\n",
      "Date                                                                    \n",
      "2010-01-04 00:00:00-05:00  13.461158  13.616553  13.422308  13.519430   \n",
      "2010-01-05 00:00:00-05:00  13.558278  13.590652  13.338134  13.512955   \n",
      "2010-01-06 00:00:00-05:00  13.474105  13.551804  13.383458  13.467630   \n",
      "2010-01-07 00:00:00-05:00  13.422307  13.441732  13.169789  13.338135   \n",
      "2010-01-08 00:00:00-05:00  13.299286  13.525903  13.208637  13.487055   \n",
      "\n",
      "                             Volume  Dividends  Stock Splits  \n",
      "Date                                                          \n",
      "2010-01-04 00:00:00-05:00  47800900        0.0           0.0  \n",
      "2010-01-05 00:00:00-05:00  52357700        0.0           0.0  \n",
      "2010-01-06 00:00:00-05:00  40037400        0.0           0.0  \n",
      "2010-01-07 00:00:00-05:00  54041500        0.0           0.0  \n",
      "2010-01-08 00:00:00-05:00  48234700        0.0           0.0  \n",
      "\n",
      "Cleaning data for INTC...\n",
      "Shape after cleaning: (3864, 5)\n",
      "\n",
      "Engineering features for INTC...\n",
      "Shape after feature engineering: (3864, 31)\n",
      "\n",
      "Creating target variables for INTC...\n",
      "Shape after adding targets: (3864, 34)\n",
      "\n",
      "Final shape after dropping NaNs: (3665, 34)\n",
      "\n",
      "Saved processed data to ../data/cleaned/INTC.csv\n",
      "\n",
      "================================================================================\n",
      "Processing T\n",
      "================================================================================\n",
      "Fetched 3864 rows of data for T from 2010-01-01 to 2025-05-14\n",
      "                               Open      High       Low     Close    Volume  \\\n",
      "Date                                                                          \n",
      "2010-01-04 00:00:00-05:00  6.923623  6.972363  6.891941  6.965053  38576858   \n",
      "2010-01-05 00:00:00-05:00  6.994298  7.001610  6.909002  6.930936  46650478   \n",
      "2010-01-06 00:00:00-05:00  6.947359  6.967244  6.847934  6.862847  50172450   \n",
      "2010-01-07 00:00:00-05:00  6.855391  6.882733  6.741051  6.785793  44486797   \n",
      "2010-01-08 00:00:00-05:00  6.783308  6.808165  6.681397  6.736082  36586622   \n",
      "\n",
      "                           Dividends  Stock Splits  \n",
      "Date                                                \n",
      "2010-01-04 00:00:00-05:00       0.00           0.0  \n",
      "2010-01-05 00:00:00-05:00       0.00           0.0  \n",
      "2010-01-06 00:00:00-05:00       0.42           0.0  \n",
      "2010-01-07 00:00:00-05:00       0.00           0.0  \n",
      "2010-01-08 00:00:00-05:00       0.00           0.0  \n",
      "\n",
      "Cleaning data for T...\n",
      "Shape after cleaning: (3864, 5)\n",
      "\n",
      "Engineering features for T...\n",
      "Shape after feature engineering: (3864, 31)\n",
      "\n",
      "Creating target variables for T...\n",
      "Shape after adding targets: (3864, 34)\n",
      "\n",
      "Final shape after dropping NaNs: (3665, 34)\n",
      "\n",
      "Saved processed data to ../data/cleaned/T.csv\n",
      "\n",
      "================================================================================\n",
      "Processing GS\n",
      "================================================================================\n",
      "Fetched 3864 rows of data for GS from 2010-01-01 to 2025-05-14\n",
      "                                 Open        High         Low       Close  \\\n",
      "Date                                                                        \n",
      "2010-01-04 00:00:00-05:00  130.327702  133.546614  129.913835  132.649918   \n",
      "2010-01-05 00:00:00-05:00  132.588641  135.087128  132.259091  134.995163   \n",
      "2010-01-06 00:00:00-05:00  134.412661  134.412661  133.171071  133.554276   \n",
      "2010-01-07 00:00:00-05:00  133.600250  136.995431  133.316671  136.167709   \n",
      "2010-01-08 00:00:00-05:00  135.140692  135.983733  133.316637  133.592545   \n",
      "\n",
      "                             Volume  Dividends  Stock Splits  \n",
      "Date                                                          \n",
      "2010-01-04 00:00:00-05:00   9135000        0.0           0.0  \n",
      "2010-01-05 00:00:00-05:00  11659400        0.0           0.0  \n",
      "2010-01-06 00:00:00-05:00   7381100        0.0           0.0  \n",
      "2010-01-07 00:00:00-05:00   8727400        0.0           0.0  \n",
      "2010-01-08 00:00:00-05:00   7268100        0.0           0.0  \n",
      "\n",
      "Cleaning data for GS...\n",
      "Shape after cleaning: (3864, 5)\n",
      "\n",
      "Engineering features for GS...\n",
      "Shape after feature engineering: (3864, 31)\n",
      "\n",
      "Creating target variables for GS...\n",
      "Shape after adding targets: (3864, 34)\n",
      "\n",
      "Final shape after dropping NaNs: (3665, 34)\n",
      "\n",
      "Saved processed data to ../data/cleaned/GS.csv\n",
      "\n",
      "================================================================================\n",
      "Processing NKE\n",
      "================================================================================\n",
      "Fetched 3864 rows of data for NKE from 2010-01-01 to 2025-05-14\n",
      "                                Open       High        Low      Close  \\\n",
      "Date                                                                    \n",
      "2010-01-04 00:00:00-05:00  13.656405  13.658473  13.462083  13.509629   \n",
      "2010-01-05 00:00:00-05:00  13.466217  13.600590  13.375257  13.563379   \n",
      "2010-01-06 00:00:00-05:00  13.519969  13.579920  13.424874  13.480690   \n",
      "2010-01-07 00:00:00-05:00  13.462087  13.644006  13.447616  13.612997   \n",
      "2010-01-08 00:00:00-05:00  13.600592  13.612996  13.424874  13.586122   \n",
      "\n",
      "                             Volume  Dividends  Stock Splits  \n",
      "Date                                                          \n",
      "2010-01-04 00:00:00-05:00  11972400        0.0           0.0  \n",
      "2010-01-05 00:00:00-05:00   6275200        0.0           0.0  \n",
      "2010-01-06 00:00:00-05:00  13399200        0.0           0.0  \n",
      "2010-01-07 00:00:00-05:00   7187600        0.0           0.0  \n",
      "2010-01-08 00:00:00-05:00   7249600        0.0           0.0  \n",
      "\n",
      "Cleaning data for NKE...\n",
      "Shape after cleaning: (3864, 5)\n",
      "\n",
      "Engineering features for NKE...\n",
      "Shape after feature engineering: (3864, 31)\n",
      "\n",
      "Creating target variables for NKE...\n",
      "Shape after adding targets: (3864, 34)\n",
      "\n",
      "Final shape after dropping NaNs: (3665, 34)\n",
      "\n",
      "Saved processed data to ../data/cleaned/NKE.csv\n"
     ]
    }
   ],
   "source": [
    "# Process all stocks (uncomment to run)\n",
    "process_all_stocks(tickers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Individual Stock Example\n",
    "\n",
    "This section provides an example of how to process and save data for a single stock. This can be useful for testing the pipeline on a smaller scale, debugging, or when only data for a specific stock is needed without processing the entire list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Processing a Single Stock ('AAPL')\n",
    "\n",
    "This cell demonstrates the steps to process data for a single stock, using 'AAPL' (Apple Inc.) as an example.\n",
    "\n",
    "**Functionality:**\n",
    "1. **Define Ticker:** Sets the `ticker` variable to 'AAPL'.\n",
    "2. **Process Stock:** Calls the `process_stock(ticker)` function. This will fetch, clean, engineer features, and create targets for 'AAPL' using the default start and end dates.\n",
    "The result (a processed DataFrame) is stored in the `df` variable.\n",
    "3. **Save to CSV:**\n",
    "   - Defines the `output_path` for the CSV file as `../data/cleaned/AAPL.csv`.\n",
    "   - Saves the `df` to this path using `df.to_csv(output_path, index=False)`.\n",
    "   - Prints a confirmation message indicating the save location.\n",
    "\n",
    "The code in this cell is commented out. To run this example, the user would need to uncomment these lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Processing AAPL\n",
      "================================================================================\n",
      "Fetched 3864 rows of data for AAPL from 2010-01-01 to 2025-05-14\n",
      "                               Open      High       Low     Close     Volume  \\\n",
      "Date                                                                           \n",
      "2010-01-04 00:00:00-05:00  6.414464  6.446622  6.382907  6.431896  493729600   \n",
      "2010-01-05 00:00:00-05:00  6.449629  6.479382  6.409055  6.443017  601904800   \n",
      "2010-01-06 00:00:00-05:00  6.443015  6.468561  6.333918  6.340530  552160000   \n",
      "2010-01-07 00:00:00-05:00  6.363975  6.371489  6.282828  6.328811  477131200   \n",
      "2010-01-08 00:00:00-05:00  6.320393  6.371486  6.283127  6.370884  447610800   \n",
      "\n",
      "                           Dividends  Stock Splits  \n",
      "Date                                                \n",
      "2010-01-04 00:00:00-05:00        0.0           0.0  \n",
      "2010-01-05 00:00:00-05:00        0.0           0.0  \n",
      "2010-01-06 00:00:00-05:00        0.0           0.0  \n",
      "2010-01-07 00:00:00-05:00        0.0           0.0  \n",
      "2010-01-08 00:00:00-05:00        0.0           0.0  \n",
      "\n",
      "Cleaning data for AAPL...\n",
      "Shape after cleaning: (3864, 5)\n",
      "\n",
      "Engineering features for AAPL...\n",
      "Shape after feature engineering: (3864, 31)\n",
      "\n",
      "Creating target variables for AAPL...\n",
      "Shape after adding targets: (3864, 34)\n",
      "\n",
      "Final shape after dropping NaNs: (3665, 34)\n",
      "\n",
      "Saved processed data to ../data/cleaned/AAPL.csv\n"
     ]
    }
   ],
   "source": [
    "# Example for processing a single stock (uncomment to run)\n",
    "ticker = 'AAPL'\n",
    "df = process_stock(ticker)\n",
    "\n",
    "# Save to CSV\n",
    "output_path = f'../data/cleaned/{ticker}.csv'\n",
    "df.to_csv(output_path, index=False)\n",
    "print(f\"\\nSaved processed data to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Analysis of Processed Data\n",
    "\n",
    "This section demonstrates how to load one of the processed CSV files and perform a brief exploratory analysis. This is a crucial step to verify that the preprocessing pipeline has worked as expected and that the data is in the correct format with the intended features and targets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and Examining a Processed File\n",
    "\n",
    "This cell provides code to load a processed stock data file (e.g., for 'AAPL') and display some basic information about it.\n",
    "\n",
    "**Functionality:**\n",
    "1. **Specify Ticker and File Path:**\n",
    "   - Sets `ticker` to 'AAPL' (or any other ticker for which data has been processed).\n",
    "   - Constructs the `file_path` to the corresponding CSV file in the `../data/cleaned/` directory.\n",
    "2. **Check File Existence:** Uses `os.path.exists(file_path)` to ensure the file actually exists before attempting to load it.\n",
    "3. **If File Exists:**\n",
    "   - **Load Data:** Reads the CSV file into a pandas DataFrame using `pd.read_csv(file_path)`.\n",
    "   - **Basic Info:**\n",
    "     - Prints the shape of the DataFrame (`df.shape`) to show the number of rows and columns.\n",
    "     - Prints the first 10 rows of the DataFrame using `display(df.head(10))` for a visual inspection of the data.\n",
    "   - **Column List:** Iterates through `df.columns` and prints each column name. This helps verify that all expected features and target variables are present.\n",
    "   - **Target Distribution:**\n",
    "     - Prints the normalized value counts for each of the target variables (`Target_1D`, `Target_1W`, `Target_1M`) using `df['Target_...'].value_counts(normalize=True)`. This shows the proportion of 0s and 1s for each target, which is important for understanding class balance in classification tasks.\n",
    "4. **If File Does Not Exist:** Prints a message indicating that the file was not found and reminds the user to process stocks first.\n",
    "\n",
    "The code in this cell is commented out. It should be uncommented and run after at least one stock's data has been processed and saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame shape: (3665, 35)\n",
      "\n",
      "First few rows:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Date",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Open",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "High",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Low",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Close",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Volume",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "RSI",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MACD",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MACD_Signal",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MACD_Hist",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MA_20",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "BB_Upper",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "BB_Lower",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "BB_Width",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "BB_Position",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Daily_Return",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Volatility_10D",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Volatility_30D",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Weekly_Return",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Monthly_Return",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MA_5",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MA_10",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MA_50",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MA_100",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MA_200",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "STD_5",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "STD_20",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Volume_MA_20",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Price_Range",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Daily_Change",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "DayOfWeek",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Month",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Target_1D",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Target_1W",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Target_1M",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "06dea15c-7de2-49db-8019-747289fe1fc6",
       "rows": [
        [
         "0",
         "2010-10-18",
         "9.571358248057816",
         "9.58728612950072",
         "9.44573126638254",
         "9.557232856750488",
         "1093010800",
         "82.03707524477862",
         "0.3217730753671244",
         "0.2643164696838607",
         "0.0574566056832637",
         "8.79621443748474",
         "9.400479034327384",
         "8.1919498406421",
         "0.1373919658592202",
         "1.1297062770532678",
         "0.0103576559546314",
         "0.2287587088744164",
         "0.213042188335371",
         "0.0766524165653559",
         "0.1548098596929559",
         "9.219001770019531",
         "8.9877347946167",
         "8.128515214920045",
         "7.946636614799499",
         "7.377748332023621",
         "0.2693231304250717",
         "0.3021322984213211",
         "626992800.0",
         "0.1415548631181789",
         "-0.0141253913073278",
         "0",
         "10",
         "0",
         "0",
         "0"
        ],
        [
         "1",
         "2010-10-19",
         "9.11844003568044",
         "9.430101452353318",
         "9.01685697002107",
         "9.301469802856444",
         "1232784000",
         "69.54057883019632",
         "0.3220443888578614",
         "0.2758620535186608",
         "0.0461823353392006",
         "8.834864044189453",
         "9.46533901204347",
         "8.204389076335437",
         "0.1427243169109478",
         "0.8700430488582315",
         "-0.0267612035541638",
         "0.2656014485097578",
         "0.2326648429476647",
         "0.0366786820499569",
         "0.092716142911656",
         "9.284820747375488",
         "9.049496078491211",
         "8.157210998535156",
         "7.9635090208053585",
         "7.392096202373505",
         "0.2315465810485834",
         "0.3152374839270084",
         "655228280.0",
         "0.4132444823322476",
         "0.1830297671760039",
         "1",
         "10",
         "1",
         "0",
         "0"
        ],
        [
         "2",
         "2010-10-20",
         "9.286741825577282",
         "9.444526276017996",
         "9.22272696110659",
         "9.332724571228027",
         "721624400",
         "74.78706431891128",
         "0.3210801927579343",
         "0.2849056813665155",
         "0.0361745113914188",
         "8.869095611572266",
         "9.530460152346508",
         "8.207731070798026",
         "0.1491391162614825",
         "0.8505093870870397",
         "0.0033601967252512",
         "0.2642747119401662",
         "0.229163062776165",
         "0.0346170237352279",
         "0.0943013435342143",
         "9.347273063659667",
         "9.113631534576417",
         "8.187938394546508",
         "7.979633083343506",
         "7.406544742584228",
         "0.178440165103026",
         "0.3306822703871205",
         "662045020.0",
         "0.2217993149114061",
         "0.0459827456507451",
         "2",
         "10",
         "0",
         "0",
         "0"
        ],
        [
         "3",
         "2010-10-21",
         "9.387726376199684",
         "9.459255378967624",
         "9.220625271404025",
         "9.302372932434082",
         "551460000",
         "75.09301332502878",
         "0.3142445215763345",
         "0.2907734494084793",
         "0.0234710721678552",
         "8.90005145072937",
         "9.582414553096646",
         "8.217688348362094",
         "0.1533391365532736",
         "0.7948001440208048",
         "-0.0032521734207732",
         "0.2673418047781917",
         "0.2301667460368074",
         "0.0238498326917726",
         "0.0756559500398261",
         "9.390611457824708",
         "9.1746413230896",
         "8.223600740432738",
         "7.99426646232605",
         "7.421353957653046",
         "0.1135320240864753",
         "0.3411815511836381",
         "650312180.0",
         "0.2386301075635994",
         "-0.0853534437656016",
         "3",
         "10",
         "0",
         "0",
         "0"
        ],
        [
         "4",
         "2010-10-22",
         "9.288844121487983",
         "9.317996939486347",
         "9.205594953690143",
         "9.240757942199709",
         "372778000",
         "77.73701146056577",
         "0.3003926486765955",
         "0.2926972892621026",
         "0.0076953594144929",
         "8.922817277908326",
         "9.619315580779451",
         "8.226318975037199",
         "0.1561162312704893",
         "0.7282422390555412",
         "-0.006623577734617",
         "0.2690297806071492",
         "0.2325659394129291",
         "-0.0230989792060491",
         "0.0642042320671574",
         "9.34691162109375",
         "9.214913845062256",
         "8.257069025039673",
         "8.007346005439759",
         "7.435913691520691",
         "0.1222226981037515",
         "0.3482491514355633",
         "636476680.0",
         "0.1124019857962039",
         "-0.048086179288278",
         "4",
         "10",
         "1",
         "0",
         "1"
        ],
        [
         "5",
         "2010-10-25",
         "9.289448858025702",
         "9.364883783901345",
         "9.269912788399434",
         "9.28193473815918",
         "392462000",
         "73.11792045250124",
         "0.2894015223083066",
         "0.2920381358713434",
         "-0.0026366135630367",
         "8.949385261535644",
         "9.658640285600567",
         "8.240130237470721",
         "0.158503629766235",
         "0.7344357567730778",
         "0.0044559976808211",
         "0.2690285144887877",
         "0.2311674694536246",
         "-0.0288052120020136",
         "0.0565131923384667",
         "9.291851997375488",
         "9.25542688369751",
         "8.292977695465089",
         "8.021086750030518",
         "7.450468943119049",
         "0.0338478731044349",
         "0.3546275120324617",
         "631958040.0",
         "0.0949709955019084",
         "-0.0075141198665225",
         "0",
         "10",
         "0",
         "0",
         "0"
        ],
        [
         "6",
         "2010-10-26",
         "9.222726215103211",
         "9.308981675599153",
         "9.186059277984343",
         "9.258190155029297",
         "392929600",
         "71.63817759241353",
         "0.2755980631397925",
         "0.2887501213250332",
         "-0.0131520581852407",
         "8.98122763633728",
         "9.685638184992747",
         "8.276817087681813",
         "0.1568628648951023",
         "0.696591688767768",
         "-0.0025581501917122",
         "0.2687935878312581",
         "0.2321778747291462",
         "-0.0046529901988024",
         "0.0580093405988004",
         "9.283196067810058",
         "9.284008407592774",
         "8.329289121627808",
         "8.036741948127746",
         "7.465186462402344",
         "0.0362239765881578",
         "0.3522052743277338",
         "599852400.0",
         "0.1229223976148095",
         "0.0354639399260836",
         "1",
         "10",
         "0",
         "1",
         "1"
        ],
        [
         "7",
         "2010-10-27",
         "9.246173220464367",
         "9.313794700391234",
         "9.184561914560437",
         "9.251583099365234",
         "399002800",
         "71.25885639179018",
         "0.2611156099133112",
         "0.2832232190426889",
         "-0.0221076091293777",
         "9.011973190307618",
         "9.706673469769845",
         "8.317272910845393",
         "0.1541727354913517",
         "0.6724556014595972",
         "-0.0007136444114267",
         "0.269199380889076",
         "0.2324830086634044",
         "-0.0086942962093775",
         "0.0731023536932475",
         "9.2669677734375",
         "9.307120418548584",
         "8.362865800857543",
         "8.053839778900146",
         "7.480230104923248",
         "0.0248908886507454",
         "0.3473501397311128",
         "596320340.0",
         "0.1292327858307995",
         "0.0054098789008669",
         "2",
         "10",
         "0",
         "1",
         "1"
        ],
        [
         "8",
         "2010-10-28",
         "9.25518917402218",
         "9.256692319475404",
         "9.043308262739007",
         "9.17374324798584",
         "551051200",
         "63.45476144246014",
         "0.2405838352251113",
         "0.2746953422791733",
         "-0.034111507054062",
         "9.044266605377198",
         "9.703349128875775",
         "8.385184081878618",
         "0.1457459299368125",
         "0.5982249096223542",
         "-0.0084136791015513",
         "0.2731902271108652",
         "0.2281251726054139",
         "-0.0138276206923242",
         "0.0621849743496367",
         "9.241241836547852",
         "9.31592664718628",
         "8.394224452972413",
         "8.070643119812011",
         "7.494444243907928",
         "0.0406398605717292",
         "0.3295412617492898",
         "590203320.0",
         "0.2133840567363982",
         "-0.0814459260363396",
         "3",
         "10",
         "0",
         "1",
         "1"
        ],
        [
         "9",
         "2010-10-29",
         "9.143384023626668",
         "9.19297335523697",
         "9.042401265676084",
         "9.04570770263672",
         "430511200",
         "56.31737095096572",
         "0.2115423290999523",
         "0.2620647396433291",
         "-0.0505224105433768",
         "9.072006559371948",
         "9.677552566068336",
         "8.466460552675558",
         "0.1334977003672517",
         "0.4782850052313078",
         "-0.0139567395650878",
         "0.1662529490860921",
         "0.232616426697941",
         "-0.021107601863723",
         "0.0607223674462167",
         "9.202231788635254",
         "9.274571704864504",
         "8.424939765930176",
         "8.088008437156677",
         "7.50820154428482",
         "0.0964764702519211",
         "0.3027730033481946",
         "589321740.0",
         "0.1505720895608853",
         "-0.0976763209899491",
         "4",
         "10",
         "1",
         "1",
         "1"
        ]
       ],
       "shape": {
        "columns": 35,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>RSI</th>\n",
       "      <th>MACD</th>\n",
       "      <th>MACD_Signal</th>\n",
       "      <th>MACD_Hist</th>\n",
       "      <th>...</th>\n",
       "      <th>STD_5</th>\n",
       "      <th>STD_20</th>\n",
       "      <th>Volume_MA_20</th>\n",
       "      <th>Price_Range</th>\n",
       "      <th>Daily_Change</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Month</th>\n",
       "      <th>Target_1D</th>\n",
       "      <th>Target_1W</th>\n",
       "      <th>Target_1M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-10-18</td>\n",
       "      <td>9.571358</td>\n",
       "      <td>9.587286</td>\n",
       "      <td>9.445731</td>\n",
       "      <td>9.557233</td>\n",
       "      <td>1093010800</td>\n",
       "      <td>82.037075</td>\n",
       "      <td>0.321773</td>\n",
       "      <td>0.264316</td>\n",
       "      <td>0.057457</td>\n",
       "      <td>...</td>\n",
       "      <td>0.269323</td>\n",
       "      <td>0.302132</td>\n",
       "      <td>626992800.0</td>\n",
       "      <td>0.141555</td>\n",
       "      <td>-0.014125</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-10-19</td>\n",
       "      <td>9.118440</td>\n",
       "      <td>9.430101</td>\n",
       "      <td>9.016857</td>\n",
       "      <td>9.301470</td>\n",
       "      <td>1232784000</td>\n",
       "      <td>69.540579</td>\n",
       "      <td>0.322044</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.046182</td>\n",
       "      <td>...</td>\n",
       "      <td>0.231547</td>\n",
       "      <td>0.315237</td>\n",
       "      <td>655228280.0</td>\n",
       "      <td>0.413244</td>\n",
       "      <td>0.183030</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-10-20</td>\n",
       "      <td>9.286742</td>\n",
       "      <td>9.444526</td>\n",
       "      <td>9.222727</td>\n",
       "      <td>9.332725</td>\n",
       "      <td>721624400</td>\n",
       "      <td>74.787064</td>\n",
       "      <td>0.321080</td>\n",
       "      <td>0.284906</td>\n",
       "      <td>0.036175</td>\n",
       "      <td>...</td>\n",
       "      <td>0.178440</td>\n",
       "      <td>0.330682</td>\n",
       "      <td>662045020.0</td>\n",
       "      <td>0.221799</td>\n",
       "      <td>0.045983</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-10-21</td>\n",
       "      <td>9.387726</td>\n",
       "      <td>9.459255</td>\n",
       "      <td>9.220625</td>\n",
       "      <td>9.302373</td>\n",
       "      <td>551460000</td>\n",
       "      <td>75.093013</td>\n",
       "      <td>0.314245</td>\n",
       "      <td>0.290773</td>\n",
       "      <td>0.023471</td>\n",
       "      <td>...</td>\n",
       "      <td>0.113532</td>\n",
       "      <td>0.341182</td>\n",
       "      <td>650312180.0</td>\n",
       "      <td>0.238630</td>\n",
       "      <td>-0.085353</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-10-22</td>\n",
       "      <td>9.288844</td>\n",
       "      <td>9.317997</td>\n",
       "      <td>9.205595</td>\n",
       "      <td>9.240758</td>\n",
       "      <td>372778000</td>\n",
       "      <td>77.737011</td>\n",
       "      <td>0.300393</td>\n",
       "      <td>0.292697</td>\n",
       "      <td>0.007695</td>\n",
       "      <td>...</td>\n",
       "      <td>0.122223</td>\n",
       "      <td>0.348249</td>\n",
       "      <td>636476680.0</td>\n",
       "      <td>0.112402</td>\n",
       "      <td>-0.048086</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2010-10-25</td>\n",
       "      <td>9.289449</td>\n",
       "      <td>9.364884</td>\n",
       "      <td>9.269913</td>\n",
       "      <td>9.281935</td>\n",
       "      <td>392462000</td>\n",
       "      <td>73.117920</td>\n",
       "      <td>0.289402</td>\n",
       "      <td>0.292038</td>\n",
       "      <td>-0.002637</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033848</td>\n",
       "      <td>0.354628</td>\n",
       "      <td>631958040.0</td>\n",
       "      <td>0.094971</td>\n",
       "      <td>-0.007514</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2010-10-26</td>\n",
       "      <td>9.222726</td>\n",
       "      <td>9.308982</td>\n",
       "      <td>9.186059</td>\n",
       "      <td>9.258190</td>\n",
       "      <td>392929600</td>\n",
       "      <td>71.638178</td>\n",
       "      <td>0.275598</td>\n",
       "      <td>0.288750</td>\n",
       "      <td>-0.013152</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036224</td>\n",
       "      <td>0.352205</td>\n",
       "      <td>599852400.0</td>\n",
       "      <td>0.122922</td>\n",
       "      <td>0.035464</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2010-10-27</td>\n",
       "      <td>9.246173</td>\n",
       "      <td>9.313795</td>\n",
       "      <td>9.184562</td>\n",
       "      <td>9.251583</td>\n",
       "      <td>399002800</td>\n",
       "      <td>71.258856</td>\n",
       "      <td>0.261116</td>\n",
       "      <td>0.283223</td>\n",
       "      <td>-0.022108</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024891</td>\n",
       "      <td>0.347350</td>\n",
       "      <td>596320340.0</td>\n",
       "      <td>0.129233</td>\n",
       "      <td>0.005410</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2010-10-28</td>\n",
       "      <td>9.255189</td>\n",
       "      <td>9.256692</td>\n",
       "      <td>9.043308</td>\n",
       "      <td>9.173743</td>\n",
       "      <td>551051200</td>\n",
       "      <td>63.454761</td>\n",
       "      <td>0.240584</td>\n",
       "      <td>0.274695</td>\n",
       "      <td>-0.034112</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040640</td>\n",
       "      <td>0.329541</td>\n",
       "      <td>590203320.0</td>\n",
       "      <td>0.213384</td>\n",
       "      <td>-0.081446</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2010-10-29</td>\n",
       "      <td>9.143384</td>\n",
       "      <td>9.192973</td>\n",
       "      <td>9.042401</td>\n",
       "      <td>9.045708</td>\n",
       "      <td>430511200</td>\n",
       "      <td>56.317371</td>\n",
       "      <td>0.211542</td>\n",
       "      <td>0.262065</td>\n",
       "      <td>-0.050522</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096476</td>\n",
       "      <td>0.302773</td>\n",
       "      <td>589321740.0</td>\n",
       "      <td>0.150572</td>\n",
       "      <td>-0.097676</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date      Open      High       Low     Close      Volume        RSI  \\\n",
       "0  2010-10-18  9.571358  9.587286  9.445731  9.557233  1093010800  82.037075   \n",
       "1  2010-10-19  9.118440  9.430101  9.016857  9.301470  1232784000  69.540579   \n",
       "2  2010-10-20  9.286742  9.444526  9.222727  9.332725   721624400  74.787064   \n",
       "3  2010-10-21  9.387726  9.459255  9.220625  9.302373   551460000  75.093013   \n",
       "4  2010-10-22  9.288844  9.317997  9.205595  9.240758   372778000  77.737011   \n",
       "5  2010-10-25  9.289449  9.364884  9.269913  9.281935   392462000  73.117920   \n",
       "6  2010-10-26  9.222726  9.308982  9.186059  9.258190   392929600  71.638178   \n",
       "7  2010-10-27  9.246173  9.313795  9.184562  9.251583   399002800  71.258856   \n",
       "8  2010-10-28  9.255189  9.256692  9.043308  9.173743   551051200  63.454761   \n",
       "9  2010-10-29  9.143384  9.192973  9.042401  9.045708   430511200  56.317371   \n",
       "\n",
       "       MACD  MACD_Signal  MACD_Hist  ...     STD_5    STD_20  Volume_MA_20  \\\n",
       "0  0.321773     0.264316   0.057457  ...  0.269323  0.302132   626992800.0   \n",
       "1  0.322044     0.275862   0.046182  ...  0.231547  0.315237   655228280.0   \n",
       "2  0.321080     0.284906   0.036175  ...  0.178440  0.330682   662045020.0   \n",
       "3  0.314245     0.290773   0.023471  ...  0.113532  0.341182   650312180.0   \n",
       "4  0.300393     0.292697   0.007695  ...  0.122223  0.348249   636476680.0   \n",
       "5  0.289402     0.292038  -0.002637  ...  0.033848  0.354628   631958040.0   \n",
       "6  0.275598     0.288750  -0.013152  ...  0.036224  0.352205   599852400.0   \n",
       "7  0.261116     0.283223  -0.022108  ...  0.024891  0.347350   596320340.0   \n",
       "8  0.240584     0.274695  -0.034112  ...  0.040640  0.329541   590203320.0   \n",
       "9  0.211542     0.262065  -0.050522  ...  0.096476  0.302773   589321740.0   \n",
       "\n",
       "   Price_Range  Daily_Change  DayOfWeek  Month  Target_1D  Target_1W  \\\n",
       "0     0.141555     -0.014125          0     10          0          0   \n",
       "1     0.413244      0.183030          1     10          1          0   \n",
       "2     0.221799      0.045983          2     10          0          0   \n",
       "3     0.238630     -0.085353          3     10          0          0   \n",
       "4     0.112402     -0.048086          4     10          1          0   \n",
       "5     0.094971     -0.007514          0     10          0          0   \n",
       "6     0.122922      0.035464          1     10          0          1   \n",
       "7     0.129233      0.005410          2     10          0          1   \n",
       "8     0.213384     -0.081446          3     10          0          1   \n",
       "9     0.150572     -0.097676          4     10          1          1   \n",
       "\n",
       "   Target_1M  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          1  \n",
       "5          0  \n",
       "6          1  \n",
       "7          1  \n",
       "8          1  \n",
       "9          1  \n",
       "\n",
       "[10 rows x 35 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Columns:\n",
      "- Date\n",
      "- Open\n",
      "- High\n",
      "- Low\n",
      "- Close\n",
      "- Volume\n",
      "- RSI\n",
      "- MACD\n",
      "- MACD_Signal\n",
      "- MACD_Hist\n",
      "- MA_20\n",
      "- BB_Upper\n",
      "- BB_Lower\n",
      "- BB_Width\n",
      "- BB_Position\n",
      "- Daily_Return\n",
      "- Volatility_10D\n",
      "- Volatility_30D\n",
      "- Weekly_Return\n",
      "- Monthly_Return\n",
      "- MA_5\n",
      "- MA_10\n",
      "- MA_50\n",
      "- MA_100\n",
      "- MA_200\n",
      "- STD_5\n",
      "- STD_20\n",
      "- Volume_MA_20\n",
      "- Price_Range\n",
      "- Daily_Change\n",
      "- DayOfWeek\n",
      "- Month\n",
      "- Target_1D\n",
      "- Target_1W\n",
      "- Target_1M\n",
      "\n",
      "Target distribution:\n",
      "Target_1D: Target_1D\n",
      "1    0.527967\n",
      "0    0.472033\n",
      "Name: proportion, dtype: float64\n",
      "Target_1W: Target_1W\n",
      "1    0.571896\n",
      "0    0.428104\n",
      "Name: proportion, dtype: float64\n",
      "Target_1M: Target_1M\n",
      "1    0.610641\n",
      "0    0.389359\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Uncomment to run after processing at least one stock\n",
    "ticker = 'AAPL'  # Change this to any processed ticker\n",
    "file_path = f'../data/cleaned/{ticker}.csv'\n",
    "\n",
    "if os.path.exists(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Basic info\n",
    "    print(f\"DataFrame shape: {df.shape}\")\n",
    "    print(\"\\nFirst few rows:\")\n",
    "    display(df.head(10))\n",
    "    \n",
    "    print(\"\\nColumns:\")\n",
    "    for col in df.columns:\n",
    "        print(f\"- {col}\")\n",
    "    \n",
    "    # Target distribution\n",
    "    print(\"\\nTarget distribution:\")\n",
    "    print(f\"Target_1D: {df['Target_1D'].value_counts(normalize=True)}\")\n",
    "    print(f\"Target_1W: {df['Target_1W'].value_counts(normalize=True)}\")\n",
    "    print(f\"Target_1M: {df['Target_1M'].value_counts(normalize=True)}\")\n",
    "else:\n",
    "    print(f\"File {file_path} not found. Please process stocks first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook has implemented a comprehensive preprocessing pipeline for stock data that includes:\n",
    "\n",
    "1. Fetching historical stock data using yfinance\n",
    "2. Cleaning the data by handling missing values and timezone information\n",
    "3. Engineering a rich set of features including:\n",
    "   - Returns (daily, weekly, monthly)\n",
    "   - Moving averages\n",
    "   - Technical indicators (RSI, MACD, Bollinger Bands)\n",
    "   - Volatility measures\n",
    "   - Price-based features\n",
    "   - Time-based features\n",
    "4. Creating classification target variables for next day, week, and month price direction\n",
    "5. Saving the processed data to CSV files following the project's naming convention\n",
    "\n",
    "The processed data is ready for use in machine learning models like Prophet, LSTM, and XGBoost."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
