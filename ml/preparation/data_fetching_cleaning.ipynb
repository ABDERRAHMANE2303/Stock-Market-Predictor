{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock Data Collection and Cleaning for Direction Prediction\n",
    "\n",
    "## Objective\n",
    "This notebook fetches historical stock data for 20 selected companies and performs cleaning operations with a focus on preparing data for **direction prediction** rather than exact price prediction. The cleaned datasets will be saved to `data/cleaned/` for further processing by model-specific preparation notebooks.\n",
    "\n",
    "## Purpose\n",
    "The goal is to create a clean dataset with appropriate features and multiple target variables for different prediction horizons, but focusing on price movement direction rather than exact prices:\n",
    "- Next day price direction (up or down)\n",
    "- Next week price direction (up or down)\n",
    "- Next month price direction (up or down)\n",
    "\n",
    "Each of these targets will be used to train separate specialized models, allowing for higher accuracy across different prediction timeframes.\n",
    "\n",
    "## Steps:\n",
    "1. Import necessary libraries\n",
    "2. Define companies list\n",
    "3. Fetch historical data using yfinance\n",
    "4. Perform basic cleaning\n",
    "5. Add direction prediction targets for multiple timeframes\n",
    "6. Visualize the data\n",
    "7. Save cleaned datasets\n",
    "8. Perform data quality checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define Stock List\n",
    "\n",
    "We'll use a predefined list of 20 companies representing different sectors for our analysis. This provides a diverse dataset for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define list of companies with symbols\n",
    "stocks = [\n",
    "    \"AAPL\", \"MSFT\", \"GOOG\", \"AMZN\", \"TSLA\", \n",
    "    \"META\", \"NVDA\", \"SPY\", \"V\", \"DIS\", \n",
    "    \"NFLX\", \"PYPL\", \"BABA\", \"IBM\", \"AMD\", \n",
    "    \"BA\", \"INTC\", \"T\", \"GS\", \"NKE\"\n",
    "]\n",
    "    \n",
    "print(f\"Total stocks to analyze: {len(stocks)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create Output Directory\n",
    "\n",
    "Define and create the directory where cleaned data will be stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory if it doesn't exist\n",
    "output_dir = '../data/cleaned/'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "print(f\"Output directory: {os.path.abspath(output_dir)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define Data Fetching Function\n",
    "\n",
    "This function fetches historical data for a given stock ticker using the yfinance library. We'll retrieve 10 years of data to ensure we have sufficient history for training our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_stock_data(ticker, start_date, end_date):\n",
    "    \"\"\"\n",
    "    Fetch historical stock data for a given ticker symbol.\n",
    "    \n",
    "    Parameters:\n",
    "    - ticker: Stock symbol\n",
    "    - start_date: Start date for historical data\n",
    "    - end_date: End date for historical data\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame with historical stock data\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Fetch data using yfinance\n",
    "        stock = yf.Ticker(ticker)\n",
    "        df = stock.history(start=start_date, end=end_date)\n",
    "        \n",
    "        # Check if we got any data\n",
    "        if df.empty:\n",
    "            print(f\"No data found for {ticker}\")\n",
    "            return None\n",
    "        \n",
    "        # Add ticker column\n",
    "        df['Symbol'] = ticker\n",
    "        \n",
    "        # Get company info for additional metadata\n",
    "        try:\n",
    "            info = stock.info\n",
    "            df['Sector'] = info.get('sector', 'Unknown')\n",
    "            df['Industry'] = info.get('industry', 'Unknown')\n",
    "        except:\n",
    "            print(f\"Could not retrieve company info for {ticker}\")\n",
    "            df['Sector'] = 'Unknown'\n",
    "            df['Industry'] = 'Unknown'\n",
    "        \n",
    "        print(f\"Successfully fetched data for {ticker}: {len(df)} rows\")\n",
    "        return df\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data for {ticker}: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Define Data Cleaning Function\n",
    "\n",
    "This function performs essential cleaning operations and feature engineering on the raw stock data. Key components include:\n",
    "\n",
    "1. Basic cleaning (standardizing column names, handling missing values)\n",
    "2. Feature engineering (moving averages, volatility, returns)\n",
    "3. Creating prediction targets for three different time horizons, focusing on **direction** rather than exact prices:\n",
    "   - Next day price direction (1 = up, 0 = down)\n",
    "   - Next week price direction (1 = up, 0 = down)\n",
    "   - Next month price direction (1 = up, 0 = down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_stock_data(df):\n",
    "    \"\"\"\n",
    "    Perform basic cleaning operations on stock data and create direction prediction targets.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: DataFrame with stock data\n",
    "    \n",
    "    Returns:\n",
    "    - Cleaned DataFrame with direction prediction targets\n",
    "    \"\"\"\n",
    "    if df is None or df.empty:\n",
    "        return None\n",
    "    \n",
    "    # Make a copy to avoid modifying the original DataFrame\n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    # Reset index to make Date a column\n",
    "    df_clean = df_clean.reset_index()\n",
    "    \n",
    "    # Ensure Date column is datetime\n",
    "    df_clean['Date'] = pd.to_datetime(df_clean['Date'])\n",
    "    \n",
    "    # Rename columns to standard format\n",
    "    df_clean = df_clean.rename(columns={\n",
    "        'Open': 'open',\n",
    "        'High': 'high',\n",
    "        'Low': 'low',\n",
    "        'Close': 'close',\n",
    "        'Volume': 'volume',\n",
    "        'Dividends': 'dividends',\n",
    "        'Stock Splits': 'splits',\n",
    "        'Symbol': 'symbol',\n",
    "        'Date': 'date'\n",
    "    })\n",
    "    \n",
    "    # Handle missing values\n",
    "    df_clean[['open', 'high', 'low', 'close']] = df_clean[['open', 'high', 'low', 'close']].fillna(method='ffill')\n",
    "    df_clean['volume'] = df_clean['volume'].fillna(0)\n",
    "    df_clean['dividends'] = df_clean['dividends'].fillna(0)\n",
    "    df_clean['splits'] = df_clean['splits'].fillna(0)\n",
    "    \n",
    "    # Add derived features\n",
    "    df_clean['return'] = df_clean['close'].pct_change()  # Daily returns\n",
    "    \n",
    "    # Moving averages\n",
    "    df_clean['ma5'] = df_clean['close'].rolling(window=5).mean()\n",
    "    df_clean['ma20'] = df_clean['close'].rolling(window=20).mean()\n",
    "    df_clean['ma50'] = df_clean['close'].rolling(window=50).mean()\n",
    "    \n",
    "    # Price to MA ratios (useful for trend direction)\n",
    "    df_clean['price_to_ma5'] = df_clean['close'] / df_clean['ma5']\n",
    "    df_clean['price_to_ma20'] = df_clean['close'] / df_clean['ma20']\n",
    "    df_clean['price_to_ma50'] = df_clean['close'] / df_clean['ma50']\n",
    "    \n",
    "    # MA crossovers (useful for trend changes)\n",
    "    df_clean['ma5_cross_ma20'] = (df_clean['ma5'] > df_clean['ma20']).astype(int)\n",
    "    df_clean['ma20_cross_ma50'] = (df_clean['ma20'] > df_clean['ma50']).astype(int)\n",
    "    \n",
    "    # Volatility and volume features\n",
    "    df_clean['volatility'] = df_clean['return'].rolling(window=20).std()\n",
    "    df_clean['volume_ma20'] = df_clean['volume'].rolling(window=20).mean()\n",
    "    df_clean['rel_volume'] = df_clean['volume'] / df_clean['volume_ma20']\n",
    "    \n",
    "    # Date features\n",
    "    df_clean['day_of_week'] = df_clean['date'].dt.dayofweek\n",
    "    df_clean['month'] = df_clean['date'].dt.month\n",
    "    df_clean['year'] = df_clean['date'].dt.year\n",
    "    \n",
    "    # RSI (Relative Strength Index) - simple version\n",
    "    delta = df_clean['close'].diff()\n",
    "    gain = delta.where(delta > 0, 0)\n",
    "    loss = -delta.where(delta < 0, 0)\n",
    "    avg_gain = gain.rolling(window=14).mean()\n",
    "    avg_loss = loss.rolling(window=14).mean()\n",
    "    rs = avg_gain / avg_loss\n",
    "    df_clean['rsi'] = 100 - (100 / (1 + rs))\n",
    "    \n",
    "    # Handle NaN values created by rolling calculations\n",
    "    df_clean = df_clean.fillna(method='bfill')\n",
    "    df_clean = df_clean.dropna()\n",
    "    \n",
    "    # Drop rows with extreme values (potential data errors)\n",
    "    df_clean = df_clean[(df_clean['return'] > -0.5) & (df_clean['return'] < 0.5)]\n",
    "    \n",
    "    # Create the next day close price (for reference)\n",
    "    df_clean['next_day_close'] = df_clean['close'].shift(-1)\n",
    "    \n",
    "    # Create direction prediction targets for multiple timeframes\n",
    "    # 1. Next day direction (1 = up, 0 = down)\n",
    "    df_clean['next_day_direction'] = (df_clean['next_day_close'] > df_clean['close']).astype(int)\n",
    "    \n",
    "    # 2. Next week direction (comparing current close with average close of next 5 trading days)\n",
    "    shifted_close = pd.Series(df_clean['close'].values)\n",
    "    next_week_avgs = []\n",
    "    for i in range(len(shifted_close)):\n",
    "        if i + 5 < len(shifted_close):\n",
    "            next_week_avgs.append(shifted_close[i+1:i+6].mean())\n",
    "        else:\n",
    "            next_week_avgs.append(np.nan)\n",
    "    df_clean['next_week_avg'] = next_week_avgs\n",
    "    df_clean['next_week_direction'] = (df_clean['next_week_avg'] > df_clean['close']).astype(int)\n",
    "    \n",
    "    # 3. Next month direction (comparing current close with average close of next 21 trading days)\n",
    "    next_month_avgs = []\n",
    "    for i in range(len(shifted_close)):\n",
    "        if i + 21 < len(shifted_close):\n",
    "            next_month_avgs.append(shifted_close[i+1:i+22].mean())\n",
    "        else:\n",
    "            next_month_avgs.append(np.nan)\n",
    "    df_clean['next_month_avg'] = next_month_avgs\n",
    "    df_clean['next_month_direction'] = (df_clean['next_month_avg'] > df_clean['close']).astype(int)\n",
    "    \n",
    "    # Drop rows with NaN prediction targets (last 21 days of data)\n",
    "    df_clean = df_clean.dropna()\n",
    "    \n",
    "    return df_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Define Visualization Function\n",
    "\n",
    "This function creates visualizations to help understand the data and verify the cleaning process was successful. The visualizations now focus on direction prediction rather than exact price prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_stock_data(df, ticker):\n",
    "    \"\"\"\n",
    "    Create visualizations for the stock data with a focus on direction prediction.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: DataFrame with stock data\n",
    "    - ticker: Stock symbol\n",
    "    \"\"\"\n",
    "    if df is None or df.empty:\n",
    "        print(f\"No data to visualize for {ticker}\")\n",
    "        return\n",
    "    \n",
    "    # Create figure with subplots\n",
    "    fig, axes = plt.subplots(4, 1, figsize=(14, 20))\n",
    "    \n",
    "    # Plot 1: Price history with moving averages\n",
    "    axes[0].plot(df['date'], df['close'], label='Close Price')\n",
    "    axes[0].plot(df['date'], df['ma20'], label='20-day MA', alpha=0.7)\n",
    "    axes[0].plot(df['date'], df['ma50'], label='50-day MA', alpha=0.7)\n",
    "    axes[0].set_title(f'{ticker} - Price History with Moving Averages')\n",
    "    axes[0].set_ylabel('Price ($)')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True)\n",
    "    \n",
    "    # Plot 2: Volume and RSI\n",
    "    ax2 = axes[1]\n",
    "    ax2.bar(df['date'], df['volume'], alpha=0.3, color='blue')\n",
    "    ax2.set_ylabel('Volume', color='blue')\n",
    "    ax2.tick_params(axis='y', labelcolor='blue')\n",
    "    ax2.set_title(f'{ticker} - Volume and RSI')\n",
    "    \n",
    "    ax2b = ax2.twinx()\n",
    "    ax2b.plot(df['date'], df['rsi'], color='red', alpha=0.7)\n",
    "    ax2b.axhline(y=70, color='green', linestyle='--', alpha=0.5)  # Overbought line\n",
    "    ax2b.axhline(y=30, color='green', linestyle='--', alpha=0.5)  # Oversold line\n",
    "    ax2b.set_ylabel('RSI', color='red')\n",
    "    ax2b.tick_params(axis='y', labelcolor='red')\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    # Plot 3: Returns and Volatility\n",
    "    ax3 = axes[2]\n",
    "    ax3.plot(df['date'], df['return'], label='Daily Returns', alpha=0.5, color='green')\n",
    "    ax3.set_ylabel('Returns', color='green')\n",
    "    ax3.tick_params(axis='y', labelcolor='green')\n",
    "    ax3.set_title(f'{ticker} - Returns and Volatility')\n",
    "    \n",
    "    ax3b = ax3.twinx()\n",
    "    ax3b.plot(df['date'], df['volatility'], label='Volatility (20-day)', color='red', alpha=0.7)\n",
    "    ax3b.set_ylabel('Volatility', color='red')\n",
    "    ax3b.tick_params(axis='y', labelcolor='red')\n",
    "    \n",
    "    lines1, labels1 = ax3.get_legend_handles_labels()\n",
    "    lines2, labels2 = ax3b.get_legend_handles_labels()\n",
    "    ax3.legend(lines1 + lines2, labels1 + labels2, loc='upper left')\n",
    "    ax3.grid(True)\n",
    "    \n",
    "    # Plot 4: Direction Prediction Targets (visualization for last 90 days)\n",
    "    last_90_days = df.iloc[-90:].copy()  # Focus on last 90 days for clarity\n",
    "    \n",
    "    # Create shaded regions for direction prediction\n",
    "    ax4 = axes[3]\n",
    "    ax4.plot(last_90_days['date'], last_90_days['close'], label='Close Price', color='black')\n",
    "    \n",
    "    # Color the background based on next day direction\n",
    "    for i in range(len(last_90_days)-1):\n",
    "        if last_90_days.iloc[i]['next_day_direction'] == 1:  # Up prediction\n",
    "            ax4.axvspan(last_90_days.iloc[i]['date'], last_90_days.iloc[i+1]['date'], \n",
    "                        alpha=0.2, color='green')\n",
    "        else:  # Down prediction\n",
    "            ax4.axvspan(last_90_days.iloc[i]['date'], last_90_days.iloc[i+1]['date'], \n",
    "                        alpha=0.2, color='red')\n",
    "    \n",
    "    ax4.set_title(f'{ticker} - Price with Next-Day Direction (Green=Up, Red=Down)')\n",
    "    ax4.set_ylabel('Price ($)')\n",
    "    ax4.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Prediction Target Distribution\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    \n",
    "    # Direction prediction distribution\n",
    "    labels = ['Down (0)', 'Up (1)']\n",
    "    \n",
    "    # Create a 1x3 subplot for the three direction targets\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "    \n",
    "    # Next day direction\n",
    "    day_counts = df['next_day_direction'].value_counts()\n",
    "    day_pct = 100 * day_counts / len(df)\n",
    "    axes[0].bar([0, 1], [day_counts.get(0, 0), day_counts.get(1, 0)], color=['red', 'green'])\n",
    "    axes[0].set_title(f'Next Day Direction\\nUp: {day_pct.get(1, 0):.1f}%, Down: {day_pct.get(0, 0):.1f}%')\n",
    "    axes[0].set_xticks([0, 1])\n",
    "    axes[0].set_xticklabels(labels)\n",
    "    axes[0].set_ylabel('Count')\n",
    "    \n",
    "    # Next week direction\n",
    "    week_counts = df['next_week_direction'].value_counts()\n",
    "    week_pct = 100 * week_counts / len(df)\n",
    "    axes[1].bar([0, 1], [week_counts.get(0, 0), week_counts.get(1, 0)], color=['red', 'green'])\n",
    "    axes[1].set_title(f'Next Week Direction\\nUp: {week_pct.get(1, 0):.1f}%, Down: {week_pct.get(0, 0):.1f}%')\n",
    "    axes[1].set_xticks([0, 1])\n",
    "    axes[1].set_xticklabels(labels)\n",
    "    \n",
    "    # Next month direction\n",
    "    month_counts = df['next_month_direction'].value_counts()\n",
    "    month_pct = 100 * month_counts / len(df)\n",
    "    axes[2].bar([0, 1], [month_counts.get(0, 0), month_counts.get(1, 0)], color=['red', 'green'])\n",
    "    axes[2].set_title(f'Next Month Direction\\nUp: {month_pct.get(1, 0):.1f}%, Down: {month_pct.get(0, 0):.1f}%')\n",
    "    axes[2].set_xticks([0, 1])\n",
    "    axes[2].set_xticklabels(labels)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.suptitle(f\"{ticker} - Direction Prediction Target Distribution\", y=1.05, fontsize=16)\n",
    "    plt.show()\n",
    "    \n",
    "    # Correlation matrix with a focus on predictive features and targets\n",
    "    plt.figure(figsize=(14, 12))\n",
    "    features = ['close', 'return', 'ma5', 'ma20', 'ma50', 'price_to_ma5', 'price_to_ma20',\n",
    "                'ma5_cross_ma20', 'ma20_cross_ma50', 'volatility', 'rel_volume', 'rsi',\n",
    "                'next_day_direction', 'next_week_direction', 'next_month_direction']\n",
    "    \n",
    "    corr = df[features].corr()\n",
    "    mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "    sns.heatmap(corr, mask=mask, cmap='coolwarm', vmin=-1, vmax=1, center=0,\n",
    "                square=True, linewidths=.5, cbar_kws={\"shrink\": .5}, annot=True, fmt='.2f')\n",
    "    \n",
    "    plt.title(f'{ticker} - Feature Correlation Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Fetch and Clean Data for All Stocks\n",
    "\n",
    "Now we'll fetch and clean data for all stocks in our list, creating standardized datasets ready for direction prediction model preparation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define date range (10 years of data)\n",
    "end_date = datetime.now()\n",
    "start_date = end_date - timedelta(days=365*10)  # 10 years\n",
    "\n",
    "print(f\"Fetching data from {start_date.strftime('%Y-%m-%d')} to {end_date.strftime('%Y-%m-%d')}\")\n",
    "\n",
    "# Process each stock\n",
    "results = {}\n",
    "\n",
    "for ticker in tqdm(stocks, desc=\"Processing stocks\"):\n",
    "    print(f\"\\nProcessing {ticker}...\")\n",
    "    \n",
    "    # Fetch data\n",
    "    df = fetch_stock_data(ticker, start_date, end_date)\n",
    "    \n",
    "    if df is not None and not df.empty:\n",
    "        # Clean data\n",
    "        cleaned_df = clean_stock_data(df)\n",
    "        \n",
    "        if cleaned_df is not None and not cleaned_df.empty:\n",
    "            results[ticker] = cleaned_df\n",
    "            print(f\"Cleaned data shape for {ticker}: {cleaned_df.shape}\")\n",
    "            \n",
    "            # Save cleaned data\n",
    "            output_file = os.path.join(output_dir, f\"{ticker}.csv\")\n",
    "            cleaned_df.to_csv(output_file, index=False)\n",
    "            print(f\"Saved cleaned data to {output_file}\")\n",
    "            \n",
    "            # Print class distribution for direction prediction\n",
    "            day_up_pct = 100 * cleaned_df['next_day_direction'].mean()\n",
    "            week_up_pct = 100 * cleaned_df['next_week_direction'].mean()\n",
    "            month_up_pct = 100 * cleaned_df['next_month_direction'].mean()\n",
    "            \n",
    "            print(f\"Direction prediction class distribution:\")\n",
    "            print(f\"  - Next day: {day_up_pct:.1f}% Up, {100-day_up_pct:.1f}% Down\")\n",
    "            print(f\"  - Next week: {week_up_pct:.1f}% Up, {100-week_up_pct:.1f}% Down\")\n",
    "            print(f\"  - Next month: {month_up_pct:.1f}% Up, {100-month_up_pct:.1f}% Down\")\n",
    "        else:\n",
    "            print(f\"No clean data available for {ticker} after processing\")\n",
    "    else:\n",
    "        print(f\"Skipping {ticker} due to data fetch issues\")\n",
    "\n",
    "print(f\"\\nSuccessfully processed {len(results)} out of {len(stocks)} stocks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualize Sample Stock Data\n",
    "\n",
    "Let's visualize a few stocks to understand their patterns and verify our data processing was successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check a sample of the cleaned data\n",
    "sample_file = os.path.join(output_dir, \"AAPL.csv\")\n",
    "if os.path.exists(sample_file):\n",
    "    df = pd.read_csv(sample_file)\n",
    "    print(\"Sample of cleaned data:\")\n",
    "    display(df.head(2))\n",
    "    \n",
    "    # Display direction prediction targets\n",
    "    direction_cols = ['date', 'close', 'next_day_close', 'next_day_direction', \n",
    "                      'next_week_avg', 'next_week_direction', \n",
    "                      'next_month_avg', 'next_month_direction']\n",
    "    \n",
    "    print(\"\\nDirection prediction targets:\")\n",
    "    display(df[direction_cols].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a few selected stocks\n",
    "sample_stocks = ['AAPL', 'TSLA', 'NVDA', 'AMZN']\n",
    "\n",
    "for ticker in sample_stocks:\n",
    "    if ticker in results:\n",
    "        print(f\"\\nVisualizing {ticker}...\")\n",
    "        visualize_stock_data(results[ticker], ticker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Data Quality Checks\n",
    "\n",
    "Let's perform some additional data quality checks to verify our datasets are ready for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display class balance statistics for all stocks\n",
    "class_balance = {}\n",
    "\n",
    "for ticker, df in results.items():\n",
    "    day_up_pct = 100 * df['next_day_direction'].mean()\n",
    "    week_up_pct = 100 * df['next_week_direction'].mean()\n",
    "    month_up_pct = 100 * df['next_month_direction'].mean()\n",
    "    \n",
    "    class_balance[ticker] = {\n",
    "        'day_up': day_up_pct,\n",
    "        'week_up': week_up_pct,\n",
    "        'month_up': month_up_pct\n",
    "    }\n",
    "\n",
    "class_balance_df = pd.DataFrame(class_balance).T\n",
    "class_balance_df.columns = ['Next Day % Up', 'Next Week % Up', 'Next Month % Up']\n",
    "\n",
    "# Add overall average\n",
    "class_balance_df.loc['AVERAGE'] = class_balance_df.mean()\n",
    "\n",
    "print(\"Class balance (% Up) for all stocks:\")\n",
    "display(class_balance_df)\n",
    "\n",
    "# Visualize class balance\n",
    "plt.figure(figsize=(12, 6))\n",
    "class_balance_df.iloc[:-1].plot(kind='bar', alpha=0.7)\n",
    "plt.axhline(y=50, color='r', linestyle='--', label='Balanced (50%)')\n",
    "plt.title('Direction Prediction Class Balance (% Up Direction) by Stock')\n",
    "plt.ylabel('Percentage (%)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Examine Feature Importance\n",
    "\n",
    "Let's examine which features might be most important for direction prediction across all stocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an aggregated correlation matrix for all stocks\n",
    "all_corrs = []\n",
    "\n",
    "features = [\n",
    "    'return', 'ma5', 'ma20', 'ma50', 'price_to_ma5', 'price_to_ma20', 'price_to_ma50',\n",
    "    'ma5_cross_ma20', 'ma20_cross_ma50', 'volatility', 'rel_volume', 'rsi'\n",
    "]\n",
    "\n",
    "targets = ['next_day_direction', 'next_week_direction', 'next_month_direction']\n",
    "\n",
    "for ticker, df in results.items():\n",
    "    # Calculate correlation between features and targets\n",
    "    corr = pd.DataFrame(index=features)\n",
    "    \n",
    "    for target in targets:\n",
    "        corr[f\"{target}_{ticker}\"] = [df[feature].corr(df[target]) for feature in features]\n",
    "    \n",
    "    all_corrs.append(corr)\n",
    "\n",
    "# Combine all correlations\n",
    "combined_corr = pd.concat(all_corrs, axis=1)\n",
    "\n",
    "# Calculate average correlation for each feature and target horizon\n",
    "avg_corr = pd.DataFrame(index=features)\n",
    "\n",
    "for target in targets:\n",
    "    target_cols = [col for col in combined_corr.columns if col.startswith(target)]\n",
    "    avg_corr[target.replace('next_', 'avg_')] = combined_corr[target_cols].mean(axis=1)\n",
    "\n",
    "# Sort features by absolute correlation for each target\n",
    "for col in avg_corr.columns:\n",
    "    avg_corr[f\"{col}_abs\"] = avg_corr[col].abs()\n",
    "\n",
    "day_sorted = avg_corr.sort_values('avg_day_direction_abs', ascending=False)\n",
    "week_sorted = avg_corr.sort_values('avg_week_direction_abs', ascending=False)\n",
    "month_sorted = avg_corr.sort_values('avg_month_direction_abs', ascending=False)\n",
    "\n",
    "# Display average correlations\n",
    "print(\"Average feature correlation with direction targets across all stocks:\")\n",
    "display(avg_corr[['avg_day_direction', 'avg_week_direction', 'avg_month_direction']])\n",
    "\n",
    "# Visualize top features by correlation\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Create a heatmap of average correlations\n",
    "sns.heatmap(\n",
    "    avg_corr[['avg_day_direction', 'avg_week_direction', 'avg_month_direction']],\n",
    "    annot=True,\n",
    "    cmap='coolwarm',\n",
    "    vmin=-0.3,\n",
    "    vmax=0.3,\n",
    "    center=0,\n",
    "    fmt='.3f'\n",
    ")\n",
    "\n",
    "plt.title('Average Feature Correlation with Direction Targets')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Conclusion and Next Steps\n",
    "\n",
    "We have successfully:\n",
    "1. Fetched 10 years of historical data for 20 stocks\n",
    "2. Cleaned and processed the data\n",
    "3. Added derived features relevant for direction prediction (moving averages, RSI, price/MA ratios, etc.)\n",
    "4. Created direction prediction targets for three time horizons: next day, next week, and next month\n",
    "5. Visualized the data to understand patterns and verify correctness\n",
    "6. Saved cleaned datasets to `data/cleaned/` for further processing\n",
    "7. Analyzed class balance and feature importance\n",
    "\n",
    "### Key Insights\n",
    "- We've created binary classification targets for price direction prediction at 3 different time horizons\n",
    "- The class balance is usually not perfectly balanced (not exactly 50/50), which is expected in real market data\n",
    "- Various technical indicators show different correlation strengths with direction targets\n",
    "- Longer-term direction prediction (week, month) tends to show higher correlations with technical indicators\n",
    "\n",
    "### Next Steps\n",
    "The cleaned datasets are now ready to be used in model-specific preparation notebooks for binary classification models. We'll create separate models for each prediction horizon using the same underlying dataset:\n",
    "\n",
    "1. Day direction model: Trained to predict `next_day_direction`\n",
    "2. Week direction model: Trained to predict `next_week_direction`\n",
    "3. Month direction model: Trained to predict `next_month_direction`\n",
    "\n",
    "Since we're now working with binary classification instead of regression, we'll need to use appropriate classification metrics (accuracy, precision, recall, F1 score, etc.) and models suited for classification tasks (Random Forest, XGBoost, Logistic Regression, etc.)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
