{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock Data Preprocessing Pipeline\n",
    "\n",
    "This notebook implements a comprehensive preprocessing pipeline for stock data to prepare it for machine learning models including Prophet, LSTM, and XGBoost.\n",
    "\n",
    "## Pipeline Steps:\n",
    "1. Fetch daily stock data using yfinance\n",
    "2. Clean the data (handle missing values, sort by date, etc.)\n",
    "3. Engineer features (returns, moving averages, technical indicators, etc.)\n",
    "4. Create target variables for classification\n",
    "5. Save processed data to CSV files\n",
    "\n",
    "The processed data will follow the project's structure conventions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Stock Tickers\n",
    "\n",
    "These are the 20 stocks selected for the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = [\n",
    "    'AAPL',  # Apple Inc.\n",
    "    'MSFT',  # Microsoft Corporation\n",
    "    'GOOG',  # Alphabet Inc. (Google)\n",
    "    'AMZN',  # Amazon.com, Inc.\n",
    "    'TSLA',  # Tesla, Inc.\n",
    "    'META',  # Meta Platforms, Inc. (formerly Facebook)\n",
    "    'NVDA',  # NVIDIA Corporation\n",
    "    'SPY',   # SPDR S&P 500 ETF Trust\n",
    "    'V',     # Visa Inc.\n",
    "    'DIS',   # The Walt Disney Company\n",
    "    'NFLX',  # Netflix, Inc.\n",
    "    'PYPL',  # PayPal Holdings, Inc.\n",
    "    'BABA',  # Alibaba Group\n",
    "    'IBM',   # International Business Machines Corporation\n",
    "    'AMD',   # Advanced Micro Devices, Inc.\n",
    "    'BA',    # The Boeing Company\n",
    "    'INTC',  # Intel Corporation\n",
    "    'T',     # AT&T Inc.\n",
    "    'GS',    # Goldman Sachs Group, Inc.\n",
    "    'NKE'    # Nike, Inc.\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_stock_data(ticker, start_date='2010-01-01', end_date=None):\n",
    "    \"\"\"\n",
    "    Fetch stock data for a given ticker using yfinance\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    ticker : str\n",
    "        Stock ticker symbol\n",
    "    start_date : str\n",
    "        Start date in 'YYYY-MM-DD' format\n",
    "    end_date : str\n",
    "        End date in 'YYYY-MM-DD' format, default is today\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        DataFrame containing stock data\n",
    "    \"\"\"\n",
    "    if end_date is None:\n",
    "        end_date = datetime.today().strftime('%Y-%m-%d')\n",
    "        \n",
    "    stock = yf.Ticker(ticker)\n",
    "    data = stock.history(start=start_date, end=end_date)\n",
    "    \n",
    "    print(f\"Fetched {len(data)} rows of data for {ticker} from {start_date} to {end_date}\")\n",
    "    print(data.head(5))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_stock_data(df):\n",
    "    \"\"\"\n",
    "    Clean stock data by handling missing values, sorting by date, etc.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        DataFrame containing stock data\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        Cleaned DataFrame\n",
    "    \"\"\"\n",
    "    # Make a copy to avoid modifying the original data\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Reset index to keep Date as a column\n",
    "    df = df.reset_index()\n",
    "    \n",
    "    # Remove timezone info from Date column\n",
    "    df['Date'] = df['Date'].dt.tz_localize(None)\n",
    "    \n",
    "    # Sort data by date (ascending) and reset index\n",
    "    df = df.sort_values('Date').reset_index(drop=True)\n",
    "    \n",
    "    # Drop duplicate rows\n",
    "    df = df.drop_duplicates(subset=['Date'])\n",
    "    \n",
    "    # Replace Volume = 0 with NaN\n",
    "    df.loc[df['Volume'] == 0, 'Volume'] = np.nan\n",
    "    \n",
    "    # Handle missing values: Forward fill for price columns\n",
    "    for col in ['Open', 'High', 'Low', 'Close']:\n",
    "        df[col] = df[col].ffill()\n",
    "    \n",
    "    # Forward fill for Volume\n",
    "    df['Volume'] = df['Volume'].ffill()\n",
    "    \n",
    "    # Drop any remaining rows with NaNs\n",
    "    df = df.dropna()\n",
    "    \n",
    "    # Ensure integer type for Volume\n",
    "    df['Volume'] = df['Volume'].astype(int)\n",
    "    \n",
    "    # Set Date as index again for feature engineering\n",
    "    df = df.set_index('Date')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_technical_indicators(df):\n",
    "    \"\"\"\n",
    "    Add technical indicators to the DataFrame\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        DataFrame containing stock data\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        DataFrame with added technical indicators\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Calculate RSI (Relative Strength Index)\n",
    "    delta = df['Close'].diff()\n",
    "    gain = delta.where(delta > 0, 0)\n",
    "    loss = -delta.where(delta < 0, 0)\n",
    "    \n",
    "    avg_gain = gain.rolling(window=14).mean()\n",
    "    avg_loss = loss.rolling(window=14).mean()\n",
    "    \n",
    "    rs = avg_gain / avg_loss\n",
    "    df['RSI'] = 100 - (100 / (1 + rs))\n",
    "    \n",
    "    # Calculate MACD (Moving Average Convergence Divergence)\n",
    "    exp1 = df['Close'].ewm(span=12, adjust=False).mean()\n",
    "    exp2 = df['Close'].ewm(span=26, adjust=False).mean()\n",
    "    df['MACD'] = exp1 - exp2\n",
    "    df['MACD_Signal'] = df['MACD'].ewm(span=9, adjust=False).mean()\n",
    "    df['MACD_Hist'] = df['MACD'] - df['MACD_Signal']\n",
    "    \n",
    "    # Calculate Bollinger Bands\n",
    "    df['MA_20'] = df['Close'].rolling(window=20).mean()\n",
    "    df['BB_Upper'] = df['MA_20'] + (df['Close'].rolling(window=20).std() * 2)\n",
    "    df['BB_Lower'] = df['MA_20'] - (df['Close'].rolling(window=20).std() * 2)\n",
    "    \n",
    "    # Calculate BB width and position\n",
    "    df['BB_Width'] = (df['BB_Upper'] - df['BB_Lower']) / df['MA_20']\n",
    "    df['BB_Position'] = (df['Close'] - df['BB_Lower']) / (df['BB_Upper'] - df['BB_Lower'])\n",
    "    \n",
    "    # Calculate Volatility (historical) - Daily returns standard deviation over different windows\n",
    "    df['Daily_Return'] = df['Close'].pct_change()\n",
    "    df['Volatility_10D'] = df['Daily_Return'].rolling(window=10).std() * np.sqrt(252)  # Annualized\n",
    "    df['Volatility_30D'] = df['Daily_Return'].rolling(window=30).std() * np.sqrt(252)  # Annualized\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def engineer_features(df):\n",
    "    \"\"\"\n",
    "    Engineer features for machine learning models\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        DataFrame containing clean stock data\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        DataFrame with engineered features\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # --- Technical indicators ---\n",
    "    df = add_technical_indicators(df)\n",
    "    \n",
    "    # --- Returns ---\n",
    "    # Daily return (already calculated in technical indicators function)\n",
    "    \n",
    "    # Weekly return (5 trading days)\n",
    "    df['Weekly_Return'] = df['Close'].pct_change(5)\n",
    "    \n",
    "    # Monthly return (21 trading days)\n",
    "    df['Monthly_Return'] = df['Close'].pct_change(21)\n",
    "    \n",
    "    # --- Moving averages ---\n",
    "    # MA_20 is already calculated for Bollinger Bands\n",
    "    df['MA_5'] = df['Close'].rolling(window=5).mean()\n",
    "    df['MA_10'] = df['Close'].rolling(window=10).mean()\n",
    "    df['MA_50'] = df['Close'].rolling(window=50).mean()\n",
    "    df['MA_100'] = df['Close'].rolling(window=100).mean()\n",
    "    df['MA_200'] = df['Close'].rolling(window=200).mean()\n",
    "    \n",
    "    # --- Rolling standard deviation ---\n",
    "    df['STD_5'] = df['Close'].rolling(window=5).std()\n",
    "    df['STD_20'] = df['Close'].rolling(window=20).std()\n",
    "    \n",
    "    # --- Average volume ---\n",
    "    df['Volume_MA_20'] = df['Volume'].rolling(window=20).mean()\n",
    "    \n",
    "    # --- Price range ---\n",
    "    df['Price_Range'] = df['High'] - df['Low']\n",
    "    \n",
    "    # --- Daily change ---\n",
    "    df['Daily_Change'] = df['Close'] - df['Open']\n",
    "    \n",
    "    # --- Time-based features ---\n",
    "    # Reset index to get the Date as a column for time-based features\n",
    "    df = df.reset_index()\n",
    "    df['DayOfWeek'] = df['Date'].dt.dayofweek\n",
    "    df['Month'] = df['Date'].dt.month\n",
    "    \n",
    "    # Set Date back as index\n",
    "    df = df.set_index('Date')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_target_variables(df):\n",
    "    \"\"\"\n",
    "    Create target variables for classification\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        DataFrame with engineered features\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        DataFrame with target variables\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Target for next day (1 day ahead)\n",
    "    df['Target_1D'] = np.where(df['Close'].shift(-1) > df['Close'], 1, 0)\n",
    "    \n",
    "    # Target for next week (5 trading days ahead)\n",
    "    df['Target_1W'] = np.where(df['Close'].shift(-5) > df['Close'], 1, 0)\n",
    "    \n",
    "    # Target for next month (21 trading days ahead)\n",
    "    df['Target_1M'] = np.where(df['Close'].shift(-21) > df['Close'], 1, 0)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_directories():\n",
    "    \"\"\"\n",
    "    Create directories for storing processed data\n",
    "    \"\"\"\n",
    "    os.makedirs('../data/cleaned', exist_ok=True)\n",
    "    print(\"Created directory: ../data/cleaned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_stock(ticker, start_date='2010-01-01', end_date=None):\n",
    "    \"\"\"\n",
    "    Process stock data for a given ticker through the entire pipeline\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    ticker : str\n",
    "        Stock ticker symbol\n",
    "    start_date : str\n",
    "        Start date in 'YYYY-MM-DD' format\n",
    "    end_date : str\n",
    "        End date in 'YYYY-MM-DD' format, default is today\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        Processed DataFrame ready for use in models\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*80}\\nProcessing {ticker}\\n{'='*80}\")\n",
    "    \n",
    "    # 1. Fetch data\n",
    "    df = fetch_stock_data(ticker, start_date, end_date)\n",
    "    \n",
    "    # 2. Clean data\n",
    "    print(f\"\\nCleaning data for {ticker}...\")\n",
    "    df_clean = clean_stock_data(df)\n",
    "    print(f\"Shape after cleaning: {df_clean.shape}\")\n",
    "    \n",
    "    # 3. Engineer features\n",
    "    print(f\"\\nEngineering features for {ticker}...\")\n",
    "    df_featured = engineer_features(df_clean)\n",
    "    print(f\"Shape after feature engineering: {df_featured.shape}\")\n",
    "    \n",
    "    # 4. Create target variables\n",
    "    print(f\"\\nCreating target variables for {ticker}...\")\n",
    "    df_with_targets = create_target_variables(df_featured)\n",
    "    print(f\"Shape after adding targets: {df_with_targets.shape}\")\n",
    "    \n",
    "    # 5. Drop rows with NaNs (due to rolling windows and shifting)\n",
    "    df_final = df_with_targets.dropna()\n",
    "    print(f\"\\nFinal shape after dropping NaNs: {df_final.shape}\")\n",
    "    \n",
    "    # 6. Reset index to make Date a column again before saving\n",
    "    df_final = df_final.reset_index()\n",
    "    \n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_directories()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process All Stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_all_stocks(tickers, start_date='2010-01-01', end_date=None):\n",
    "    \"\"\"\n",
    "    Process all stocks in the list and save the results to CSV files\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    tickers : list\n",
    "        List of stock ticker symbols\n",
    "    start_date : str\n",
    "        Start date in 'YYYY-MM-DD' format\n",
    "    end_date : str\n",
    "        End date in 'YYYY-MM-DD' format, default is today\n",
    "    \"\"\"\n",
    "    for ticker in tickers:\n",
    "        try:\n",
    "            # Process the stock\n",
    "            df = process_stock(ticker, start_date, end_date)\n",
    "            \n",
    "            # Save to CSV\n",
    "            output_path = f'../data/cleaned/{ticker}.csv'\n",
    "            df.to_csv(output_path, index=False)\n",
    "            print(f\"\\nSaved processed data to {output_path}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\nError processing {ticker}: {e}\")\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process all stocks (uncomment to run)\n",
    "process_all_stocks(tickers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Individual Stock Example\n",
    "\n",
    "If you want to process just one stock for testing, you can use the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example for processing a single stock (uncomment to run)\n",
    "ticker = 'AAPL'\n",
    "df = process_stock(ticker)\n",
    "\n",
    "# Save to CSV\n",
    "output_path = f'../data/cleaned/{ticker}.csv'\n",
    "df.to_csv(output_path, index=False)\n",
    "print(f\"\\nSaved processed data to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Analysis of Processed Data\n",
    "\n",
    "Let's load one of the processed files and examine it to ensure everything looks correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to run after processing at least one stock\n",
    "ticker = 'AAPL'  # Change this to any processed ticker\n",
    "file_path = f'../data/cleaned/{ticker}.csv'\n",
    "\n",
    "if os.path.exists(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Basic info\n",
    "    print(f\"DataFrame shape: {df.shape}\")\n",
    "    print(\"\\nFirst few rows:\")\n",
    "    display(df.head(10))\n",
    "    \n",
    "    print(\"\\nColumns:\")\n",
    "    for col in df.columns:\n",
    "        print(f\"- {col}\")\n",
    "    \n",
    "    # Target distribution\n",
    "    print(\"\\nTarget distribution:\")\n",
    "    print(f\"Target_1D: {df['Target_1D'].value_counts(normalize=True)}\")\n",
    "    print(f\"Target_1W: {df['Target_1W'].value_counts(normalize=True)}\")\n",
    "    print(f\"Target_1M: {df['Target_1M'].value_counts(normalize=True)}\")\n",
    "else:\n",
    "    print(f\"File {file_path} not found. Please process stocks first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook has implemented a comprehensive preprocessing pipeline for stock data that includes:\n",
    "\n",
    "1. Fetching historical stock data using yfinance\n",
    "2. Cleaning the data by handling missing values and timezone information\n",
    "3. Engineering a rich set of features including:\n",
    "   - Returns (daily, weekly, monthly)\n",
    "   - Moving averages\n",
    "   - Technical indicators (RSI, MACD, Bollinger Bands)\n",
    "   - Volatility measures\n",
    "   - Price-based features\n",
    "   - Time-based features\n",
    "4. Creating classification target variables for next day, week, and month price direction\n",
    "5. Saving the processed data to CSV files following the project's naming convention\n",
    "\n",
    "The processed data is ready for use in machine learning models like Prophet, LSTM, and XGBoost."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
