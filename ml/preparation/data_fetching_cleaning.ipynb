{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock Data Collection and Basic Cleaning\n",
    "\n",
    "## Objective\n",
    "This notebook fetches historical stock data for 20 selected companies and performs basic cleaning operations. The cleaned datasets will be saved to `data/cleaned/` for further processing by model-specific preparation notebooks.\n",
    "\n",
    "## Purpose\n",
    "The goal is to create a clean dataset with appropriate features and multiple target variables for different prediction horizons:\n",
    "- Next day closing price\n",
    "- Next week average price\n",
    "- Next month average price\n",
    "\n",
    "Each of these targets will be used to train separate specialized models, allowing for higher accuracy across different prediction timeframes.\n",
    "\n",
    "## Steps:\n",
    "1. Import necessary libraries\n",
    "2. Define companies list\n",
    "3. Fetch historical data using yfinance\n",
    "4. Perform basic cleaning\n",
    "5. Add prediction targets for multiple timeframes\n",
    "6. Visualize the data\n",
    "7. Save cleaned datasets\n",
    "8. Perform data quality checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define Stock List\n",
    "\n",
    "We'll use a predefined list of 20 companies representing different sectors for our analysis. This provides a diverse dataset for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define list of companies with symbols\n",
    "stocks = [\n",
    "    \"AAPL\", \"MSFT\", \"GOOG\", \"AMZN\", \"TSLA\", \n",
    "    \"FB\", \"NVDA\", \"SPY\", \"V\", \"DIS\", \n",
    "    \"NFLX\", \"PYPL\", \"BABA\", \"IBM\", \"AMD\", \n",
    "    \"BA\", \"INTC\", \"T\", \"GS\", \"NKE\"\n",
    "]\n",
    "\n",
    "# Note: FB is now META, but we'll try both to ensure we get data\n",
    "if \"FB\" in stocks:\n",
    "    stocks.append(\"META\")\n",
    "    \n",
    "print(f\"Total stocks to analyze: {len(stocks)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create Output Directory\n",
    "\n",
    "Define and create the directory where cleaned data will be stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output directory: /home/abderrahmane/Stock-Market-Predictor/ml/data/cleaned\n"
     ]
    }
   ],
   "source": [
    "# Create output directory if it doesn't exist\n",
    "output_dir = '../data/cleaned/'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "print(f\"Output directory: {os.path.abspath(output_dir)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define Data Fetching Function\n",
    "\n",
    "This function fetches historical data for a given stock ticker using the yfinance library. We'll retrieve 10 years of data to ensure we have sufficient history for training our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_stock_data(ticker, start_date, end_date):\n",
    "    \"\"\"\n",
    "    Fetch historical stock data for a given ticker symbol.\n",
    "    \n",
    "    Parameters:\n",
    "    - ticker: Stock symbol\n",
    "    - start_date: Start date for historical data\n",
    "    - end_date: End date for historical data\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame with historical stock data\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Fetch data using yfinance\n",
    "        stock = yf.Ticker(ticker)\n",
    "        df = stock.history(start=start_date, end=end_date)\n",
    "        \n",
    "        # Check if we got any data\n",
    "        if df.empty:\n",
    "            print(f\"No data found for {ticker}\")\n",
    "            return None\n",
    "        \n",
    "        # Add ticker column\n",
    "        df['Symbol'] = ticker\n",
    "        \n",
    "        # Get company info for additional metadata\n",
    "        try:\n",
    "            info = stock.info\n",
    "            df['Sector'] = info.get('sector', 'Unknown')\n",
    "            df['Industry'] = info.get('industry', 'Unknown')\n",
    "        except:\n",
    "            print(f\"Could not retrieve company info for {ticker}\")\n",
    "            df['Sector'] = 'Unknown'\n",
    "            df['Industry'] = 'Unknown'\n",
    "        \n",
    "        print(f\"Successfully fetched data for {ticker}: {len(df)} rows\")\n",
    "        return df\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data for {ticker}: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Define Data Cleaning Function\n",
    "\n",
    "This function performs essential cleaning operations and feature engineering on the raw stock data. Key components include:\n",
    "\n",
    "1. Basic cleaning (standardizing column names, handling missing values)\n",
    "2. Feature engineering (moving averages, volatility, returns)\n",
    "3. Creating prediction targets for three different time horizons:\n",
    "   - Next day closing price\n",
    "   - Next week average price (5 trading days)\n",
    "   - Next month average price (21 trading days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_stock_data(df):\n",
    "    \"\"\"\n",
    "    Perform basic cleaning operations on stock data and create prediction targets.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: DataFrame with stock data\n",
    "    \n",
    "    Returns:\n",
    "    - Cleaned DataFrame with prediction targets\n",
    "    \"\"\"\n",
    "    if df is None or df.empty:\n",
    "        return None\n",
    "    \n",
    "    # Make a copy to avoid modifying the original DataFrame\n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    # Reset index to make Date a column\n",
    "    df_clean = df_clean.reset_index()\n",
    "    \n",
    "    # Ensure Date column is datetime\n",
    "    df_clean['Date'] = pd.to_datetime(df_clean['Date'])\n",
    "    \n",
    "    # Rename columns to standard format\n",
    "    df_clean = df_clean.rename(columns={\n",
    "        'Open': 'open',\n",
    "        'High': 'high',\n",
    "        'Low': 'low',\n",
    "        'Close': 'close',\n",
    "        'Volume': 'volume',\n",
    "        'Dividends': 'dividends',\n",
    "        'Stock Splits': 'splits',\n",
    "        'Symbol': 'symbol',\n",
    "        'Date': 'date'\n",
    "    })\n",
    "    \n",
    "    # Handle missing values\n",
    "    df_clean[['open', 'high', 'low', 'close']] = df_clean[['open', 'high', 'low', 'close']].fillna(method='ffill')\n",
    "    df_clean['volume'] = df_clean['volume'].fillna(0)\n",
    "    df_clean['dividends'] = df_clean['dividends'].fillna(0)\n",
    "    df_clean['splits'] = df_clean['splits'].fillna(0)\n",
    "    \n",
    "    # Add derived features\n",
    "    df_clean['return'] = df_clean['close'].pct_change()  # Daily returns\n",
    "    \n",
    "    # Moving averages\n",
    "    df_clean['ma5'] = df_clean['close'].rolling(window=5).mean()\n",
    "    df_clean['ma20'] = df_clean['close'].rolling(window=20).mean()\n",
    "    df_clean['ma50'] = df_clean['close'].rolling(window=50).mean()\n",
    "    \n",
    "    # Volatility and volume features\n",
    "    df_clean['volatility'] = df_clean['return'].rolling(window=20).std()\n",
    "    df_clean['volume_ma20'] = df_clean['volume'].rolling(window=20).mean()\n",
    "    \n",
    "    # Date features\n",
    "    df_clean['day_of_week'] = df_clean['date'].dt.dayofweek\n",
    "    df_clean['month'] = df_clean['date'].dt.month\n",
    "    df_clean['year'] = df_clean['date'].dt.year\n",
    "    \n",
    "    # Handle NaN values created by rolling calculations\n",
    "    df_clean = df_clean.fillna(method='bfill')\n",
    "    df_clean = df_clean.dropna()\n",
    "    \n",
    "    # Drop rows with extreme values (potential data errors)\n",
    "    df_clean = df_clean[(df_clean['return'] > -0.5) & (df_clean['return'] < 0.5)]\n",
    "    \n",
    "    # Create prediction targets for multiple timeframes\n",
    "    # 1. Next day closing price\n",
    "    df_clean['next_day_close'] = df_clean['close'].shift(-1)\n",
    "    \n",
    "    # 2. Next week average price (5 trading days)\n",
    "    # Calculate forward-looking rolling average\n",
    "    shifted_close = pd.Series(df_clean['close'].values)\n",
    "    # For each row, calculate average of next 5 days\n",
    "    next_week_avgs = []\n",
    "    for i in range(len(shifted_close)):\n",
    "        if i + 5 < len(shifted_close):\n",
    "            next_week_avgs.append(shifted_close[i+1:i+6].mean())\n",
    "        else:\n",
    "            next_week_avgs.append(np.nan)\n",
    "    df_clean['next_week_avg'] = next_week_avgs\n",
    "    \n",
    "    # 3. Next month average price (21 trading days)\n",
    "    next_month_avgs = []\n",
    "    for i in range(len(shifted_close)):\n",
    "        if i + 21 < len(shifted_close):\n",
    "            next_month_avgs.append(shifted_close[i+1:i+22].mean())\n",
    "        else:\n",
    "            next_month_avgs.append(np.nan)\n",
    "    df_clean['next_month_avg'] = next_month_avgs\n",
    "    \n",
    "    # Drop rows with NaN prediction targets (last 21 days of data)\n",
    "    df_clean = df_clean.dropna()\n",
    "    \n",
    "    return df_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Define Visualization Function\n",
    "\n",
    "This function creates visualizations to help understand the data and verify the cleaning process was successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_stock_data(df, ticker):\n",
    "    \"\"\"\n",
    "    Create visualizations for the stock data.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: DataFrame with stock data\n",
    "    - ticker: Stock symbol\n",
    "    \"\"\"\n",
    "    if df is None or df.empty:\n",
    "        print(f\"No data to visualize for {ticker}\")\n",
    "        return\n",
    "    \n",
    "    # Create figure with subplots\n",
    "    fig, axes = plt.subplots(4, 1, figsize=(14, 20))\n",
    "    \n",
    "    # Plot 1: Price history with moving averages\n",
    "    axes[0].plot(df['date'], df['close'], label='Close Price')\n",
    "    axes[0].plot(df['date'], df['ma20'], label='20-day MA', alpha=0.7)\n",
    "    axes[0].plot(df['date'], df['ma50'], label='50-day MA', alpha=0.7)\n",
    "    axes[0].set_title(f'{ticker} - Price History')\n",
    "    axes[0].set_ylabel('Price ($)')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True)\n",
    "    \n",
    "    # Plot 2: Volume\n",
    "    axes[1].bar(df['date'], df['volume'], alpha=0.7, color='blue')\n",
    "    axes[1].plot(df['date'], df['volume_ma20'], color='red', alpha=0.7, label='20-day Volume MA')\n",
    "    axes[1].set_title(f'{ticker} - Trading Volume')\n",
    "    axes[1].set_ylabel('Volume')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True)\n",
    "    \n",
    "    # Plot 3: Returns and Volatility\n",
    "    ax3 = axes[2]\n",
    "    ax3.plot(df['date'], df['return'], label='Daily Returns', alpha=0.5, color='green')\n",
    "    ax3.set_ylabel('Returns', color='green')\n",
    "    ax3.tick_params(axis='y', labelcolor='green')\n",
    "    ax3.set_title(f'{ticker} - Returns and Volatility')\n",
    "    \n",
    "    ax3b = ax3.twinx()\n",
    "    ax3b.plot(df['date'], df['volatility'], label='Volatility (20-day)', color='red', alpha=0.7)\n",
    "    ax3b.set_ylabel('Volatility', color='red')\n",
    "    ax3b.tick_params(axis='y', labelcolor='red')\n",
    "    \n",
    "    lines1, labels1 = ax3.get_legend_handles_labels()\n",
    "    lines2, labels2 = ax3b.get_legend_handles_labels()\n",
    "    ax3.legend(lines1 + lines2, labels1 + labels2, loc='upper left')\n",
    "    ax3.grid(True)\n",
    "    \n",
    "    # Plot 4: Prediction Targets\n",
    "    # Select just the last year of data for clarity\n",
    "    last_year = df[df['date'] > df['date'].max() - pd.Timedelta(days=365)]\n",
    "    \n",
    "    axes[3].plot(last_year['date'], last_year['close'], label='Actual Close', color='blue')\n",
    "    axes[3].plot(last_year['date'], last_year['next_day_close'], label='Next Day Close', color='green', linestyle='--')\n",
    "    axes[3].plot(last_year['date'], last_year['next_week_avg'], label='Next Week Avg', color='orange', linestyle=':')\n",
    "    axes[3].plot(last_year['date'], last_year['next_month_avg'], label='Next Month Avg', color='red', linestyle='-.')\n",
    "    axes[3].set_title(f'{ticker} - Prediction Targets (Last Year)')\n",
    "    axes[3].set_ylabel('Price ($)')\n",
    "    axes[3].legend()\n",
    "    axes[3].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Monthly Returns & Target Prediction Horizons Comparison\n",
    "    monthly_returns = df.groupby('month')['return'].mean()\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    \n",
    "    # Create a figure with 2 subplots\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 12))\n",
    "    \n",
    "    # Monthly returns plot\n",
    "    ax1.bar(range(1, 13), monthly_returns, color=['green' if x > 0 else 'red' for x in monthly_returns])\n",
    "    ax1.set_title(f'{ticker} - Average Monthly Returns')\n",
    "    ax1.set_xlabel('Month')\n",
    "    ax1.set_ylabel('Average Return')\n",
    "    ax1.set_xticks(range(1, 13))\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Prediction horizons comparison (using last 90 days for clarity)\n",
    "    last_90_days = df.iloc[-90:]\n",
    "    ax2.plot(last_90_days['date'], last_90_days['close'], label='Actual Price', linewidth=2)\n",
    "    ax2.plot(last_90_days['date'], last_90_days['next_day_close'], label='Next Day', linestyle='--')\n",
    "    ax2.plot(last_90_days['date'], last_90_days['next_week_avg'], label='Next Week Avg', linestyle='-.')\n",
    "    ax2.plot(last_90_days['date'], last_90_days['next_month_avg'], label='Next Month Avg', linestyle=':')\n",
    "    ax2.set_title(f'{ticker} - Prediction Targets (Last 90 Days)')\n",
    "    ax2.set_xlabel('Date')\n",
    "    ax2.set_ylabel('Price')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Fetch and Clean Data for All Stocks\n",
    "\n",
    "Now we'll fetch and clean data for all stocks in our list, creating standardized datasets ready for model-specific preparation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define date range (10 years of data)\n",
    "end_date = datetime.now()\n",
    "start_date = end_date - timedelta(days=365*10)  # 10 years\n",
    "\n",
    "print(f\"Fetching data from {start_date.strftime('%Y-%m-%d')} to {end_date.strftime('%Y-%m-%d')}\")\n",
    "\n",
    "# Process each stock\n",
    "results = {}\n",
    "\n",
    "for ticker in stocks:\n",
    "    print(f\"Processing {ticker}...\")\n",
    "    \n",
    "    # Fetch data\n",
    "    df = fetch_stock_data(ticker, start_date, end_date)\n",
    "    \n",
    "    if df is not None and not df.empty:\n",
    "        # Clean data\n",
    "        cleaned_df = clean_stock_data(df)\n",
    "        \n",
    "        if cleaned_df is not None and not cleaned_df.empty:\n",
    "            results[ticker] = cleaned_df\n",
    "            print(f\"Cleaned data shape for {ticker}: {cleaned_df.shape}\")\n",
    "            \n",
    "            # Save cleaned data\n",
    "            output_file = os.path.join(output_dir, f\"{ticker}.csv\")\n",
    "            cleaned_df.to_csv(output_file, index=False)\n",
    "            print(f\"Saved cleaned data to {output_file}\")\n",
    "        else:\n",
    "            print(f\"No clean data available for {ticker} after processing\")\n",
    "    else:\n",
    "        print(f\"Skipping {ticker} due to data fetch issues\")\n",
    "\n",
    "print(f\"Successfully processed {len(results)} out of {len(stocks)} stocks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualize Sample Stock Data\n",
    "\n",
    "Let's visualize a few stocks to understand their patterns and verify our data processing was successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/cleaned/AAPL.csv\")\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a few selected stocks\n",
    "sample_stocks = ['AAPL', 'MSFT', 'TSLA', 'NVDA', 'AMZN']\n",
    "\n",
    "for ticker in sample_stocks:\n",
    "    if ticker in results:\n",
    "        print(f\"\\nVisualizing {ticker}...\")\n",
    "        visualize_stock_data(results[ticker], ticker)\n",
    "        \n",
    "        # Display some basic statistics\n",
    "        print(f\"\\n{ticker} Statistics:\")\n",
    "        print(f\"Data range: {results[ticker]['date'].min()} to {results[ticker]['date'].max()}\")\n",
    "        print(f\"Total trading days: {len(results[ticker])}\")\n",
    "        print(f\"Average daily return: {results[ticker]['return'].mean():.4f}\")\n",
    "        print(f\"Standard deviation of returns: {results[ticker]['return'].std():.4f}\")\n",
    "        \n",
    "        # Display correlation matrix for selected columns\n",
    "        corr_cols = ['open', 'high', 'low', 'close', 'volume', 'return', 'volatility', 'ma20', 'next_day_close', 'next_week_avg', 'next_month_avg']\n",
    "        corr_matrix = results[ticker][corr_cols].corr()\n",
    "        \n",
    "        plt.figure(figsize=(12, 10))\n",
    "        sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1, center=0, annot_kws={\"size\": 8})\n",
    "        plt.title(f\"{ticker} - Feature Correlation Matrix\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Conclusion and Next Steps\n",
    "\n",
    "We have successfully:\n",
    "1. Fetched 10 years of historical data for 20 stocks\n",
    "2. Cleaned and processed the data\n",
    "3. Added derived features (moving averages, volatility, etc.)\n",
    "4. Created prediction targets for three time horizons: next day, next week, and next month\n",
    "5. Visualized the data to understand patterns and verify correctness\n",
    "6. Saved cleaned datasets to `data/cleaned/` for further processing\n",
    "\n",
    "### Key Insights\n",
    "- We've observed varying degrees of volatility and returns across different stocks\n",
    "- Technology stocks generally show higher volatility but also higher returns\n",
    "- The three prediction horizons (day, week, month) provide different perspectives on price movements\n",
    "\n",
    "### Next Steps\n",
    "The cleaned datasets are now ready to be used in model-specific preparation notebooks. We'll create separate models for each prediction horizon using the same underlying dataset to ensure optimal prediction accuracy:\n",
    "\n",
    "1. Day prediction model: Trained to predict `next_day_close`\n",
    "2. Week prediction model: Trained to predict `next_week_avg`\n",
    "3. Month prediction model: Trained to predict `next_month_avg`\n",
    "\n",
    "This approach will allow us to maintain one streamlined dataset while still achieving specialized accuracy for each prediction timeframe."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
