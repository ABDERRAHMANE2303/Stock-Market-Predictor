{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation for Prophet Model\n",
    "\n",
    "## Objective\n",
    "This notebook prepares the cleaned stock data for the Prophet model. Prophet requires specific formatting and can benefit from carefully selected features.\n",
    "\n",
    "## Process\n",
    "1. Load the cleaned data from `data/cleaned/`\n",
    "2. Format data for Prophet (rename columns, add features)\n",
    "3. Create separate datasets for each prediction horizon (day, week, month)\n",
    "4. Save prepared files in the proper directory structure\n",
    "\n",
    "## Notes\n",
    "- Prophet requires a date column named 'ds' and a target column named 'y'\n",
    "- We'll also include additional regressors that can help improve predictions\n",
    "- Separate files for each prediction horizon allows for specialized models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "%matplotlib inline\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define Directories\n",
    "\n",
    "First, let's set up the input and output directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created directory: ../data/prophet/day\n",
      "Created directory: ../data/prophet/week\n",
      "Created directory: ../data/prophet/month\n"
     ]
    }
   ],
   "source": [
    "# Input directory (where cleaned data is stored)\n",
    "input_dir = '../data/cleaned/'\n",
    "\n",
    "# Output base directory\n",
    "output_base_dir = '../data/prophet/'\n",
    "\n",
    "# Create output directories for each prediction period\n",
    "periods = ['day', 'week', 'month']\n",
    "output_dirs = {}\n",
    "\n",
    "for period in periods:\n",
    "    output_dirs[period] = os.path.join(output_base_dir, period)\n",
    "    os.makedirs(output_dirs[period], exist_ok=True)\n",
    "    print(f\"Created directory: {output_dirs[period]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define Feature Engineering Function\n",
    "\n",
    "This function will prepare the data for Prophet by:\n",
    "1. Renaming required columns (date → ds, target → y)\n",
    "2. Adding useful technical indicators as additional regressors\n",
    "3. Keeping only the features that are relevant for Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_prophet(df, prediction_period='day'):\n",
    "    \"\"\"\n",
    "    Prepare stock data for Prophet model.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: DataFrame with cleaned stock data\n",
    "    - prediction_period: 'day', 'week', or 'month' for different prediction horizons\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame formatted for Prophet\n",
    "    \"\"\"\n",
    "    # Make a copy to avoid modifying the original DataFrame\n",
    "    df_prophet = df.copy()\n",
    "    \n",
    "    # Make sure date is in datetime format\n",
    "    df_prophet['date'] = pd.to_datetime(df_prophet['date'])\n",
    "    \n",
    "    # Rename date column to 'ds' as required by Prophet\n",
    "    df_prophet = df_prophet.rename(columns={'date': 'ds'})\n",
    "    \n",
    "    # Set the appropriate target variable based on prediction period\n",
    "    if prediction_period == 'day':\n",
    "        df_prophet = df_prophet.rename(columns={'next_day_close': 'y'})\n",
    "    elif prediction_period == 'week':\n",
    "        df_prophet = df_prophet.rename(columns={'next_week_avg': 'y'})\n",
    "    elif prediction_period == 'month':\n",
    "        df_prophet = df_prophet.rename(columns={'next_month_avg': 'y'})\n",
    "    else:\n",
    "        raise ValueError(\"prediction_period must be 'day', 'week', or 'month'\")\n",
    "    \n",
    "    # Feature Engineering: Create additional technical indicators\n",
    "    \n",
    "    # 1. Price momentum: % difference between close and moving averages\n",
    "    df_prophet['close_ma5_pct'] = (df_prophet['close'] - df_prophet['ma5']) / df_prophet['ma5']\n",
    "    df_prophet['close_ma20_pct'] = (df_prophet['close'] - df_prophet['ma20']) / df_prophet['ma20']\n",
    "    df_prophet['close_ma50_pct'] = (df_prophet['close'] - df_prophet['ma50']) / df_prophet['ma50']\n",
    "    \n",
    "    # 2. Rolling returns for different windows\n",
    "    df_prophet['rolling_return_3d'] = df_prophet['return'].rolling(window=3).sum()\n",
    "    df_prophet['rolling_return_7d'] = df_prophet['return'].rolling(window=7).sum()\n",
    "    \n",
    "    # 3. Volatility ratio (short-term to long-term)\n",
    "    # Calculate 10-day and 30-day volatility\n",
    "    df_prophet['volatility_10d'] = df_prophet['return'].rolling(window=10).std()\n",
    "    df_prophet['volatility_ratio'] = df_prophet['volatility_10d'] / df_prophet['volatility']\n",
    "    \n",
    "    # 4. Volume relative to its moving average\n",
    "    df_prophet['volume_ratio'] = df_prophet['volume'] / df_prophet['volume_ma20']\n",
    "    \n",
    "    # Fill NaN values created by rolling calculations\n",
    "    df_prophet = df_prophet.fillna(method='bfill').fillna(method='ffill')\n",
    "    \n",
    "    # Select only the columns we need for Prophet\n",
    "    columns_to_keep = [\n",
    "        'ds',                  # Date\n",
    "        'y',                   # Target variable\n",
    "        'symbol',              # Stock symbol\n",
    "        'open',                # Price variables\n",
    "        'high',\n",
    "        'low',\n",
    "        'close',\n",
    "        'volume',              # Volume\n",
    "        'return',              # Returns\n",
    "        'ma5',                 # Moving averages\n",
    "        'ma20',\n",
    "        'ma50',\n",
    "        'volatility',          # Volatility measures\n",
    "        'volume_ma20',         # Volume moving average\n",
    "        'close_ma5_pct',       # Additional engineered features\n",
    "        'close_ma20_pct',\n",
    "        'close_ma50_pct',\n",
    "        'rolling_return_3d',\n",
    "        'rolling_return_7d',\n",
    "        'volatility_10d',\n",
    "        'volatility_ratio',\n",
    "        'volume_ratio'\n",
    "    ]\n",
    "    \n",
    "    # Keep only the selected columns\n",
    "    df_prophet = df_prophet[columns_to_keep]\n",
    "    \n",
    "    # Drop any remaining NaN values\n",
    "    df_prophet = df_prophet.dropna()\n",
    "    \n",
    "    return df_prophet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define Data Visualization Function\n",
    "\n",
    "We'll create a function to visualize the prepared data to ensure our transformations are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_prophet_data(df, symbol, period):\n",
    "    \"\"\"\n",
    "    Visualize the data prepared for Prophet.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: DataFrame prepared for Prophet\n",
    "    - symbol: Stock symbol\n",
    "    - period: Prediction period ('day', 'week', or 'month')\n",
    "    \"\"\"\n",
    "    # Create figure with subplots\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(14, 18))\n",
    "    \n",
    "    # Plot 1: Close Price and Target Variable\n",
    "    axes[0].plot(df['ds'], df['close'], label='Close Price', color='blue')\n",
    "    axes[0].plot(df['ds'], df['y'], label=f'Target ({period})', color='red', linestyle='--')\n",
    "    axes[0].set_title(f'{symbol} - Close Price vs Target ({period})')\n",
    "    axes[0].set_ylabel('Price ($)')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True)\n",
    "    \n",
    "    # Plot 2: Engineered Features (momentum)\n",
    "    axes[1].plot(df['ds'], df['close_ma5_pct'], label='% Diff Close-MA5', color='green')\n",
    "    axes[1].plot(df['ds'], df['close_ma20_pct'], label='% Diff Close-MA20', color='orange')\n",
    "    axes[1].plot(df['ds'], df['close_ma50_pct'], label='% Diff Close-MA50', color='purple')\n",
    "    axes[1].set_title(f'{symbol} - Price Momentum Indicators')\n",
    "    axes[1].set_ylabel('Percent Difference')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True)\n",
    "    \n",
    "    # Plot 3: Volatility Features\n",
    "    axes[2].plot(df['ds'], df['volatility'], label='Volatility (20d)', color='red')\n",
    "    axes[2].plot(df['ds'], df['volatility_10d'], label='Volatility (10d)', color='blue')\n",
    "    axes[2].plot(df['ds'], df['volatility_ratio'], label='Volatility Ratio', color='green')\n",
    "    axes[2].set_title(f'{symbol} - Volatility Indicators')\n",
    "    axes[2].set_ylabel('Volatility')\n",
    "    axes[2].legend()\n",
    "    axes[2].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Correlation heatmap of features\n",
    "    plt.figure(figsize=(14, 12))\n",
    "    correlation = df.corr()\n",
    "    mask = np.triu(correlation)\n",
    "    sns.heatmap(correlation, mask=mask, annot=True, cmap='coolwarm', linewidths=0.5, fmt='.2f', cbar_kws={\"shrink\": .8})\n",
    "    plt.title(f'{symbol} - Feature Correlation ({period})')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Process All Stock Files\n",
    "\n",
    "Now we'll process all stock files in the input directory and prepare them for Prophet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of all stock files\n",
    "stock_files = glob.glob(os.path.join(input_dir, \"*.csv\"))\n",
    "print(f\"Found {len(stock_files)} stock files to process\")\n",
    "\n",
    "# Process each stock file for each prediction period\n",
    "for file_path in tqdm(stock_files, desc=\"Processing stocks\"):\n",
    "    # Extract symbol from filename\n",
    "    symbol = os.path.basename(file_path).split('.')[0]\n",
    "    print(f\"\\nProcessing {symbol}...\")\n",
    "    \n",
    "    # Load data\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(f\"Loaded data for {symbol}: {len(df)} rows\")\n",
    "        \n",
    "        # Process for each prediction period\n",
    "        for period in periods:\n",
    "            try:\n",
    "                # Prepare data for Prophet\n",
    "                df_prophet = prepare_for_prophet(df, prediction_period=period)\n",
    "                print(f\"Prepared {symbol} data for {period} prediction: {len(df_prophet)} rows\")\n",
    "                \n",
    "                # Save prepared data\n",
    "                output_file = os.path.join(output_dirs[period], f\"{symbol}_prophet.csv\")\n",
    "                df_prophet.to_csv(output_file, index=False)\n",
    "                print(f\"Saved {period} data to {output_file}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error preparing {symbol} data for {period} prediction: {str(e)}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {symbol} data: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualize Sample Prepared Data\n",
    "\n",
    "Let's visualize some prepared data to verify our transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose sample stocks to visualize\n",
    "sample_stocks = ['AAPL', 'MSFT', 'TSLA', 'AMZN', 'NVDA']\n",
    "\n",
    "for symbol in sample_stocks:\n",
    "    for period in periods:\n",
    "        file_path = os.path.join(output_dirs[period], f\"{symbol}_prophet.csv\")\n",
    "        \n",
    "        if os.path.exists(file_path):\n",
    "            # Load prepared data\n",
    "            df_prophet = pd.read_csv(file_path)\n",
    "            df_prophet['ds'] = pd.to_datetime(df_prophet['ds'])\n",
    "            \n",
    "            # Show basic info\n",
    "            print(f\"\\n{symbol} - {period.capitalize()} Prediction Data:\")\n",
    "            print(f\"Date range: {df_prophet['ds'].min()} to {df_prophet['ds'].max()}\")\n",
    "            print(f\"Number of rows: {len(df_prophet)}\")\n",
    "            print(f\"Features: {df_prophet.columns.tolist()}\")\n",
    "            \n",
    "            # Display first few rows\n",
    "            print(\"\\nSample data:\")\n",
    "            display(df_prophet.head(3))\n",
    "            \n",
    "            # Visualize the data\n",
    "            visualize_prophet_data(df_prophet, symbol, period)\n",
    "        else:\n",
    "            print(f\"File not found: {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Data Quality Check\n",
    "\n",
    "Let's perform some basic quality checks on our prepared data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_data_quality(df, symbol, period):\n",
    "    \"\"\"\n",
    "    Perform basic quality checks on prepared data.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: DataFrame prepared for Prophet\n",
    "    - symbol: Stock symbol\n",
    "    - period: Prediction period\n",
    "    \n",
    "    Returns:\n",
    "    - Dictionary with quality check results\n",
    "    \"\"\"\n",
    "    quality = {}\n",
    "    \n",
    "    # Check for missing values\n",
    "    missing = df.isnull().sum()\n",
    "    quality['missing_values'] = missing[missing > 0].to_dict()\n",
    "    \n",
    "    # Check for duplicate dates\n",
    "    duplicate_dates = df['ds'].duplicated().sum()\n",
    "    quality['duplicate_dates'] = duplicate_dates\n",
    "    \n",
    "    # Check for data continuity (gaps in dates)\n",
    "    date_diff = df['ds'].diff().dt.days\n",
    "    gaps = date_diff[date_diff > 1]\n",
    "    quality['date_gaps'] = len(gaps)\n",
    "    if len(gaps) > 0:\n",
    "        quality['max_gap_days'] = gaps.max()\n",
    "    \n",
    "    # Check for outliers in target variable\n",
    "    q1 = df['y'].quantile(0.25)\n",
    "    q3 = df['y'].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower_bound = q1 - 1.5 * iqr\n",
    "    upper_bound = q3 + 1.5 * iqr\n",
    "    outliers = df[(df['y'] < lower_bound) | (df['y'] > upper_bound)]\n",
    "    quality['target_outliers'] = len(outliers)\n",
    "    quality['target_outliers_pct'] = round(len(outliers) / len(df) * 100, 2)\n",
    "    \n",
    "    # Check correlations between features and target\n",
    "    corr_with_target = df.corr()['y'].abs().sort_values(ascending=False)\n",
    "    quality['top_5_correlations'] = corr_with_target.head(6).to_dict()\n",
    "    \n",
    "    # Check feature distribution skewness\n",
    "    skew = df.skew()\n",
    "    highly_skewed = skew[abs(skew) > 1].to_dict()\n",
    "    quality['highly_skewed_features'] = highly_skewed\n",
    "    \n",
    "    return quality\n",
    "\n",
    "# Run quality checks on sample stocks\n",
    "quality_results = {}\n",
    "\n",
    "for symbol in sample_stocks:\n",
    "    quality_results[symbol] = {}\n",
    "    \n",
    "    for period in periods:\n",
    "        file_path = os.path.join(output_dirs[period], f\"{symbol}_prophet.csv\")\n",
    "        \n",
    "        if os.path.exists(file_path):\n",
    "            # Load prepared data\n",
    "            df_prophet = pd.read_csv(file_path)\n",
    "            df_prophet['ds'] = pd.to_datetime(df_prophet['ds'])\n",
    "            \n",
    "            # Run quality checks\n",
    "            quality = check_data_quality(df_prophet, symbol, period)\n",
    "            quality_results[symbol][period] = quality\n",
    "            \n",
    "            # Print quality check summary\n",
    "            print(f\"\\n{symbol} - {period.capitalize()} Data Quality Check:\")\n",
    "            print(f\"Missing values: {len(quality['missing_values'])}\")\n",
    "            print(f\"Duplicate dates: {quality['duplicate_dates']}\")\n",
    "            print(f\"Date gaps: {quality['date_gaps']}\")\n",
    "            print(f\"Target outliers: {quality['target_outliers']} ({quality['target_outliers_pct']}%)\")\n",
    "            print(\"Top correlations with target:\")\n",
    "            for feat, corr in list(quality['top_5_correlations'].items())[:5]:\n",
    "                if feat != 'y':  # Skip self-correlation\n",
    "                    print(f\"  - {feat}: {corr:.4f}\")\n",
    "        else:\n",
    "            print(f\"File not found: {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Conclusion and Next Steps\n",
    "\n",
    "We have successfully:\n",
    "1. Loaded cleaned stock data for multiple companies\n",
    "2. Transformed the data to match Prophet's required format\n",
    "3. Created additional engineered features that can improve prediction performance\n",
    "4. Prepared separate datasets for day, week, and month prediction periods\n",
    "5. Saved the prepared data in organized directories\n",
    "6. Performed quality checks to ensure data integrity\n",
    "\n",
    "### Key Insights\n",
    "- The prepared data includes a mix of price-based features, technical indicators, and engineered features\n",
    "- The correlation analysis shows which features are most likely to be useful for predictions\n",
    "- The quality checks help identify potential issues that might affect model performance\n",
    "\n",
    "### Next Steps\n",
    "The prepared datasets are now ready to be used for training Prophet models. We'll create separate models for each prediction horizon (day, week, month) to achieve specialized accuracy for each timeframe."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
