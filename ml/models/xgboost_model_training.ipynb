{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock Price Prediction Data Preparation for XGBoost\n",
    "\n",
    "This notebook prepares stock data for prediction using XGBoost models for three different time periods:\n",
    "1. Next day close price\n",
    "2. Next week average close price\n",
    "3. Next month average close price\n",
    "\n",
    "For each stock, we'll create three separate datasets specifically formatted for each prediction period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of stock symbols\n",
    "stocks = [\"AAPL\", \"MSFT\", \"GOOG\", \"AMZN\", \"TSLA\", \n",
    "          \"META\", \"NVDA\", \"SPY\", \"V\", \"DIS\",\n",
    "          \"NFLX\", \"PYPL\", \"BABA\", \"IBM\", \"AMD\",\n",
    "          \"BA\", \"INTC\", \"T\", \"GS\", \"NKE\"]\n",
    "\n",
    "# Path to the project root\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"../..\"))\n",
    "\n",
    "# Paths for input and output data\n",
    "input_folder = os.path.join(project_root, \"data\", \"xgboost\")\n",
    "output_base_folder = os.path.join(project_root, \"data\", \"xgboost\")\n",
    "\n",
    "# Create output folders for each prediction period\n",
    "output_folders = {\n",
    "    'day': os.path.join(output_base_folder, \"day\"),\n",
    "    'week': os.path.join(output_base_folder, \"week\"),\n",
    "    'month': os.path.join(output_base_folder, \"month\")\n",
    "}\n",
    "\n",
    "# Ensure output directories exist\n",
    "for folder in output_folders.values():\n",
    "    os.makedirs(folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_daily_prediction_data(df, stock_symbol):\n",
    "    \"\"\"\n",
    "    Prepare data for next day close price prediction.\n",
    "    The next_day_close and next_day_close_original columns are already present.\n",
    "    \"\"\"\n",
    "    # Make a copy to avoid modifications to the original dataframe\n",
    "    daily_df = df.copy()\n",
    "    \n",
    "    # Rename target columns for clarity\n",
    "    daily_df = daily_df.rename(columns={\n",
    "        'next_day_close': 'target',\n",
    "        'next_day_close_original': 'target_original',\n",
    "        'pct_change_next_day': 'pct_change_target'\n",
    "    })\n",
    "    \n",
    "    # Drop rows with NaN target values (typically the last row)\n",
    "    daily_df = daily_df.dropna(subset=['target'])\n",
    "    \n",
    "    # Save to CSV\n",
    "    output_path = os.path.join(output_folders['day'], f\"{stock_symbol}_xgboost_day.csv\")\n",
    "    daily_df.to_csv(output_path, index=False)\n",
    "    \n",
    "    return output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_weekly_prediction_data(df, stock_symbol):\n",
    "    \"\"\"\n",
    "    Prepare data for next week average close price prediction.\n",
    "    We'll calculate the average close price for the next 5 trading days.\n",
    "    \"\"\"\n",
    "    # Make a copy to avoid modifications to the original dataframe\n",
    "    weekly_df = df.copy()\n",
    "    \n",
    "    # Calculate the average close price for the next 5 trading days\n",
    "    # First, get the original close prices (non-normalized)\n",
    "    close_original = weekly_df['close_original'].values\n",
    "    \n",
    "    # Initialize arrays for targets\n",
    "    next_week_close = np.full(len(weekly_df), np.nan)\n",
    "    next_week_close_original = np.full(len(weekly_df), np.nan)\n",
    "    pct_change_next_week = np.full(len(weekly_df), np.nan)\n",
    "    \n",
    "    # For each day, calculate the average of the next 5 trading days\n",
    "    for i in range(len(weekly_df) - 5):\n",
    "        next_week_close[i] = np.mean(weekly_df['close'].values[i+1:i+6])\n",
    "        next_week_close_original[i] = np.mean(close_original[i+1:i+6])\n",
    "        # Calculate percentage change from current close to next week average\n",
    "        pct_change_next_week[i] = (next_week_close_original[i] / close_original[i]) - 1\n",
    "    \n",
    "    # Add target columns\n",
    "    weekly_df['target'] = next_week_close\n",
    "    weekly_df['target_original'] = next_week_close_original\n",
    "    weekly_df['pct_change_target'] = pct_change_next_week\n",
    "    \n",
    "    # Create binary target for price movement direction\n",
    "    weekly_df['price_up'] = (weekly_df['pct_change_target'] > 0).astype(int)\n",
    "    \n",
    "    # Drop rows with NaN target values\n",
    "    weekly_df = weekly_df.dropna(subset=['target'])\n",
    "    \n",
    "    # Save to CSV\n",
    "    output_path = os.path.join(output_folders['week'], f\"{stock_symbol}_xgboost_week.csv\")\n",
    "    weekly_df.to_csv(output_path, index=False)\n",
    "    \n",
    "    return output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_monthly_prediction_data(df, stock_symbol):\n",
    "    \"\"\"\n",
    "    Prepare data for next month average close price prediction.\n",
    "    We'll calculate the average close price for the next 21 trading days (approx. one month).\n",
    "    \"\"\"\n",
    "    # Make a copy to avoid modifications to the original dataframe\n",
    "    monthly_df = df.copy()\n",
    "    \n",
    "    # Calculate the average close price for the next 21 trading days\n",
    "    # First, get the original close prices (non-normalized)\n",
    "    close_original = monthly_df['close_original'].values\n",
    "    \n",
    "    # Initialize arrays for targets\n",
    "    next_month_close = np.full(len(monthly_df), np.nan)\n",
    "    next_month_close_original = np.full(len(monthly_df), np.nan)\n",
    "    pct_change_next_month = np.full(len(monthly_df), np.nan)\n",
    "    \n",
    "    # For each day, calculate the average of the next 21 trading days\n",
    "    for i in range(len(monthly_df) - 21):\n",
    "        next_month_close[i] = np.mean(monthly_df['close'].values[i+1:i+22])\n",
    "        next_month_close_original[i] = np.mean(close_original[i+1:i+22])\n",
    "        # Calculate percentage change from current close to next month average\n",
    "        pct_change_next_month[i] = (next_month_close_original[i] / close_original[i]) - 1\n",
    "    \n",
    "    # Add target columns\n",
    "    monthly_df['target'] = next_month_close\n",
    "    monthly_df['target_original'] = next_month_close_original\n",
    "    monthly_df['pct_change_target'] = pct_change_next_month\n",
    "    \n",
    "    # Create binary target for price movement direction\n",
    "    monthly_df['price_up'] = (monthly_df['pct_change_target'] > 0).astype(int)\n",
    "    \n",
    "    # Drop rows with NaN target values\n",
    "    monthly_df = monthly_df.dropna(subset=['target'])\n",
    "    \n",
    "    # Save to CSV\n",
    "    output_path = os.path.join(output_folders['month'], f\"{stock_symbol}_xgboost_month.csv\")\n",
    "    monthly_df.to_csv(output_path, index=False)\n",
    "    \n",
    "    return output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_stock(stock_symbol):\n",
    "    \"\"\"\n",
    "    Process a single stock symbol to create all three prediction datasets.\n",
    "    \"\"\"\n",
    "    print(f\"Processing {stock_symbol}...\")\n",
    "    \n",
    "    # Construct the input file path\n",
    "    input_file = os.path.join(input_folder, f\"{stock_symbol}.csv\")\n",
    "    \n",
    "    # Check if the file exists\n",
    "    if not os.path.exists(input_file):\n",
    "        print(f\"Warning: {input_file} not found. Skipping {stock_symbol}.\")\n",
    "        return None\n",
    "    \n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(input_file, parse_dates=['date'])\n",
    "    \n",
    "    # Process data for each prediction period\n",
    "    daily_output = prepare_daily_prediction_data(df, stock_symbol)\n",
    "    weekly_output = prepare_weekly_prediction_data(df, stock_symbol)\n",
    "    monthly_output = prepare_monthly_prediction_data(df, stock_symbol)\n",
    "    \n",
    "    print(f\"Created prediction datasets for {stock_symbol}:\")\n",
    "    print(f\"  - Daily: {daily_output}\")\n",
    "    print(f\"  - Weekly: {weekly_output}\")\n",
    "    print(f\"  - Monthly: {monthly_output}\")\n",
    "    \n",
    "    return {\n",
    "        'day': daily_output,\n",
    "        'week': weekly_output,\n",
    "        'month': monthly_output\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process all stocks\n",
    "results = {}\n",
    "for stock in stocks:\n",
    "    results[stock] = process_stock(stock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print summary\n",
    "print(\"\\nProcessing Summary:\")\n",
    "print(f\"Total stocks processed: {len([r for r in results.values() if r is not None])}\")\n",
    "print(f\"Failed to process: {len([r for r in results.values() if r is None])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_datasets():\n",
    "    \"\"\"\n",
    "    Validate the created datasets to ensure they have the expected structure.\n",
    "    \"\"\"\n",
    "    print(\"\\nValidating datasets...\")\n",
    "    \n",
    "    for period in ['day', 'week', 'month']:\n",
    "        folder = output_folders[period]\n",
    "        files = os.listdir(folder)\n",
    "        if not files:\n",
    "            print(f\"Warning: No files found in {folder}\")\n",
    "            continue\n",
    "            \n",
    "        # Check the first file as a sample\n",
    "        sample_file = os.path.join(folder, files[0])\n",
    "        sample_df = pd.read_csv(sample_file)\n",
    "        \n",
    "        # Check for required columns\n",
    "        required_cols = ['date', 'target', 'target_original', 'pct_change_target', 'price_up']\n",
    "        missing = [col for col in required_cols if col not in sample_df.columns]\n",
    "        \n",
    "        if missing:\n",
    "            print(f\"Warning: {period} datasets are missing columns: {missing}\")\n",
    "        else:\n",
    "            print(f\"{period} datasets validation passed!\")\n",
    "            print(f\"  - Sample file: {files[0]}\")\n",
    "            print(f\"  - Row count: {len(sample_df)}\")\n",
    "            print(f\"  - Target mean: {sample_df['target'].mean():.4f}\")\n",
    "    \n",
    "    print(\"\\nValidation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run validation\n",
    "validate_datasets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Analysis\n",
    "\n",
    "Let's examine a sample of the generated datasets to confirm they're structured correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to load and display samples from each time period if available\n",
    "try:\n",
    "    # Get first available stock\n",
    "    available_stocks = [stock for stock in stocks if results.get(stock) is not None]\n",
    "    if available_stocks:\n",
    "        sample_stock = available_stocks[0]\n",
    "        \n",
    "        print(f\"Sample analysis for {sample_stock}:\")\n",
    "        \n",
    "        # Load samples from each period\n",
    "        for period in ['day', 'week', 'month']:\n",
    "            file_path = os.path.join(output_folders[period], f\"{sample_stock}_xgboost_{period}.csv\")\n",
    "            if os.path.exists(file_path):\n",
    "                df = pd.read_csv(file_path, parse_dates=['date'])\n",
    "                print(f\"\\n{period.capitalize()} prediction dataset:\")\n",
    "                print(f\"  - Shape: {df.shape}\")\n",
    "                print(f\"  - Date range: {df['date'].min()} to {df['date'].max()}\")\n",
    "                print(f\"  - Percent of price increases: {df['price_up'].mean()*100:.2f}%\")\n",
    "                print(\"\\nSample rows:\")\n",
    "                print(df[['date', 'close_original', 'target_original', 'pct_change_target', 'price_up']].head())\n",
    "    else:\n",
    "        print(\"No processed stocks available for sample analysis.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during sample analysis: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}